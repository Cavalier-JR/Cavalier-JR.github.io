<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>计算机视觉知识点总结（结合cs131）</title>
      <link href="/2025/04/25/post13/"/>
      <url>/2025/04/25/post13/</url>
      
        <content type="html"><![CDATA[<h1 id="〇、考点"><a href="#〇、考点" class="headerlink" title="〇、考点"></a>〇、考点</h1><blockquote><p><strong>题目主要集中在分割之前</strong></p></blockquote><h2 id="1-绪论"><a href="#1-绪论" class="headerlink" title="1. 绪论"></a>1. 绪论</h2><ul><li>知道几个计算机视觉的应用场景（选择题）</li></ul><h2 id="2-图像的形成"><a href="#2-图像的形成" class="headerlink" title="2. 图像的形成"></a>2. 图像的形成</h2><ul><li>颜色直方图的优缺点</li></ul><h2 id="3-图像处理基础"><a href="#3-图像处理基础" class="headerlink" title="3. 图像处理基础"></a>3. 图像处理基础</h2><ul><li>卷积时对边缘填坑问题的四种处理方式，对应matlab函数的意义</li><li>高斯核方差/窗宽的变化与平滑程度的关系（可能简答可能选择）</li><li>常见卷积核（原图、左移一个单位、模糊……）</li><li>高斯核的自卷积性质</li><li>卷积时间复杂度分析（强调了一定会考）</li></ul><h2 id="4-边缘检测"><a href="#4-边缘检测" class="headerlink" title="4. 边缘检测"></a>4. 边缘检测</h2><ul><li>解释为什么图像对x（y）求导提取了y（x）方向的特征</li><li>可分离性的证明，可能是高斯核，也可能是高斯一阶偏导核（一定会考）</li><li>3.10没声，不知道Canny边缘检测器的考点情况</li><li>霍夫变换和RANSAC的异同点？（简答）</li><li>霍夫变换的流程的大致描述</li><li>霍夫变换的优缺点（可能选择也可能问答）</li></ul><h2 id="5-拟合"><a href="#5-拟合" class="headerlink" title="5. 拟合"></a>5. 拟合</h2><ul><li>K-Means 算法的流程</li><li>K-Means 算法的优缺点</li><li>Mean Shift 算法的流程</li><li>Mean Shift 算法的优缺点</li></ul><h2 id="6-局部特征"><a href="#6-局部特征" class="headerlink" title="6. 局部特征"></a>6. 局部特征</h2><h3 id="（1）角点检测"><a href="#（1）角点检测" class="headerlink" title="（1）角点检测"></a>（1）角点检测</h3><ul><li>Harris角点检测的流程</li><li>M矩阵和阈值R如何计算</li><li>Harris角点检测的不变性</li></ul><h3 id="（2）斑点检测"><a href="#（2）斑点检测" class="headerlink" title="（2）斑点检测"></a>（2）斑点检测</h3><ul><li>高斯差分如何提升了计算效率</li><li>高斯核的性质（高斯核的自卷积性质）</li></ul><h3 id="（3）纹理特征"><a href="#（3）纹理特征" class="headerlink" title="（3）纹理特征"></a>（3）纹理特征</h3><ul><li>优点、属性（可能以选择题的形式）</li><li>SIFT特征的维度（128）</li><li>需要好好复习SIFT特征</li></ul><h2 id="7-分割"><a href="#7-分割" class="headerlink" title="7. 分割"></a>7. 分割</h2><p>不知道</p><h2 id="8-识别"><a href="#8-识别" class="headerlink" title="8. 识别"></a>8. 识别</h2><p>不知道</p><h2 id="9-检测"><a href="#9-检测" class="headerlink" title="9. 检测"></a>9. 检测</h2><ul><li>Boosting算法的思想</li><li>统计模板方法的优缺点（选择题）</li></ul><h1 id="一、绪论"><a href="#一、绪论" class="headerlink" title="一、绪论"></a>一、绪论</h1><h2 id="1-计算机视觉的目标"><a href="#1-计算机视觉的目标" class="headerlink" title="1. 计算机视觉的目标"></a>1. 计算机视觉的目标</h2><p>跨越“语义鸿沟”建立像素到语义的映射</p><h2 id="2-人类视觉系统"><a href="#2-人类视觉系统" class="headerlink" title="2. 人类视觉系统"></a>2. 人类视觉系统</h2><h3 id="（1）视觉流程"><a href="#（1）视觉流程" class="headerlink" title="（1）视觉流程"></a>（1）视觉流程</h3><p>图像/视频 → 眼睛【感知设备】 → 大脑【解释器】 → 花草树木 春夏秋冬 山河湖海…【解释】</p><h3 id="（2）能力"><a href="#（2）能力" class="headerlink" title="（2）能力"></a>（2）能力</h3><ul><li>运动视盲</li><li>分割</li><li>感知</li><li>….</li></ul><h3 id="（3）计算机视觉的应用场景"><a href="#（3）计算机视觉的应用场景" class="headerlink" title="（3）计算机视觉的应用场景"></a>（3）计算机视觉的应用场景</h3><ul><li>三维重建</li><li>人脸检测、笑容检测</li><li>虹膜识别、指纹识别</li><li>手写字体识别、车牌识别</li><li>无人超市</li><li>火星探测</li><li>医学图像辅助诊断</li><li>增强现实</li><li>虚拟现实</li><li>…….<blockquote><p>这部分没什么东西，略过</p></blockquote></li></ul><h1 id="二、图像的形成"><a href="#二、图像的形成" class="headerlink" title="二、图像的形成"></a>二、图像的形成</h1><h2 id="1-图像的类型"><a href="#1-图像的类型" class="headerlink" title="1. 图像的类型"></a>1. 图像的类型</h2><h3 id="（1）二进制图像"><a href="#（1）二进制图像" class="headerlink" title="（1）二进制图像"></a>（1）二进制图像</h3><p>每个像素点取值0/1；0黑，1白<br>每个像素点可以用1个bit表示<br><img src="/../images/post13_images/c577564971b79c29dc5958291aa7c1ab.png"></p><h3 id="（2）灰色图像"><a href="#（2）灰色图像" class="headerlink" title="（2）灰色图像"></a>（2）灰色图像</h3><p>每个像素点取值0~255；小黑，大白<br>每个像素点可以用1个byte表示（$1$ $byte$ = $2^8$ $bit$=256$ $bit$）<br><img src="/../images/post13_images/347e291fb5502947fa87fd2fb5a65d94.png"><br>灰度图像能表示的信息有限，比如车道的黄线和白线，灰度表示不出来</p><h3 id="（3）彩色图像"><a href="#（3）彩色图像" class="headerlink" title="（3）彩色图像"></a>（3）彩色图像</h3><h4 id="eg-RGB"><a href="#eg-RGB" class="headerlink" title="eg.RGB"></a>eg.RGB</h4><p>三个通道：Red/Green/Blue<br>每个像素点可以用3个byte表示</p><h2 id="2-数字图像的存储"><a href="#2-数字图像的存储" class="headerlink" title="2. 数字图像的存储"></a>2. 数字图像的存储</h2><blockquote><p>对数字图像进行采样和量化两个操作，从而表示为整数值矩阵</p></blockquote><h3 id="（1）采样"><a href="#（1）采样" class="headerlink" title="（1）采样"></a>（1）采样</h3><p>在一个规则的网格上对二维空间进行采样：</p><ul><li>把图像划分为非常多的小格子，格子越多，分辨率越高，每个格子表示一个像素<br><img src="/../images/post13_images/b6153f9813f5948f64910aef2bcedc50.png"></li></ul><h3 id="（2）量化"><a href="#（2）量化" class="headerlink" title="（2）量化"></a>（2）量化</h3><ul><li>给每个小格子（像素）一个整数值，0~255，数值连续<br><img src="/../images/post13_images/3d9d43a93052cd327031dc82bc9b8bbd.png"></li></ul><h2 id="3-图像色彩模型"><a href="#3-图像色彩模型" class="headerlink" title="3. 图像色彩模型"></a>3. 图像色彩模型</h2><h3 id="（1）色彩空间的定义"><a href="#（1）色彩空间的定义" class="headerlink" title="（1）色彩空间的定义"></a>（1）色彩空间的定义</h3><p>通过多个颜色分量构成坐标系来表示各种颜色的模型系统</p><h3 id="（2）常见的色彩空间"><a href="#（2）常见的色彩空间" class="headerlink" title="（2）常见的色彩空间"></a>（2）常见的色彩空间</h3><h4 id="①-RGB"><a href="#①-RGB" class="headerlink" title="① RGB"></a>① RGB</h4><p>Red/Green/Blue<br>红绿蓝，每个0~255，因此可以表示$256^3$种颜色<br><img src="/../images/post13_images/a33f3b2a71ca3653b8e46b2c37c0f1f4.png"></p><h4 id="②-HSV"><a href="#②-HSV" class="headerlink" title="② HSV"></a>② HSV</h4><p>Hue（色调）/Saturation（饱和度）/Value（亮度）<br><img src="/../images/post13_images/63295e8932a2054577fa6773825184f6.png"><br>Hue的取值是0°<del>360°；Saturation的取值是0</del>1；Value的取值是0~1<br>HSV在图像增强领域应用的比较多，能够更大程度保护图像颜色信息，避免色彩失真</p><h4 id="③-HLS"><a href="#③-HLS" class="headerlink" title="③ HLS"></a>③ HLS</h4><p>Hue（色调）/Lightness（亮度）/Saturation（饱和度）<br><img src="/../images/post13_images/81457c35c1609f9b35ecbd6030ebd880.png"><br>（图中说数值越大越小，色彩越白越黑，指的是）</p><h4 id="Value和Lightness的区别"><a href="#Value和Lightness的区别" class="headerlink" title="Value和Lightness的区别"></a>Value和Lightness的区别</h4><ul><li>Value：光线强度的明度</li><li>Lightness：白色光线的多少</li></ul><h2 id="4-图像直方图"><a href="#4-图像直方图" class="headerlink" title="4. 图像直方图"></a>4. 图像直方图</h2><h3 id="（1）构建直方图示例（简单灰度图像示例）"><a href="#（1）构建直方图示例（简单灰度图像示例）" class="headerlink" title="（1）构建直方图示例（简单灰度图像示例）"></a>（1）构建直方图示例（简单灰度图像示例）</h3><p>直方图Histograms，初始化直方图有i个格子（bin）：H[i]<br>假设i=4，对如下图的图像构建直方图：<br><img src="/../images/post13_images/f05d39f1037bb15116353a75b2431921.png"></p><h3 id="（2）归一化"><a href="#（2）归一化" class="headerlink" title="（2）归一化"></a>（2）归一化</h3><h4 id="①-动机"><a href="#①-动机" class="headerlink" title="① 动机"></a>① 动机</h4><p>对于两个大小不同的图像，想要进行比较，如果都选取同样bin的数量构建直方图，则小的图像显然取值少，无法合理比较。</p><h4 id="②-做法"><a href="#②-做法" class="headerlink" title="② 做法"></a>② 做法</h4><p>按照原来的取值，除以总像素数量即可。<br>在刚才的例子中，相当于从 $2,3 ,1,3$ 变成 $\frac{2}{9},\frac{3}{9},\frac{1}{9},\frac{3}{9}$</p><h3 id="（3）彩色图像构建直方图——颜色直方图"><a href="#（3）彩色图像构建直方图——颜色直方图" class="headerlink" title="（3）彩色图像构建直方图——颜色直方图"></a>（3）彩色图像构建直方图——颜色直方图</h3><h4 id="①-构建方法"><a href="#①-构建方法" class="headerlink" title="① 构建方法"></a>① 构建方法</h4><h5 id="a-方法1：分别构建三个通道的直方图"><a href="#a-方法1：分别构建三个通道的直方图" class="headerlink" title="a. 方法1：分别构建三个通道的直方图"></a>a. 方法1：分别构建三个通道的直方图</h5><h5 id="b-方法2：三个通道取均值-按比例得到一个数值，再构建一个直方图"><a href="#b-方法2：三个通道取均值-按比例得到一个数值，再构建一个直方图" class="headerlink" title="b. 方法2：三个通道取均值/按比例得到一个数值，再构建一个直方图"></a>b. 方法2：三个通道取均值/按比例得到一个数值，再构建一个直方图</h5><h4 id="②-颜色直方图的优点"><a href="#②-颜色直方图的优点" class="headerlink" title="② 颜色直方图的优点"></a>② 颜色直方图的优点</h4><ul><li>颜色直方图可以比较好的表示一张图像</li><li>计算过程快速且计算方式简单</li><li>可以将大小进行标准化，从而比较不同的图像直方图</li><li>可以利用颜色直方图进行数据库查询或分类</li></ul><h3 id="（4）总结bin与像素的关系"><a href="#（4）总结bin与像素的关系" class="headerlink" title="（4）总结bin与像素的关系"></a>（4）总结bin与像素的关系</h3><ul><li>每个像素都有且只有一个自己所属的bin</li><li>每个bin可能会对应多个像素</li></ul><h1 id="三、图像处理基础"><a href="#三、图像处理基础" class="headerlink" title="三、图像处理基础"></a>三、图像处理基础</h1><h2 id="1-噪声的去除"><a href="#1-噪声的去除" class="headerlink" title="1. 噪声的去除"></a>1. 噪声的去除</h2><p>如果能和周围的像素加权平均一下，噪声点的影响就变小了<br>因此可以把加权平均的权值做成一个卷积核/滤波核</p><h2 id="2-卷积"><a href="#2-卷积" class="headerlink" title="2. 卷积"></a>2. 卷积</h2><h3 id="（1）卷积核"><a href="#（1）卷积核" class="headerlink" title="（1）卷积核"></a>（1）卷积核</h3><h4 id="①-卷积核的意义"><a href="#①-卷积核的意义" class="headerlink" title="① 卷积核的意义"></a>① 卷积核的意义</h4><p>存储了当前点和周围点的加权平均的权值<br><img src="/../images/post13_images/568dc1194148738e2a082f16abb95060.png"><br>例如上图，$\frac{1}{9}$其实是需要乘到每个小方格里面的<br>那么以中间的$\frac{1}{9}$为例子，它就是由周围的$9$个$\frac{1}{9}$，加起来后除以$9$，进而得到的</p><h4 id="②-卷积的定义"><a href="#②-卷积的定义" class="headerlink" title="② 卷积的定义"></a>② 卷积的定义</h4><p>假设$f$是图像，$g$是卷积核：<br>$$(f * g)[m,n] = \sum_{k,l} f[m-k, n-l] g[k,l]$$<br>其中：<br>$m,n$是卷积模板最中间位置的坐标<br>$k,l$是翻转后卷积核的坐标，取值范围是$-1,0,1$<br>$g[k,l]$是翻转后的卷积核在(k,l)位置的值<br><strong>我认为需要结合一个例子来解释更清晰：</strong><br><img src="/../images/post13_images/14ea42f0ecee36dbc0b1126671110af8.png"><br><strong>关于卷积核的翻转：</strong><br>老师的PPT中翻转是垂直翻转，但实际上严格的卷积翻转是垂直+水平，也就是中心旋转180°<br>考试中如果提到翻转还是默认以老师PPT中的垂直翻转为准<br>上面的卷积公式，只有在中心旋转时才生效！否则不生效，是错误的！</p><h4 id="③-卷积的理解"><a href="#③-卷积的理解" class="headerlink" title="③ 卷积的理解"></a>③ 卷积的理解</h4><p><img src="/../images/post13_images/388e3a914032945e25299b0fead74271.png"><br>因此卷积做了翻转：<br><img src="/../images/post13_images/d03b2f7a5f086e2005bd71ba1f97fda1.png"></p><h3 id="（2）卷积操作的特性"><a href="#（2）卷积操作的特性" class="headerlink" title="（2）卷积操作的特性"></a>（2）卷积操作的特性</h3><h4 id="①-线性"><a href="#①-线性" class="headerlink" title="① 线性"></a>① 线性</h4><p>$$filter(f_1+f_2)=filter(f_1)+filter(f_2)$$<br>即$f_1,f_2$两张图像先求和在做卷积，等于分别卷积后在求和</p><h4 id="②-平移不变性"><a href="#②-平移不变性" class="headerlink" title="② 平移不变性"></a>② 平移不变性</h4><p>$$filter(shift(f))=shift(filter(f))$$<br>即一张图像先做平移还是先做卷积，结果是一样的<br><strong>推论：任何剪平移不变的操作，都可以用卷积来表示</strong></p><h4 id="③-一些数学特性"><a href="#③-一些数学特性" class="headerlink" title="③ 一些数学特性"></a>③ 一些数学特性</h4><ul><li>交换律：$a<em>b=b</em>a$</li><li>结合律：$a*(b<em>c)=(a</em>b)*c$</li><li>分配律：$a*(b+c)=(a<em>b)+(a</em>c)$</li><li>数乘结合律：$ka<em>b=a</em>kb=k(a*b)$</li><li>对于单位脉冲信号$e=[…,0,0,1,0,0,…]$，有$a*e=a$</li></ul><h3 id="（3）卷积核覆盖与图像大小的关系"><a href="#（3）卷积核覆盖与图像大小的关系" class="headerlink" title="（3）卷积核覆盖与图像大小的关系"></a>（3）卷积核覆盖与图像大小的关系</h3><p>matlab函数中通过指定shape，存在三种覆盖模式<br><img src="/../images/post13_images/95d591d05d9c3616f7dff8fc77150edb.png"></p><ul><li>full：卷积后图像会变大一圈</li><li>same：卷积后图像会保留原始尺寸</li><li>valid：卷积后图像会变小一圈</li></ul><h3 id="（4）卷积边缘填坑问腿"><a href="#（4）卷积边缘填坑问腿" class="headerlink" title="（4）卷积边缘填坑问腿"></a>（4）卷积边缘填坑问腿</h3><p>对于上面的same模式，由于卷积核部分在目标区域外，落在周围那一圈是我们需要填充的，有下面几个填充方法：</p><h4 id="①-Clip-filter（black）"><a href="#①-Clip-filter（black）" class="headerlink" title="① Clip filter（black）"></a>① Clip filter（black）</h4><p>就是常数填充<br>填充一圈黑的，会出现黑边，不太好<br>对应matlab：imfilter(f,g,0)</p><h4 id="②-wrap-around"><a href="#②-wrap-around" class="headerlink" title="② wrap around"></a>② wrap around</h4><p>填充的那一圈是从图像中随机采样的<br>对应matlab：imfilter(f,g,’circular’)</p><h4 id="③-copy-edge"><a href="#③-copy-edge" class="headerlink" title="③ copy edge"></a>③ copy edge</h4><p>填充的那一圈是把边缘继续延伸进去的<br>对应matlab：imfilter(f,g,’replicate’)</p><h4 id="④-reflect-across-edge"><a href="#④-reflect-across-edge" class="headerlink" title="④ reflect across edge"></a>④ reflect across edge</h4><p>填充的那一圈是沿着边缘镜像过去的<br>对应matlab：imfilter(f,g,’symme’)<br><img src="/../images/post13_images/62d3c1650c634c1796e1d32081151dd9.png"></p><h3 id="（5）常见卷积核"><a href="#（5）常见卷积核" class="headerlink" title="（5）常见卷积核"></a>（5）常见卷积核</h3><p><img src="/../images/post13_images/fc38dd0c2eceb75fb338638891a94b4b.png"><br><strong>锐化的原理：</strong><br>模糊/平滑卷积核相当于提取了平滑的特征，原图减去这些平滑的就剩不平滑的部分了，再加回原图相当于加强了。因此一共存在两倍的原图，所以在上面存在一个2<br><img src="/../images/post13_images/c0e3bdc8fc6f8acf17d178aa0a450182.png"><br>$$f*(2e-g)$$<br>同时，可以设置一个$α$在第二步加回去的突出部分前面，从而控制加回去多少细节，进而控制锐化强度，则有：<br>$$f + \alpha (f - f \ast g) = (1 + \alpha)f - \alpha f \ast g = f \ast ((1 + \alpha)e - \alpha g)$$</p><h3 id="（6）卷积核的有效性"><a href="#（6）卷积核的有效性" class="headerlink" title="（6）卷积核的有效性"></a>（6）卷积核的有效性</h3><h4 id="①-动机-1"><a href="#①-动机-1" class="headerlink" title="① 动机"></a>① 动机</h4><ul><li>卷积核通过与图像的像素值进行加权求和，提取特定的特征（如边缘、纹理）或实现滤波效果（如模糊、锐化）。卷积核中每个值的大小决定了对应位置像素的权重，因此可以说卷积核的设计直接影响了每个像素对输出结果的“贡献”。</li><li>想要得到更加有效的卷积模板，则应该考虑图像每个像素的贡献来设计卷积核的每个值，贡献大设计值大，贡献小设计值小。</li><li>因此很容易想到大部分情况下，中心像素对任务贡献最大。因此希望设计卷积核中间值大，越往两边越小。</li></ul><h3 id="②-高斯核-高斯滤波"><a href="#②-高斯核-高斯滤波" class="headerlink" title="② 高斯核/高斯滤波"></a>② 高斯核/高斯滤波</h3><p>$$G_\sigma = \frac{1}{2\pi\sigma^2} e^{-\frac{(x^2 + y^2)}{2\sigma^2}}$$<br>高斯函数就是中间大两头小，非常符合上面我们的想法。</p><h4 id="a-参数-sigma-（方差）"><a href="#a-参数-sigma-（方差）" class="headerlink" title="a. 参数$\sigma$（方差）"></a>a. 参数$\sigma$（方差）</h4><p>固定窗宽看方差变化的影响：</p><ul><li>$\sigma$越大，数据越分散，中心点峰值越小，卷积核中心值越小</li><li>$\sigma$越小，数据越集中，中心点峰值越大，卷积核中心值越大<br><img src="/../images/post13_images/9247199addd60a97673d778010320237.png"><br>因此$\sigma$可以控制平滑程度，形象点说，中心值越大说明对自己有很大的掌控权啊，平滑对我自己的影响就小，中心值小说明我容易丧失自我，就被平滑的很厉害~</li></ul><h4 id="b-窗宽"><a href="#b-窗宽" class="headerlink" title="b. 窗宽"></a>b. 窗宽</h4><p>固定方差看窗宽变化的影响：</p><ul><li>窗宽越小，在归一化时分母越小，每个的权重就越大，平滑程度越大</li><li>窗宽越大，在归一化时分母越大，每个的权重就越小，平滑程度越小<br><img src="/../images/post13_images/f4ba84297588a11164d00d332e4e1a23.png"></li></ul><h4 id="c-现实中如何设置"><a href="#c-现实中如何设置" class="headerlink" title="c. 现实中如何设置"></a>c. 现实中如何设置</h4><p>根据经验值，窗宽的一半=三倍的方差<br>一般在现成的工具包中，指定一个方差，窗宽会自动给出</p><h4 id="d-高斯核的特性"><a href="#d-高斯核的特性" class="headerlink" title="d. 高斯核的特性"></a>d. 高斯核的特性</h4><ul><li>作为低通滤波器，从图像中移除高频信号</li><li><font color="red"><strong>高斯核的自卷积是另一个高斯函数，因此可以用小粒度高斯核的多次卷积，得到使用大粒度高斯核卷积相同的结果。    【重要！】</strong></font><br>![](../images/post13_images/ /8fab1ebe7bf74472049b9536fa518edd.png)<br>图中的 $I$ 表示图像；同时这里符合勾股定理，$a^2+b^2=c^2$</li><li>一个二维的高斯函数可以拆分成两个一维的——<strong>可分离的</strong>函数<br>可分离性的应用：<br><img src="/../images/post13_images/624eb31b695986113315cc50e03817ca.png"><br>就是一个拆分后逐步计算</li></ul><h3 id="（7）卷积的时间复杂度"><a href="#（7）卷积的时间复杂度" class="headerlink" title="（7）卷积的时间复杂度"></a>（7）卷积的时间复杂度</h3><p>$m×m$ 的卷积核 和 $n×n$ 的图像做卷积</p><h4 id="①-一般情况"><a href="#①-一般情况" class="headerlink" title="① 一般情况"></a>① 一般情况</h4><p>$O(n^2m^2)$</p><h4 id="②-卷积核可分离的情况"><a href="#②-卷积核可分离的情况" class="headerlink" title="② 卷积核可分离的情况"></a>② 卷积核可分离的情况</h4><p>$O(n^2m)$</p><h2 id="3-噪声"><a href="#3-噪声" class="headerlink" title="3. 噪声"></a>3. 噪声</h2><h3 id="（1）噪声的种类"><a href="#（1）噪声的种类" class="headerlink" title="（1）噪声的种类"></a>（1）噪声的种类</h3><p><img src="/../images/post13_images/e991f67613e75b26e3acf7f170039324.png"></p><h4 id="①-椒盐噪声（Salt-and-pepper-noise）"><a href="#①-椒盐噪声（Salt-and-pepper-noise）" class="headerlink" title="① 椒盐噪声（Salt and pepper noise）"></a>① 椒盐噪声（Salt and pepper noise）</h4><blockquote><p>像随机在图像上撒了一把“椒盐”，有黑的有白的</p></blockquote><p>随机出现黑白像素</p><h4 id="②-白噪声（Impulse-noise）"><a href="#②-白噪声（Impulse-noise）" class="headerlink" title="② 白噪声（Impulse noise）"></a>② 白噪声（Impulse noise）</h4><p>随机出现白色像素</p><h4 id="③-高斯噪声（Gaussian-noise）"><a href="#③-高斯噪声（Gaussian-noise）" class="headerlink" title="③ 高斯噪声（Gaussian noise）"></a>③ 高斯噪声（Gaussian noise）</h4><p>出现从高斯正态分布得到的强度变化（叠加变量）<br>$$f(x, y) = \hat{f}(x, y) + \eta(x, y)$$<br>其中：</p><ul><li>$f(x, y)$ 是高斯噪声产生后的图像</li><li>$\hat{f}(x, y)$ 是理想状态没有高斯噪声的清晰图像</li><li>$\eta(x, y)$ 是高斯噪声，满足$\eta(x, y)$~$N(μ,σ)$ ，即服从高斯分布</li></ul><h3 id="（2）使用高斯滤波器去除高斯噪声"><a href="#（2）使用高斯滤波器去除高斯噪声" class="headerlink" title="（2）使用高斯滤波器去除高斯噪声"></a>（2）使用高斯滤波器去除高斯噪声</h3><p><img src="/../images/post13_images/0fe237f3052110aab6472db0f277e7bf.png"><br>但上图也可以发现，大方差高斯卷积核虽然更能去除噪声，但也<strong>损失图像细节</strong></p><h3 id="（3）去除椒盐噪声"><a href="#（3）去除椒盐噪声" class="headerlink" title="（3）去除椒盐噪声"></a>（3）去除椒盐噪声</h3><h4 id="①-高斯卷积核效果不佳"><a href="#①-高斯卷积核效果不佳" class="headerlink" title="① 高斯卷积核效果不佳"></a>① 高斯卷积核效果不佳</h4><p>用高斯卷积核去除椒盐噪声<strong>效果不理想</strong>：<br><img src="/../images/post13_images/16fb090613a3e2bbbb402e1384823f38.png"><br>大模板不仅没能更有效去除噪声，反而还损失了不少图像细节</p><h4 id="②-中值滤波的步骤"><a href="#②-中值滤波的步骤" class="headerlink" title="② 中值滤波的步骤"></a>② 中值滤波的步骤</h4><h5 id="a-第一步：生成模板（3×3为例）"><a href="#a-第一步：生成模板（3×3为例）" class="headerlink" title="a. 第一步：生成模板（3×3为例）"></a>a. 第一步：生成模板（3×3为例）</h5><p>单纯一个3×3的框，里面啥也没有</p><h5 id="b-第二步：放到图像中取出像素值"><a href="#b-第二步：放到图像中取出像素值" class="headerlink" title="b. 第二步：放到图像中取出像素值"></a>b. 第二步：放到图像中取出像素值</h5><h5 id="c-第三步：对其中的值找到中位数"><a href="#c-第三步：对其中的值找到中位数" class="headerlink" title="c. 第三步：对其中的值找到中位数"></a>c. 第三步：对其中的值找到中位数</h5><p><img src="/../images/post13_images/a5257af2a6160a141995951348c110d9.png"></p><h5 id="d-第四步：用中位数替代模板最中间的值"><a href="#d-第四步：用中位数替代模板最中间的值" class="headerlink" title="d. 第四步：用中位数替代模板最中间的值"></a>d. 第四步：用中位数替代模板最中间的值</h5><blockquote><p>Q：中值滤波是一个线性操作嘛？<br>A：不是，因为其中核心原理在排序，排序不是线性操作。</p></blockquote><h4 id="③-中值滤波的优点"><a href="#③-中值滤波的优点" class="headerlink" title="③ 中值滤波的优点"></a>③ 中值滤波的优点</h4><h5 id="a-擅长处理椒盐噪声、白噪声"><a href="#a-擅长处理椒盐噪声、白噪声" class="headerlink" title="a. 擅长处理椒盐噪声、白噪声"></a>a. 擅长处理椒盐噪声、白噪声</h5><h5 id="b-和均值滤波相比"><a href="#b-和均值滤波相比" class="headerlink" title="b. 和均值滤波相比"></a>b. 和均值滤波相比</h5><p><img src="/../images/post13_images/d8d32d9613174203f86ed491eacc5e2c.png"></p><h1 id="四、边缘检测"><a href="#四、边缘检测" class="headerlink" title="四、边缘检测"></a>四、边缘检测</h1><h2 id="1-边缘基本概念"><a href="#1-边缘基本概念" class="headerlink" title="1. 边缘基本概念"></a>1. 边缘基本概念</h2><h3 id="（1）边缘的定义"><a href="#（1）边缘的定义" class="headerlink" title="（1）边缘的定义"></a>（1）边缘的定义</h3><p>图像中亮度值明显而急剧变化的点</p><h3 id="（2）研究边缘的意义"><a href="#（2）研究边缘的意义" class="headerlink" title="（2）研究边缘的意义"></a>（2）研究边缘的意义</h3><ul><li>图像中大多数语义和形状信息可在边缘进行编码</li><li>相对于像素表示边缘表示更加紧凑<br>图像→边缘→语义</li></ul><h3 id="（3）边缘的分类"><a href="#（3）边缘的分类" class="headerlink" title="（3）边缘的分类"></a>（3）边缘的分类</h3><ul><li>表面法向不连续</li><li>深度不连续</li><li>表面颜色不连续</li><li>光照不连续<br><img src="/../images/post13_images/79e912ac1a3c00f556e77546261682a9.png"></li></ul><h2 id="2-边缘的提取"><a href="#2-边缘的提取" class="headerlink" title="2. 边缘的提取"></a>2. 边缘的提取</h2><h3 id="（1）思路"><a href="#（1）思路" class="headerlink" title="（1）思路"></a>（1）思路</h3><p>水平方向观察到像素值变化，强度函数求导找到极值点,极值点展示出边缘<br><img src="/../images/post13_images/e914eceb58b435ebfeee3474855e0467.png"></p><h3 id="（2）图像求导"><a href="#（2）图像求导" class="headerlink" title="（2）图像求导"></a>（2）图像求导</h3><h4 id="①-2D函数求导公式"><a href="#①-2D函数求导公式" class="headerlink" title="① 2D函数求导公式"></a>① 2D函数求导公式</h4><p>$$\frac{\partial f(x, y)}{\partial x} = \lim_{\varepsilon \to 0} \frac{f(x + \varepsilon, y) - f(x, y)}{\varepsilon}$$</p><h4 id="②-图像求导公式"><a href="#②-图像求导公式" class="headerlink" title="② 图像求导公式"></a>② 图像求导公式</h4><p>图像是一个一个像素，是离散存储的，并不是上面那样连续的，因此只能取$\epsilon=1$来近似：<br>$$\frac{\partial f(x, y)}{\partial x} \approx \frac{f(x + 1, y) - f(x, y)}{1}$$<br>相当于右边的像素减去自己，就是导数了</p><h4 id="③-用卷积实现图像求导"><a href="#③-用卷积实现图像求导" class="headerlink" title="③ 用卷积实现图像求导"></a>③ 用卷积实现图像求导</h4><p>如图设计卷积核：<br><img src="/../images/post13_images/6572a796ec866d8e5d5d9dc78238fe75.png"><br>正好水平x求导就是右减左，竖直y求导就是下减上</p><h4 id="④-解释对不同方向求导得出垂直方向特征图像的原因【导数模板方向和信号方向是垂直关系】"><a href="#④-解释对不同方向求导得出垂直方向特征图像的原因【导数模板方向和信号方向是垂直关系】" class="headerlink" title="④ 解释对不同方向求导得出垂直方向特征图像的原因【导数模板方向和信号方向是垂直关系】"></a>④ 解释对不同方向求导得出垂直方向特征图像的原因【导数模板方向和信号方向是垂直关系】</h4><p><img src="/../images/post13_images/df18927abab0b64a37451286e6552fef.png"><br>解释：<br>对于x方向，求导相当于水平两个像素做差。</p><ul><li>如果水平的两个像素差异不大，相减就相当于0，什么都没有了，导数为接近0，而前面说了，求导数后导数的极值点展示了边缘，所以没有展示出x方向的边缘。</li><li>如果水平的两个像素差异明显，同理，那么导数就得到了极值点，检测出y方向边缘。<br><img src="/../images/post13_images/1737439c8fe7834b23afa913bcee0064.png"></li></ul><h4 id="⑤-其他常见的导数滤波器（可略）"><a href="#⑤-其他常见的导数滤波器（可略）" class="headerlink" title="⑤ 其他常见的导数滤波器（可略）"></a>⑤ 其他常见的导数滤波器（可略）</h4><h5 id="a-简介"><a href="#a-简介" class="headerlink" title="a. 简介"></a>a. 简介</h5><p><img src="/../images/post13_images/65375152be328c5234f7125884569718.png"></p><ul><li>Prewitt：利用像素点上下、左右邻点的灰度差。这种判定是欠合理的，会造成边缘点的误判，因为许多噪声点的灰度值也很大，而且对于幅值较小的边缘点，其边缘反而丢失了。</li><li>Sobel：Sobel 算子在 Prewitt 算子的基础上增加了权重的概念，认为相邻点的距离远近对当前像素点的影响是不同的，距离越近的像素点对应当前像素的影响越大，从而实现图像锐化并突出边缘轮廓。</li><li>Roberts：交叉算子边缘检测方法。该方法最大优点是计算量小，速度快。但该方法由于是采用偶数模板，如下图所示，所求的(x,y)点处梯度幅度值，其实是图中交叉点处的值，从而导致在图像(x,y)点所求的梯度幅度值偏移了半个像素<br><img src="/../images/post13_images/eb7ca1698d2d9d3e6c8711df862ff915.png"></li></ul><h5 id="b-总结"><a href="#b-总结" class="headerlink" title="b. 总结"></a>b. 总结</h5><ul><li>Robert算子对陡峭的低噪声图像效果较好，尤其是边缘正负45度较多的图像，但定位准确率较差；</li><li>Prewitt算子对灰度渐变的图像边缘提取效果较好，而没有考虑相邻点的距离远近对当前像素点的影响；</li><li>Sobel算子考虑了综合因素，对噪声较多的图像处理效果更好。<br><img src="/../images/post13_images/ac18a383e7c30fcc5fbd95d400953594.png"></li></ul><h3 id="（3）图像梯度"><a href="#（3）图像梯度" class="headerlink" title="（3）图像梯度"></a>（3）图像梯度</h3><p><img src="/../images/post13_images/2b94b200b979f35581cd0088d4e151cc.png"></p><h2 id="3-噪声对边缘的影响"><a href="#3-噪声对边缘的影响" class="headerlink" title="3. 噪声对边缘的影响"></a>3. 噪声对边缘的影响</h2><h3 id="（1）影响"><a href="#（1）影响" class="headerlink" title="（1）影响"></a>（1）影响</h3><p>存在影响：<br><img src="/../images/post13_images/acd89619e493294306a1eab8978d5bf2.png"></p><h3 id="（2）原因"><a href="#（2）原因" class="headerlink" title="（2）原因"></a>（2）原因</h3><p><img src="/../images/post13_images/cbe2af545dc0f863efb03fd44e18065d.png"><br>由于噪声的存在，找不到极值点了</p><h3 id="（3）解决"><a href="#（3）解决" class="headerlink" title="（3）解决"></a>（3）解决</h3><h4 id="①-流程"><a href="#①-流程" class="headerlink" title="① 流程"></a>① 流程</h4><p>先去噪，再对信号求导，找到极值点<br><img src="/../images/post13_images/c44f26b9647acdf319383576ed77e1c4.png"></p><h4 id="②-弊端"><a href="#②-弊端" class="headerlink" title="② 弊端"></a>② 弊端</h4><p>存在两次卷积，一次是去噪时卷积（$f<em>g$），另一次是求偏导时用导数模板做卷积求出偏导数，即上图红框的部分的求导过程。<br>当图像数量多的时候，由于存在两次卷积，*<em>计算量大</em></em></p><h4 id="③-弊端的进一步解决"><a href="#③-弊端的进一步解决" class="headerlink" title="③ 弊端的进一步解决"></a>③ 弊端的进一步解决</h4><p>利用卷积的结合性：$\frac{d}{dx}(f * g) = f * \frac{d}{dx}g$<br>也就是：</p><ul><li>先对高斯核进行求导——得到 <font color="red"><strong>高斯一阶偏导核</strong></font></li><li>再利用求导后的高斯核来和原始的有噪声的图像做卷积<br><img src="/../images/post13_images/cfb1ae26fc3bf2c26ae1a7775a9db82b.png"></li></ul><h4 id="④-高斯一阶偏导核"><a href="#④-高斯一阶偏导核" class="headerlink" title="④ 高斯一阶偏导核"></a>④ 高斯一阶偏导核</h4><h5 id="a-可视化"><a href="#a-可视化" class="headerlink" title="a. 可视化"></a>a. 可视化</h5><p>看一下就行：<br><img src="/../images/post13_images/8b49e7eb0501dc0bdd18435f85d255b2.png"></p><h5 id="b-方差的影响"><a href="#b-方差的影响" class="headerlink" title="b. 方差的影响"></a>b. 方差的影响</h5><p>随高斯一阶偏导核方差变大，图像细节的丢失也会越来越严重</p><blockquote><p>实际应用中，如果要识别细微的边缘特征，肯定方差设置小一点会好些；但如果只是想粗糙识别一下，比如看远方的一个物体是不是人，那方差设置大一点会好些，保留了轮廓信息<br>【就是看我们需要的轮廓是粗糙的还是细微的】</p></blockquote><h5 id="c-可分离性证明"><a href="#c-可分离性证明" class="headerlink" title="c. 可分离性证明"></a>c. 可分离性证明</h5><p><img src="/../images/post13_images/fa68aa6e8847a0a41ab9a8c7cc24cdb4.png"></p><h5 id="d-高斯核-vs-高斯一阶偏导核"><a href="#d-高斯核-vs-高斯一阶偏导核" class="headerlink" title="d. 高斯核 vs 高斯一阶偏导核"></a>d. 高斯核 vs 高斯一阶偏导核</h5><p>总结对比一下：<br><img src="/../images/post13_images/35ce0e86b652578d02f876c32b2cbf13.png"></p><h2 id="4-Canny边缘检测器"><a href="#4-Canny边缘检测器" class="headerlink" title="4. Canny边缘检测器"></a>4. Canny边缘检测器</h2><blockquote><p>这部分智慧课堂无声，本人参考<a href="https://blog.csdn.net/weixin_42118657/article/details/121255328">CS131专题-3：图像梯度、边缘检测（sobel、canny等）</a>进行学习，感谢这篇博客。这篇博客恰好对应本章所有内容，相较课内更为详细，推荐学习。</p></blockquote><h3 id="（1）提出动机"><a href="#（1）提出动机" class="headerlink" title="（1）提出动机"></a>（1）提出动机</h3><p>常规边缘检测算法存在以下问题：</p><ul><li>边缘很粗：如sobel这样的边缘检测算子，对图像求梯度图后，会设置一个阈值，绝对值超过阈值的像素为视为边缘，这就导致得到的边缘图中“边缘”会很粗<br><img src="/../images/post13_images/08e2185d3cd2fe3a0f0481b1b8bd8592.png"></li><li>渐变边低于阈值，无法被识别为边缘：由于sobel中梯度阈值是全局性的，不能太高也不能太低，这就导致很多不明显的渐变边被擦除。<br><img src="/../images/post13_images/36f9d48a22cde65528e3c8269167be76.png"></li></ul><h3 id="（2）Canny边缘检测器算法流程"><a href="#（2）Canny边缘检测器算法流程" class="headerlink" title="（2）Canny边缘检测器算法流程"></a>（2）Canny边缘检测器算法流程</h3><p>matlab：edge(image,’canny’)</p><h4 id="①-对原始图像进行灰度化"><a href="#①-对原始图像进行灰度化" class="headerlink" title="① 对原始图像进行灰度化"></a>① 对原始图像进行灰度化</h4><p>此步课内PPT未提及，但是要进行的。因为边缘检测本质检测的是亮度变化。</p><h4 id="②-对图像进行平滑（高斯滤波）"><a href="#②-对图像进行平滑（高斯滤波）" class="headerlink" title="② 对图像进行平滑（高斯滤波）"></a>② 对图像进行平滑（高斯滤波）</h4><p>用高斯导数对图像进行滤波：对图像的x方向和y方向求梯度</p><h4 id="③-求图像平滑后的梯度图、以及梯度方向图"><a href="#③-求图像平滑后的梯度图、以及梯度方向图" class="headerlink" title="③ 求图像平滑后的梯度图、以及梯度方向图"></a>③ 求图像平滑后的梯度图、以及梯度方向图</h4><p>计算梯度强度（衡量是否为边缘）和梯度方向（用于非极大值抑制）</p><h4 id="④-NMS非极大值抑制筛选"><a href="#④-NMS非极大值抑制筛选" class="headerlink" title="④ NMS非极大值抑制筛选"></a>④ NMS非极大值抑制筛选</h4><p>顾名思义就是在附近的一堆值中找到最大的那个，然后把不是最大的都设0<br><img src="/../images/post13_images/21c5b2245b44a323e4d37f36f74559c1.png"><br>对比一下非极大值抑制的效果，明显变细了：<br><img src="/../images/post13_images/7c66d41c3bbadfe147ef53b64c9ca5fd.png"></p><h4 id="⑤-双阈值-连通与否筛选"><a href="#⑤-双阈值-连通与否筛选" class="headerlink" title="⑤ 双阈值+连通与否筛选"></a>⑤ 双阈值+连通与否筛选</h4><p>双门限法：定义两个阈值</p><ul><li>高阈值：检测强边缘</li><li>低阈值：连接强边缘<br><img src="/../images/post13_images/51bf3feebbd7360d9977231cade81e4e.png"><br>简单来说就是高于高的就是边缘，低于低的就不是边缘，在中间的看有没有穿过高阈值的部分</li></ul><h4 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h4><ul><li>在②③两部分，实际中会采取之前说的先得到高斯一阶偏导核，再做卷积~</li><li>高斯核的方差$\sigma$越大，对图像平滑效果越强，越容易把边缘平滑掉，边缘会稀疏（仅保留非常明显的边缘）；反之，边缘会密集、详细。因此可控制方差大小获得想要的边缘图。</li><li>Canny边缘检测的一些缺点：边缘可能不连续、边缘位置可能出现空间偏移（偏离真实边界）、方差的变化会明显改变结果，鲁棒性差。<br><img src="/../images/post13_images/9621d8a62d6e10bd05ccb16856a1c0f9.png"></li></ul><h2 id="5-其他边缘检测技术（缺）"><a href="#5-其他边缘检测技术（缺）" class="headerlink" title="5. 其他边缘检测技术（缺）"></a>5. 其他边缘检测技术（缺）</h2><blockquote><p>因为视频没声，PPT这部分也看不出来是想说啥细节，所以只能略过喽</p></blockquote><ul><li>CNN 边缘检测模型</li><li>用Transformer做边缘检测</li><li>语义边缘检测</li><li>遮挡边缘检测</li></ul><h1 id="五、拟合（Fitting）"><a href="#五、拟合（Fitting）" class="headerlink" title="五、拟合（Fitting）"></a>五、拟合（Fitting）</h1><blockquote><p>边缘检测出的边缘是一个底层的特征 low-level<br><strong>从边缘图中，通过拟合技术，进一步提取需要的几何边缘</strong></p></blockquote><h2 id="1-拟合的基本概念"><a href="#1-拟合的基本概念" class="headerlink" title="1. 拟合的基本概念"></a>1. 拟合的基本概念</h2><h3 id="（1）目标"><a href="#（1）目标" class="headerlink" title="（1）目标"></a>（1）目标</h3><p>找到一个参数化的模型，来表示特征</p><h3 id="（2）难点-需要解决的问题"><a href="#（2）难点-需要解决的问题" class="headerlink" title="（2）难点/需要解决的问题"></a>（2）难点/需要解决的问题</h3><p><img src="/../images/post13_images/b747884957bd4465dc44a6d937e56064.png"></p><ul><li>噪声：图像以及预处理会存在各种噪声，影响拟合</li><li>外点/无关点：比如我只想找车上的几何形状，那么车之外的像素点都是无关点，这些点会影响程序自动化寻找车的形状</li><li>缺失数据——遮挡：由于遮挡关系，几何形状可能是间断的。比如想检测车后面房子的窗户的形状，结果由于车在前面，被挡住了。</li></ul><h2 id="2-拟合的常见方法"><a href="#2-拟合的常见方法" class="headerlink" title="2. 拟合的常见方法"></a>2. 拟合的常见方法</h2><h3 id="（1）最小二乘法（Least-squres-line-fitting）"><a href="#（1）最小二乘法（Least-squres-line-fitting）" class="headerlink" title="（1）最小二乘法（Least squres line fitting）"></a>（1）最小二乘法（Least squres line fitting）</h3><h4 id="①-原理"><a href="#①-原理" class="headerlink" title="① 原理"></a>① 原理</h4><h5 id="a-确定目标函数"><a href="#a-确定目标函数" class="headerlink" title="a. 确定目标函数"></a>a. 确定目标函数</h5><p><img src="/../images/post13_images/8a0b4e595d6d4a8e4c73235739c1ba8b.png"></p><h5 id="b-最小化目标函数"><a href="#b-最小化目标函数" class="headerlink" title="b. 最小化目标函数"></a>b. 最小化目标函数</h5><p>利用$|\mathbf{P}|^2 = P_1^2 + P_2^2 + \cdots + P_n^2=\mathbf{P}^T\mathbf{P}$<br><img src="/../images/post13_images/7f0ccb8dc1b03b50228562fab8271ed3.png"><br>最终得到了最优直线对应的m和b（B矩阵）</p><h4 id="②-缺陷"><a href="#②-缺陷" class="headerlink" title="② 缺陷"></a>② 缺陷</h4><p><img src="/../images/post13_images/29550c26cb37aba9aecf8f0973a3ee93.png"><br>所以缺陷就是没办法解决垂直线，因为它不是旋转不变的，只要发生旋转了，就解决不好问题了</p><h3 id="（2）全最小二乘法（Total-least-squares）"><a href="#（2）全最小二乘法（Total-least-squares）" class="headerlink" title="（2）全最小二乘法（Total least squares）"></a>（2）全最小二乘法（Total least squares）</h3><h4 id="①-原理-1"><a href="#①-原理-1" class="headerlink" title="① 原理"></a>① 原理</h4><p>本质上就是将计算的距离从竖直方向距离改为点到直线的距离<br>最优化的参数从两个（m，b）变为三个（a，b，d）<br><img src="/../images/post13_images/8e61f7f2d99b3bc1a05ade96d02e46fa.png"><br><img src="/../images/post13_images/bfafdc9629a990839758aa3ee221d0fa.png"><br>其中从对d求导到得到d的a、b表示：<br>$$\sum_{i=1}^{n} (-2ax_i - 2by_i + 2d) = 0$$<br>$$d=\sum_{i=1}^{n}(ax_i+by_i)$$<br>$$d = \frac{a}{n} \sum_{i=1}^{n} x_i + \frac{b}{n} \sum_{i=1}^{n} y_i = a \bar{x} + b \bar{y}$$<br>以及其中矩阵U：<br><img src="/../images/post13_images/1dbdcf11de1c89a201662a0f212000bc.png"></p><h4 id="②-优缺点"><a href="#②-优缺点" class="headerlink" title="② 优缺点"></a>② 优缺点</h4><ul><li>优点：相较于最小二乘，具有旋转不变性</li><li>缺点：不能很好地对抗噪声点<br><img src="/../images/post13_images/b1da2f3b0ccee2fdec55f5054d6107b6.png"></li></ul><h4 id="③-从概率角度理解全最小二乘"><a href="#③-从概率角度理解全最小二乘" class="headerlink" title="③ 从概率角度理解全最小二乘"></a>③ 从概率角度理解全最小二乘</h4><blockquote><p>感觉不是很重要，但是PPT讲了，就附带一下吧<br>也就是最小二乘法与极大似然估计之间的内在联系</p></blockquote><p><strong>假设：</strong><br>存在一条理想直线（最终的拟合直线）$ax+by=d$，法向量$\mathbf{n}=(a,b)$，直线上真实点坐标为$(u,v)$，但观测点$(x,y)$受到垂直于直线方向的噪声干扰。<br><strong>观测点的表示：</strong><br>$$(x, y) = (u, v) + \varepsilon \cdot \frac{(a, b)}{\sqrt{a^2 + b^2}}$$<br>其中$ε$是噪声幅值，服从均值为0、标准差为$σ$的高斯分布<br><strong>单点概率密度：</strong><br>给定直线参数 $(a,b,d)$，观测点$(x_i,y_i)$的噪声服从高斯分布，由于理想点$(u,v)$满足$au+bv=d$，垂直距离$\varepsilon = \frac{|ax_i + by_i - d|}{\sqrt{a^2 + b^2}}$，结合高斯分布公式，化简得到观测点$(x_i,y_i)$的概率密度为：<br>$$P(x_i, y_i \mid a, b, d) \propto \exp \left( -\frac{(ax_i + by_i - d)^2}{2\sigma^2} \right)$$<br><strong>似然函数：</strong><br>假设所有观测点独立同分布，联合似然函数为各点概率的乘积：<br>$$\mathcal{L}(a, b, d) = \prod_{i=1}^{n} \exp \left( -\frac{(ax_i + by_i - d)^2}{2\sigma^2} \right)$$<br><strong>对数似然函数：</strong><br>$$\ln \mathcal{L}(a, b, d) = -\frac{1}{2\sigma^2} \sum_{i=1}^{n} (ax_i + by_i - d)^2$$<br><strong>最大化似然函数相当于：</strong><br>$$\max_{a,b,d} -\sum_{i=1}^{n} (ax_i + by_i - d)^2$$<br><strong>等价于全最小二乘的目标：</strong><br>$$\min_{a,b,d} \sum_{i=1}^{n} (ax_i + by_i - d)^2$$</p><h3 id="（3）鲁棒最小二乘法"><a href="#（3）鲁棒最小二乘法" class="headerlink" title="（3）鲁棒最小二乘法"></a>（3）鲁棒最小二乘法</h3><h4 id="①-原理-2"><a href="#①-原理-2" class="headerlink" title="① 原理"></a>① 原理</h4><p>根据点的残差来差异化特征贡献，也就是离得近的贡献大，离得远的贡献小<br><strong>找到最优参数 $\theta$ 最小化目标损失函数：</strong><br>$$\sum_{i} \rho(r_i(x_i, \theta); \sigma)=\sum_{i} \rho(u;\sigma)=\sum_{i} \frac{u^2}{\sigma^2+u^2}$$<br>其中：</p><ul><li>$u=r_i(x_i,θ)$是第 $i$ 个数据点的残差（模型预测值与真实值的偏差）</li><li>$σ$ 是尺度参数，控制函数从“类平方”到“饱和”的转折点。$σ$  越小，函数越早进入饱和区，模型对离群点更鲁棒；$σ$  越大，饱和区延迟，模型更接近传统最小二乘。<br><img src="/../images/post13_images/1f420d0acb628860ab3da05239d329c4.png"><br>如上图，横坐标是残差 $u$ ，纵坐标是对应的响应（贡献）$\rho$，三条曲线分别展现了不同 $σ$ 大小带来的影响。</li></ul><h4 id="②-特点"><a href="#②-特点" class="headerlink" title="② 特点"></a>② 特点</h4><ul><li>非线性优化过程，经过了一个非线性的变换</li><li>可以先用全最小二乘初始化初始解，再用梯度下降方法取求最优解</li><li>受 $\sigma$ 大小的影响很大，一般选择1.5倍的平均残差</li></ul><h4 id="③-优缺点"><a href="#③-优缺点" class="headerlink" title="③ 优缺点"></a>③ 优缺点</h4><ul><li>优点：对外点具有鲁棒性</li><li>缺点：依赖于 $σ$ 的取值，取大取小都不好；如果外点数变多，表现可能也不是那么好了<br><img src="/../images/post13_images/c921a13f321cab84bb954899c455f683.png"></li></ul><h3 id="（4）随机采样一致性算法RANSAC"><a href="#（4）随机采样一致性算法RANSAC" class="headerlink" title="（4）随机采样一致性算法RANSAC"></a>（4）随机采样一致性算法RANSAC</h3><blockquote><p>如果有很多外点，鲁棒最小二乘可能也不好用了<br>RANSAC：Random sample consensus</p></blockquote><h4 id="①-原理流程（以直线为例）"><a href="#①-原理流程（以直线为例）" class="headerlink" title="① 原理流程（以直线为例）"></a>① 原理流程（以直线为例）</h4><h5 id="a-随机从所有点中选择所需的最少的样本点（如估计一条直线方程需要两个点，其他模型可能不一样）"><a href="#a-随机从所有点中选择所需的最少的样本点（如估计一条直线方程需要两个点，其他模型可能不一样）" class="headerlink" title="a. 随机从所有点中选择所需的最少的样本点（如估计一条直线方程需要两个点，其他模型可能不一样）"></a>a. 随机从所有点中选择所需的最少的样本点（如估计一条直线方程需要两个点，其他模型可能不一样）</h5><h5 id="b-拟合出一条直线"><a href="#b-拟合出一条直线" class="headerlink" title="b. 拟合出一条直线"></a>b. 拟合出一条直线</h5><h5 id="c-计算每个点到该直线的距离，并设置一个距离的阈值-门限"><a href="#c-计算每个点到该直线的距离，并设置一个距离的阈值-门限" class="headerlink" title="c. 计算每个点到该直线的距离，并设置一个距离的阈值/门限"></a>c. 计算每个点到该直线的距离，并设置一个距离的阈值/门限</h5><h5 id="d-记录落在阈值-门限范围内的点的数量（内点数量），作为投票得分"><a href="#d-记录落在阈值-门限范围内的点的数量（内点数量），作为投票得分" class="headerlink" title="d. 记录落在阈值/门限范围内的点的数量（内点数量），作为投票得分"></a>d. 记录落在阈值/门限范围内的点的数量（内点数量），作为投票得分</h5><h5 id="e-重复abcd这四步若干次"><a href="#e-重复abcd这四步若干次" class="headerlink" title="e. 重复abcd这四步若干次"></a>e. 重复abcd这四步若干次</h5><h5 id="f-跳出迭代后，选用内点最多（投票得分最高）的拟合结果"><a href="#f-跳出迭代后，选用内点最多（投票得分最高）的拟合结果" class="headerlink" title="f. 跳出迭代后，选用内点最多（投票得分最高）的拟合结果"></a>f. 跳出迭代后，选用内点最多（投票得分最高）的拟合结果</h5><p><img src="/../images/post13_images/1d04e12fa76de326f80a0f8c6c106bfc.png"></p><h4 id="②-参数设置"><a href="#②-参数设置" class="headerlink" title="② 参数设置"></a>② 参数设置</h4><h5 id="a-初始化样本点数-s"><a href="#a-初始化样本点数-s" class="headerlink" title="a. 初始化样本点数 s"></a>a. 初始化样本点数 s</h5><p>这个是跟任务相关的，直线最少需要俩点，其他模型可能更多</p><h5 id="b-门限-阈值-t"><a href="#b-门限-阈值-t" class="headerlink" title="b. 门限/阈值 t"></a>b. 门限/阈值 t</h5><h5 id="c-迭代次数-N"><a href="#c-迭代次数-N" class="headerlink" title="c. 迭代次数 N"></a>c. 迭代次数 N</h5><blockquote><p>迭代多少次才结束呢？需要选取一个合适的迭代次数</p></blockquote><h6 id="i-基本原理"><a href="#i-基本原理" class="headerlink" title="i. 基本原理"></a>i. 基本原理</h6><p>先设置两个概率：</p><ul><li><strong>最优概率 $p$：</strong> 只要这个拟合结果有 $p$ 的概率能够准确检测所有样本点的，那么久接受它，不去继续找了</li><li><strong>外点概率 $e$：</strong> 某个点不属于拟合结果的概率是 $e$</li></ul><p>然后进行下面的理解：</p><ul><li>最终拟合直线的准确率是 $p$</li><li>最终拟合直线预测错误的概率是 $1-p$</li><li>外点的概率是 $e$</li><li>内点的概率是 $1-e$</li><li>对于某一次迭代，最开始选了 $s$ 个点做初始化，内点的概率是 $(1-e)^s$</li><li>对于某一次迭代，最开始选了 $s$ 个点做初始化，外点的概率是 $1-(1-e)^s$</li><li>对于总共 $N$ 次迭代，外点的概率是 $(1-(1-e)^s)^N$</li></ul><p>对于理想的拟合直线，它已经是由很多内点投票出来的直线了，它对于这些内点，就相当于是可以预测/检测成功的；那相对应的，如果遇到外点了，那可不就是会预测错误嘛<br>所以：<br>$$1-(1-e)^s=1-p$$<br>满足上式的 $N$ 就是我们想要的，反解出来：<br>$$N=log(1-p)/log(1-(1-e)^s)$$ </p><h6 id="ii-自适应算法"><a href="#ii-自适应算法" class="headerlink" title="ii. 自适应算法"></a>ii. 自适应算法</h6><blockquote><p>实际的外点概率 $e$ 经常是未知的，如果外点特别多的话，$N$ 会非常大，也不利于计算</p></blockquote><p>步骤如下：<br>$N=∞,smaple_count=0$<br>While $N&gt;sample_count$ :<br>  选择一个样本并计算内点率 $1-e$（就是正常拟合后算出来阈值内的内点数，然后算个占比）；<br>  进一步计算出外点率 $e$ （就是1-内点率）<br>  根据 $N=log(1-p)/log(1-(1-e)^s)$ 更新 $N$<br>  $sample_count$++</p><p>【其实通过分析公式，可以看出 $e\propto N$，所以上面的自适应算法由于动态计算 $e$，就实现了动态调整 $N$】</p><h5 id="d-一致性-d"><a href="#d-一致性-d" class="headerlink" title="d. 一致性 d"></a>d. 一致性 d</h5><p>比如对于总共有100个点，我们可以设置d=50，迭代结束后：</p><ul><li>如果所有拟合结果的内点数（投票得分）都没到50，最终给出投票数最高的那个就行</li><li>如果有多个都到了50，除了最高的以外，这些高于50的也给出来，输出多条直线。<br>【因此可以通过设置d来控制结果要多条直线还是单条直线】</li></ul><h4 id="③-优缺点-1"><a href="#③-优缺点-1" class="headerlink" title="③ 优缺点"></a>③ 优缺点</h4><h5 id="a-优点"><a href="#a-优点" class="headerlink" title="a. 优点"></a>a. 优点</h5><ul><li>简单、通用</li><li>适用于许多不同问题</li><li>在实践中效果通常不错</li></ul><h5 id="b-缺点"><a href="#b-缺点" class="headerlink" title="b. 缺点"></a>b. 缺点</h5><ul><li>需要调整的参数很多</li><li>内点数比较低（外点数比较多）的时候，迭代次数太多</li><li>初始化不稳定，比如如果第一次外点数就爆多，那很坏了；<br>但是如果第一次内点数爆多，那说不定很快就解决了；<br>所以这初始化挺不稳定的</li></ul><h4 id="④-补充"><a href="#④-补充" class="headerlink" title="④ 补充"></a>④ 补充</h4><ul><li><strong>还是建议记忆一下 <font color="red">$e\propto N$</font></strong></li><li>真实应用时，其实需要针对特定问题和情况做更多改进，比如RANSAC最终得到最好的一根线，其实再用最小二乘去拟合这根线周围的点，得到的新直线会更好（<strong>细化</strong>）</li><li>RANSAC的一个实际应用的抽象示例——指纹匹配<br><img src="/../images/post13_images/6e8726c3c30421b22707a24a3d14a37a.png"></li></ul><h3 id="（5）霍夫变换"><a href="#（5）霍夫变换" class="headerlink" title="（5）霍夫变换"></a>（5）霍夫变换</h3><h4 id="①-引入——RANSAC无法解决的一些问题"><a href="#①-引入——RANSAC无法解决的一些问题" class="headerlink" title="① 引入——RANSAC无法解决的一些问题"></a>① 引入——RANSAC无法解决的一些问题</h4><p>如果只想检测下图的绿色直线，那么其他直线都是外点，外电太多了，RANSAC计算量爆炸，效果也受影响。<strong>RANSAC不好解决图像中存在大量线的情况</strong><br><img src="/../images/post13_images/3a81fcd271fa745accdb6f8887f7006f.png"></p><h4 id="②-霍夫变换需要满足的投票方案"><a href="#②-霍夫变换需要满足的投票方案" class="headerlink" title="② 霍夫变换需要满足的投票方案"></a>② 霍夫变换需要满足的投票方案</h4><h5 id="a-让每个特征为所有与其兼容的模型投票"><a href="#a-让每个特征为所有与其兼容的模型投票" class="headerlink" title="a. 让每个特征为所有与其兼容的模型投票"></a>a. 让每个特征为所有与其兼容的模型投票</h5><p>也就是说，对于一个点，谁能检测到它，它就给谁投票。都各自投完，最后选的模型依然是分数最高的那个。</p><h5 id="b-噪声点不可以一直为同一个模型投票。"><a href="#b-噪声点不可以一直为同一个模型投票。" class="headerlink" title="b, 噪声点不可以一直为同一个模型投票。"></a>b, 噪声点不可以一直为同一个模型投票。</h5><p>不能所有噪声点都投给一个模型，噪声本就是随机产生的，咋可能都投给一个模型，那根本没随机性，不能叫噪声了欸。</p><h5 id="c-只要足够多特征同意一个模型，缺失数据也并不重要（但也不能太多）"><a href="#c-只要足够多特征同意一个模型，缺失数据也并不重要（但也不能太多）" class="headerlink" title="c. 只要足够多特征同意一个模型，缺失数据也并不重要（但也不能太多）"></a>c. 只要足够多特征同意一个模型，缺失数据也并不重要（但也不能太多）</h5><p>只要得分高，有遮挡也无所谓，反正其他大部分特征都选择它了。正因如此，霍夫变换也可以解决遮挡问题。但遮挡的也不能太多，如果几乎全遮挡，剩下零散几个点也没办法确定目标的模型。</p><h4 id="③-霍夫变换的原理"><a href="#③-霍夫变换的原理" class="headerlink" title="③ 霍夫变换的原理"></a>③ 霍夫变换的原理</h4><p><img src="/../images/post13_images/73a276a70d3af4ce88629ea963d06206.png"><br>于是可以绘制出图像空间和参数空间：<br><img src="/../images/post13_images/0aaeea182babc24186d567abe68bc9a8.png"><br>当情况逐渐复杂：<br><img src="/../images/post13_images/f6810b84cc3184fbee66a1003a7ccf0d.png"></p><h4 id="④-霍夫变换的流程"><a href="#④-霍夫变换的流程" class="headerlink" title="④ 霍夫变换的流程"></a>④ 霍夫变换的流程</h4><p><img src="/../images/post13_images/deb7336fceb50058fd2b811c683e9870.png"><br>如果图像空间有其他的直线，那么在参数空间就会出现其他的极大值，这个可以在下面的例子中看到</p><h4 id="⑤-霍夫变换的检测示例（数学模型上）"><a href="#⑤-霍夫变换的检测示例（数学模型上）" class="headerlink" title="⑤ 霍夫变换的检测示例（数学模型上）"></a>⑤ 霍夫变换的检测示例（数学模型上）</h4><p>最简单的情况：<br><img src="/../images/post13_images/413ab608f19a4413d795686036913ca1.png"><br>稍微复杂的情况，多个点—多个拟合结果—多个局部极大值<br><img src="/../images/post13_images/d69554353046db95943f5d7c728dddd4.png"><br>多条线的情况，每条线一个局部最大值：<br><img src="/../images/post13_images/74fe3a9fd6abcbbb9455bab62e1927d2.png"></p><h4 id="⑥-传统霍夫变换的局限性"><a href="#⑥-传统霍夫变换的局限性" class="headerlink" title="⑥ 传统霍夫变换的局限性"></a>⑥ 传统霍夫变换的局限性</h4><p>对于垂直的线，没斜率，没法对应到参数空间：<br><img src="/../images/post13_images/ff5219d5c8e202fdd903a5155ee2d30a.png"><br>如果累加器设置的太小，那可能没包含我们涉及到的点；<br>如果累加器设置的太大，那就需要遍历所有斜率，对内存和计算能力要求太高</p><h4 id="⑦-改进：极坐标系下的霍夫变换"><a href="#⑦-改进：极坐标系下的霍夫变换" class="headerlink" title="⑦ 改进：极坐标系下的霍夫变换"></a>⑦ 改进：极坐标系下的霍夫变换</h4><h5 id="a-原理"><a href="#a-原理" class="headerlink" title="a. 原理"></a>a. 原理</h5><p>改用极坐标系，用 $\theta$ 表示方向，用 $\rho$ 表示原点到直线的距离<br><img src="/../images/post13_images/db86958451d8208354668ba5c98d5f3f.png"><br>$\theta$ 的范围显而易见；$\rho$ 的范围是因为图像有边界，最大也就是图像对角线的距离<br><img src="/../images/post13_images/a73152d8655be88123d56f1b5e60c04a.png"><br>同样可以找到局部极大值</p><h5 id="b-步骤"><a href="#b-步骤" class="headerlink" title="b. 步骤"></a>b. 步骤</h5><p><img src="/../images/post13_images/03c09fc27da03cd8ef998193bb14cf33.png"></p><h5 id="c-优点"><a href="#c-优点" class="headerlink" title="c. 优点"></a>c. 优点</h5><p>如上图，$\theta$ 有范围，可以遍历表示垂直的直线</p><h5 id="d-进一步改进提升效率"><a href="#d-进一步改进提升效率" class="headerlink" title="d. 进一步改进提升效率"></a>d. 进一步改进提升效率</h5><p>上图橙色问题是想表明，<strong>对于每个角度都遍历，计算量有点大，咋办</strong><br>解决方案：<br>可以先用边缘检测，拿到最大梯度方向，而边缘方向和梯度方向是垂直关系，则可以在这个方向（角度）进行极坐标霍夫变换。同时，也可以根据这个角度来设置一个小的范围，更加严谨地进行遍历~<br><img src="/../images/post13_images/e41a2804bca67c301a8d0eae86cf1d4b.png"></p><h4 id="⑧-霍夫变换的实例效果（实际任务上）"><a href="#⑧-霍夫变换的实例效果（实际任务上）" class="headerlink" title="⑧ 霍夫变换的实例效果（实际任务上）"></a>⑧ 霍夫变换的实例效果（实际任务上）</h4><p><img src="/../images/post13_images/8f2c5bfb1a134fcd703f2dcdcc9986d3.png"></p><h4 id="⑨-霍夫变换的影响因素与解决"><a href="#⑨-霍夫变换的影响因素与解决" class="headerlink" title="⑨ 霍夫变换的影响因素与解决"></a>⑨ 霍夫变换的影响因素与解决</h4><h5 id="a-（自身）噪声的影响"><a href="#a-（自身）噪声的影响" class="headerlink" title="a. （自身）噪声的影响"></a>a. （自身）噪声的影响</h5><h6 id="i-影响"><a href="#i-影响" class="headerlink" title="i. 影响"></a>i. 影响</h6><p>一个例子：<br><img src="/../images/post13_images/bb0610b62968e544667895a56112a01d.png"><br>噪声大小和投票数最大值的关系图（以20个点的图为例）：<br><img src="/../images/post13_images/e057758a1640889701a9e56c35be08b5.png"><br>可以看出噪声越大，票数峰值越小，对投票的影响越大<br>即<strong>噪声越大，霍夫变换性能越差</strong></p><h5 id="b-（外部噪声）随机点的影响"><a href="#b-（外部噪声）随机点的影响" class="headerlink" title="b. （外部噪声）随机点的影响"></a>b. （外部噪声）随机点的影响</h5><blockquote><p>随机点是外部随机生成的噪声点，和刚才那个自身的噪声不一样，这个是外部随机出现在图像中的随机点。<strong>一个是自身的，一个是外部的。</strong></p></blockquote><p>一个例子：<br><img src="/../images/post13_images/421b9dca92ab9934ff7aa706fc41e70b.png"><br>随着随机点噪声的增大，越有可能出现虚假峰值（伪峰值），也就是由这些随机噪声点投票出来了一个结果，而不是我们本来的数据。<br><img src="/../images/post13_images/630f60c8c6e351c3f5d841417a020aaf.png"><br>如上图所示，随机点越多，伪峰值越可能出现。</p><h5 id="c-解决"><a href="#c-解决" class="headerlink" title="c. 解决"></a>c. 解决</h5><ul><li>方法1：在对参数空间进行离散化时，选取一个合适大小的网格<br>不能太大，也不能太小<br><img src="/../images/post13_images/25330ae90951c7114fefc3d989d4d20e.png"></li><li>方法2：软投票——不采用“落在某个格子”来投票，而用“距离”来投票<br>相当于一票掰开好多份，给近的多些，给远的少些</li><li>方法3：尝试去掉不相关的特征，只选择具有明显梯度的边缘做霍夫变换</li></ul><h4 id="⑩-霍夫变换检测圆形"><a href="#⑩-霍夫变换检测圆形" class="headerlink" title="⑩ 霍夫变换检测圆形"></a>⑩ 霍夫变换检测圆形</h4><h5 id="a-原理-1"><a href="#a-原理-1" class="headerlink" title="a. 原理"></a>a. 原理</h5><p>圆的方程：$(x-u)^2+(y-v)^2=r^2$，其中 $(u,v)$ 是圆心，$r$ 是半径<br>一个圆由三个参数确定：$u,v,r$<br>依旧是从图像空间变换到参数空间<br>读懂下面的图，需要先进行以下理解：</p><ul><li>图像空间的一个圆，可以用三个参数表示：圆心坐标 $(x, y)$ 和半径 $r$ 。所以，<strong>图像中一个圆，可以用三维参数空间中一个点来表示</strong></li><li>一个点如果在图像中的某个圆上，那它和圆心所成的方向，是该点<strong>图像梯度的方向</strong></li><li>已知的某点图像梯度方向，经过图像中某一个点的所有可能的圆，可以在x,y,r三维空间中用<strong>两根直线</strong>表示。<br>（如果不考虑该点梯度方向，则笛卡尔坐标系中某一个点，其所有可能的圆，在参数空间中可以用一个<strong>立体圆锥曲面</strong>表示！）</li><li>对于图像中某个像素点 $(x,y)$ ，当给定 $r$ 半径值后，仅有<strong>两个可能的圆心位置</strong>（这两个潜在可能的圆心位置相对这个像素点<strong>互为镜像位置</strong>），这两个圆心的位置可以通过x，y，r，以及图像梯度角度值计算出来。<br><img src="/../images/post13_images/15edeb7edb21b596af6c8898dba09c5d.png"></li></ul><h4 id="⑪-广义霍夫变换"><a href="#⑪-广义霍夫变换" class="headerlink" title="⑪ 广义霍夫变换"></a>⑪ 广义霍夫变换</h4><h5 id="a-动机"><a href="#a-动机" class="headerlink" title="a. 动机"></a>a. 动机</h5><blockquote><p>普通霍夫变换需要用方程描述要检测的形状，从而获得图像空间到参数空间的变换，但有些形状很难用方程参数化描述</p></blockquote><p>拟合无法用方程描述的形状</p><h5 id="b-原理"><a href="#b-原理" class="headerlink" title="b. 原理"></a>b. 原理</h5><p>我们的目的：找到一个能表示这个形状的参考点，最终模型可以表示这个参考点<br>例如下图的不规则形状，怎么做：</p><ul><li>先假设参考点是 $(x_c,y_c)$，这个参考点的具体坐标我们不知道，只是先设出来。</li><li>然后对于边缘上的所有点，每个点都要计算：<ul><li>$r$ ：点到参考点的距离</li><li>$\alpha$：点和参考点连线与水平方向的夹角</li><li>$\phi$ ：点的梯度方向（注意图中说的边缘方向实际上是想说边缘梯度方向）</li></ul></li><li>统计梯度方向的投票情况。如图中的 $\phi_i$，可以看出多个点可能存在相同的梯度方向</li><li>取出投每个梯度方向，拿到各自所包含的点，进行投票。<br><img src="/../images/post13_images/63bcc2c1dbab49373a0e66292d3c64d3.png"></li></ul><h5 id="c-流程"><a href="#c-流程" class="headerlink" title="c. 流程"></a>c. 流程</h5><p><img src="/../images/post13_images/42703432f4e82ba1dc05262b96d64f01.png"></p><h5 id="d-改进"><a href="#d-改进" class="headerlink" title="d. 改进"></a>d. 改进</h5><p>存在问题：无法应对旋转<br><img src="/../images/post13_images/395080a9329ba46d7742fb126b9162ad.png"><br>改进方式：引入更多参数<br><img src="/../images/post13_images/0cf0d21bcc39a3395793fde56bd9cace.png"></p><h5 id="e-应用"><a href="#e-应用" class="headerlink" title="e. 应用"></a>e. 应用</h5><p>除了检测形状以外，还可以通过检测一些大物体的局部组件相对大物体的位置关系，通过方向投票机制，去锁定图像中某大物体的中心位置。<br><img src="/../images/post13_images/cb3a0a2d7a6ccf5cc239c6f5e984d869.png"></p><h4 id="⑫-霍夫变换的优缺点"><a href="#⑫-霍夫变换的优缺点" class="headerlink" title="⑫ 霍夫变换的优缺点"></a>⑫ 霍夫变换的优缺点</h4><h5 id="a-优点-1"><a href="#a-优点-1" class="headerlink" title="a. 优点"></a>a. 优点</h5><ul><li>可以处理非局部性的（全局的）和遮挡的情况</li><li>可以检测出多个模型的实例（就是拟合出多个符合要求的模型出来）</li><li>对噪声比较鲁棒（这是前提条件了，见第②部分）</li></ul><h5 id="b-缺点-1"><a href="#b-缺点-1" class="headerlink" title="b. 缺点"></a>b. 缺点</h5><ul><li>随着模型参数的增加，搜索空间变越来越大，搜索时间复杂度指数级增长</li><li>非形状目标可能会在参数空间中产生虚假峰值（伪峰值）</li><li>很难选择一个合适的网格大小（见⑨.c）</li></ul><h2 id="3-拟合方法的选择"><a href="#3-拟合方法的选择" class="headerlink" title="3. 拟合方法的选择"></a>3. 拟合方法的选择</h2><p><img src="/../images/post13_images/275a8a32d3475d58bf586ae9ebbfbd3c.png"></p><h1 id="六、局部特征"><a href="#六、局部特征" class="headerlink" title="六、局部特征"></a>六、局部特征</h1><h2 id="1-角点检测"><a href="#1-角点检测" class="headerlink" title="1. 角点检测"></a>1. 角点检测</h2><h3 id="（1）为什么要提取特征"><a href="#（1）为什么要提取特征" class="headerlink" title="（1）为什么要提取特征"></a>（1）为什么要提取特征</h3><h4 id="动机：全景拼接"><a href="#动机：全景拼接" class="headerlink" title="动机：全景拼接"></a>动机：全景拼接</h4><blockquote><p>摄像机视角有限，因此需要转动在多视角进行拍摄，完成全景图像。</p></blockquote><h5 id="a-流程"><a href="#a-流程" class="headerlink" title="a. 流程"></a>a. 流程</h5><p>提取特征 –&gt; 进行特征匹配 –&gt; 根据匹配得到的联系，拼接图像</p><h5 id="b-良好特征的性质（提取哪些特征才更适配任务）"><a href="#b-良好特征的性质（提取哪些特征才更适配任务）" class="headerlink" title="b. 良好特征的性质（提取哪些特征才更适配任务）"></a>b. 良好特征的性质（提取哪些特征才更适配任务）</h5><ul><li>可重复性：在几幅图像中可以找到的共同特征</li><li>显著性：显著区别于其他的特征</li><li>紧凑性和效率：希望特征能比图像像素少得多，从而计算是高效的</li><li>局部性：特征只跟其周围的图像有关系（在图像中占据相对较小的区域），对杂乱和遮挡具有鲁棒性</li></ul><h5 id="c-特征点的应用"><a href="#c-特征点的应用" class="headerlink" title="c. 特征点的应用"></a>c. 特征点的应用</h5><p>图像对齐、3D重建、运动跟踪、机器人导航、索引和数据库检索、物体识别……</p><h3 id="（2）角点"><a href="#（2）角点" class="headerlink" title="（2）角点"></a>（2）角点</h3><h4 id="①-角点的定义"><a href="#①-角点的定义" class="headerlink" title="① 角点的定义"></a>① 角点的定义</h4><p>图像梯度在两个方向或更多方向上发生了突变的地方</p><h4 id="②-角点的性质"><a href="#②-角点的性质" class="headerlink" title="② 角点的性质"></a>② 角点的性质</h4><p>角点具有可重复性、显著性、紧凑性（时间计算效率高）、局部性</p><h4 id="③-判断是否是角点"><a href="#③-判断是否是角点" class="headerlink" title="③ 判断是否是角点"></a>③ 判断是否是角点</h4><h5 id="a-直观描述"><a href="#a-直观描述" class="headerlink" title="a. 直观描述"></a>a. 直观描述</h5><p><img src="/../images/post13_images/1c78897a756fa731f684b9d86a6b3bfb.png"><br>如果是角点，窗口至少沿着两个方向移动会发生变化</p><h5 id="b-数值描述"><a href="#b-数值描述" class="headerlink" title="b. 数值描述"></a>b. 数值描述</h5><p>$E(u, v) = \sum_{x, y} w(x, y) \left[ I(x + u, y + v) - I(x, y) \right]^2$</p><p><img src="/../images/post13_images/33dd7bd924045b7c00cba30ed7a3cbc8.png"></p><ul><li>$u,v$：平移量</li><li>$I(x,y)$：没有移动前的图像强度</li><li>$I(x+u,y+v)$：移动后的图像强度</li><li>$E(u,v)$：窗口移动前后像素值的差异；</li><li>$w(x,y)$：权值，可根据每个点对整个E(u,v)的贡献的差异特异化设置</li></ul><p><strong>i. 将E(u,v)进行二阶泰勒展开，以观测在很小的移动下E(u,v)的数值表现（E(u,v)和u,v的关系会更加直观）：</strong><br><img src="/../images/post13_images/ecf8e088532ae18f6981a67e69e0cc8c.png"><br><strong>ii. 计算上式中涉及到的偏导数：</strong><br><img src="/../images/post13_images/5da01acc050884586c8f4624a717c8d8.png"><br><strong>iii. 代入数值并整理得到最终二阶泰勒展开式化简结果：</strong><br><img src="/../images/post13_images/3c4995c84cb467ceaba233bb6328e721.png"><br><strong>iv. 理解M矩阵：</strong></p><ul><li>假设窗口检测到的信号是垂直关系的，则有 $I_x I_y = 0$，则M可以转化成下图特征值的形式：<br><img src="/../images/post13_images/b9aebc64e9a48e495c3a9bb7fdca000c.png"></li><li><ul><li>如果点位于垂直的边缘，即 $I_x≠0，I_y =0$ ：<br>则 $M = \begin{bmatrix}\lambda_1 &amp; 0 \0 &amp; 0\end{bmatrix}，E(u,v)=λ_1u^2$<br>则 $u$变，$E(u,v)$变；$v$变，$E(u,v)$不变</li></ul></li><li><ul><li>如果点位于水平的边缘，即 $I_x=0，I_y ≠0$ ：<br>则 $M = \begin{bmatrix}\ 0&amp; 0 \0 &amp; \lambda_2\end{bmatrix}，E(u,v)=λ_2v^2$<br>则 $u$变，$E(u,v)$不变；$v$变，$E(u,v)$变</li></ul></li></ul><p>所以，只有 $λ_1$ 和 $λ_2$ 都不为0（或接近0）时，角点才存在</p><ul><li>假设窗口检测到的信号存在旋转，则M是一个实对称矩阵：<br> $M = \begin{bmatrix} a &amp; c \c &amp; a\end{bmatrix}，c≠0$，<br>则可以进行对角化：$M = R^{-1}\begin{bmatrix}\lambda_1 &amp; 0 \0 &amp; \lambda_2\end{bmatrix}R, R$是一个正交矩阵<br>同样等于$M = R^{T}\begin{bmatrix}\lambda_1 &amp; 0 \0 &amp; \lambda_2\end{bmatrix}R$</li></ul><p>所以，无论是否存在旋转，都可以通过上述方法只分析 $λ_1$ 和 $λ_2$ ‘<br><strong>v. E(u,v)在数学上是椭圆</strong></p><ul><li>课程中，首先是针对$I_x≠0，I_y =0$ 的情况，进行化简发现$E(u,v)$满足椭圆方程，是一个正椭圆，而刚才第四部分对M的讨论的第二种情况，存在旋转，即一个旋转的椭圆。</li><li>在形式上，椭圆的轴长由 $λ_1$ 和 $λ_2$确定，方向由$R$确定</li><li>$λ_1$ 和 $λ_2$ 越大，轴越短 ； $λ_1$ 和 $λ_2$ 越小，轴越长<br><img src="/../images/post13_images/1c7291a49768036eecda238a0681b3e2.png"></li></ul><p><strong>vi. 二阶矩矩阵M的可视化</strong><br><img src="/../images/post13_images/677a2434fa4e0a1504ed546c02b55c35.png"></p><p><strong>vii. 阶段总结</strong></p><ul><li>$λ_1=0$ 或 $λ_2=0$ ，点在边</li><li>$λ_1≠0$ 且 $λ_2≠0$ 且都非常大，角点</li><li>$λ_1=0$ 且 $λ_2=0$ 或都非常小，平坦区域</li></ul><p><strong>viii. 阈值R</strong><br>Q：多大算非常大？这不方便人工设定<br><strong>A：$R = \det(M) - \alpha , (\mathrm{tr}(M))^2 = \lambda_1 \lambda_2 - \alpha (\lambda_1 + \lambda_2)^2$</strong><br><strong>其中 $tr(M)$ 是矩阵的迹，是主对角线元素之和</strong><br><strong>$R&gt;0$，则是角点</strong><br><strong>$R&lt;0$，则是边缘</strong><br><strong>$R→0$，则是平坦区域</strong></p><h5 id="c-Harris角点检测"><a href="#c-Harris角点检测" class="headerlink" title="c. Harris角点检测"></a>c. Harris角点检测</h5><p>Harris角点检测就是上面的数值描述方法，总结一下：</p><ul><li>先在每个像素处计算高斯导数，也就是$I_x$和$I_y$，相关计算见b.ii</li><li>然后计算每个像素周围高斯窗口的二阶矩矩阵M，相关计算见b.iii</li><li>然后计算角点响应函数R，相关计算见b.viii</li><li>将R作为阈值来判断是否是角点，相关判断见b.viii</li><li>最后进行非极大值抑制，找到响应函数的局部最大值</li></ul><p>最后一步的是因为：某一个点是角点（响应较高）时，周围的点可能也是如此。找到最高的即可。  </p><h3 id="（3）Harris角点的特性"><a href="#（3）Harris角点的特性" class="headerlink" title="（3）Harris角点的特性"></a>（3）Harris角点的特性</h3><h4 id="①-好的特征具备的四个特性"><a href="#①-好的特征具备的四个特性" class="headerlink" title="① 好的特征具备的四个特性"></a>① 好的特征具备的四个特性</h4><p>可重复性、显著性、计算高效（紧凑性）、局部性</p><h4 id="②-Invariance-和-Covariance-的区别"><a href="#②-Invariance-和-Covariance-的区别" class="headerlink" title="② Invariance 和 Covariance 的区别"></a>② Invariance 和 Covariance 的区别</h4><ul><li>Invariance：$F(I)=F[T(I)]$<br>即图像变化前后，用同一个特征提取器$F$提取到的特征是相同的</li><li>Covariance：$F(I)≠F[T(I)]$，但$T’[F(I)]=F[T(I)]$<br>即对原始图像提取的特征做变换后，与变换后的图像提取到的特征是相同的</li></ul><p><strong>所以，好的特征应当具备Invariance特性，实在不行，Covariance特性也可以</strong></p><h4 id="③-探究Harris角点是否具有Invariance-Covariance特性"><a href="#③-探究Harris角点是否具有Invariance-Covariance特性" class="headerlink" title="③ 探究Harris角点是否具有Invariance/Covariance特性"></a>③ 探究Harris角点是否具有Invariance/Covariance特性</h4><h5 id="a-对图像强度进行变化"><a href="#a-对图像强度进行变化" class="headerlink" title="a. 对图像强度进行变化"></a>a. 对图像强度进行变化</h5><p>加光照，$I → I+b$，并不改变梯度变化，对$M$矩阵无影响，因此还能检测到角点，<strong>满足Invariance</strong></p><h5 id="b-对图像进行尺度变化（缩放）"><a href="#b-对图像进行尺度变化（缩放）" class="headerlink" title="b, 对图像进行尺度变化（缩放）"></a>b, 对图像进行尺度变化（缩放）</h5><p>缩放，$I → αI$，可能将原本低于$R$阈值的响应点也检测为角点，<strong>不满足Invariance和Covariance</strong>，如图：<br><img src="/../images/post13_images/eb06cee6da5ca4d10c58723d04aef8b8.png"></p><h5 id="c-对图像进行平移或旋转"><a href="#c-对图像进行平移或旋转" class="headerlink" title="c, 对图像进行平移或旋转"></a>c, 对图像进行平移或旋转</h5><p>平移或旋转不改变梯度，还是能够检测到角点，但平移或旋转前后提取到的特征不相同，<strong>不满足Invariance</strong>；但把平移后得到的特征再变化，就相同了，<strong>满足Covariance</strong></p><h5 id="d-结论"><a href="#d-结论" class="headerlink" title="d. 结论"></a>d. 结论</h5><p>Harris角点检测对于仿射变换具有<strong>部分</strong>的不变性<br>Harris角点检测不具备尺度不变性<br>如果相机和场景距离固定（图像尺度不变），Harris角点检测可行，反之不可行</p><hr><h2 id="2-Blob检测"><a href="#2-Blob检测" class="headerlink" title="2. Blob检测"></a>2. Blob检测</h2><blockquote><p>Blob检测具有尺度不变性，而Harris角点检测不具备尺度不变性</p></blockquote><h3 id="（1）Blob（斑点）"><a href="#（1）Blob（斑点）" class="headerlink" title="（1）Blob（斑点）"></a>（1）Blob（斑点）</h3><h4 id="①-定义："><a href="#①-定义：" class="headerlink" title="① 定义："></a>① 定义：</h4><p>二维图像跟周围有着明显颜色和灰度变化的区域</p><blockquote><p>斑点可以是一个区域，但角点只是一个点，因此斑点具有<strong>更好的稳定性和抗干扰能力</strong></p></blockquote><h4 id="②-斑点的尺度寻找"><a href="#②-斑点的尺度寻找" class="headerlink" title="② 斑点的尺度寻找"></a>② 斑点的尺度寻找</h4><p>找到一个函数，从而自适应尺度的变化，因此有尺度不变性<br><img src="/../images/post13_images/fc7f5fed3f567897168db5d6d8af4d16.png"></p><blockquote><p>回顾边缘检测</p></blockquote><h5 id="a-高斯一阶偏导核"><a href="#a-高斯一阶偏导核" class="headerlink" title="a. 高斯一阶偏导核"></a>a. 高斯一阶偏导核</h5><p><img src="/../images/post13_images/938235066e8c47e45724d511464633f8.png"></p><h5 id="b-高斯二阶偏导核（拉普拉斯核）"><a href="#b-高斯二阶偏导核（拉普拉斯核）" class="headerlink" title="b. 高斯二阶偏导核（拉普拉斯核）"></a>b. 高斯二阶偏导核（拉普拉斯核）</h5><p><img src="/../images/post13_images/0bd611aa56f53df69370dd3910ac4250.png"></p><h5 id="c-通过拉普拉斯核找到最优尺度"><a href="#c-通过拉普拉斯核找到最优尺度" class="headerlink" title="c. 通过拉普拉斯核找到最优尺度"></a>c. 通过拉普拉斯核找到最优尺度</h5><p><img src="/../images/post13_images/eec9eeba1a6ee1b9012d8174825b23a0.png"><br>在实际应用中，由于不知道信号长什么样，会设置多个不同方差的拉普拉斯核去卷积，从而才能选择到最好的。</p><h5 id="d-拉普拉斯核方差的选择"><a href="#d-拉普拉斯核方差的选择" class="headerlink" title="d. 拉普拉斯核方差的选择"></a>d. 拉普拉斯核方差的选择</h5><p><strong>问题</strong>：随着方差$σ$逐渐变大，信号会逐渐衰减，很难找到极值点<br><strong>原因</strong>：<br><img src="/../images/post13_images/486dcbdb3deaa9e7eaff10174a447aaa.png"></p><ul><li>数学理解：$σ$越大，图中面积越小，产生出的信号相应越小。（图中仅是高斯一阶偏导核，而二阶会受到更强烈的影响）</li><li>物理理解：高斯核去噪，$σ$越大，去噪效果越强，把高频信号都去掉了，原本响应值突出的区域也都因此变得平坦了</li></ul><p><strong>解决</strong>：需要对信号进行补偿，给拉普拉斯核乘上一个$σ^2$：$\nabla^2_{\text{norm}} g = \sigma^2 \left( \frac{\partial^2 g}{\partial x^2} + \frac{\partial^2 g}{\partial y^2} \right)$<br>  从而把分母上的$σ^2$约掉，效果如图，可以找到我们想要的函数曲线了：<br>  <img src="/../images/post13_images/9337869d8a3f92af9b40847f83b40a24.png"><br>  横轴是方差变化，也就是尺度变化；纵轴是响应值变化</p><h5 id="e-拉普拉斯核方差和信号半径的关系"><a href="#e-拉普拉斯核方差和信号半径的关系" class="headerlink" title="e. 拉普拉斯核方差和信号半径的关系"></a>e. 拉普拉斯核方差和信号半径的关系</h5><p>当拉普拉斯核的过零点的宽度和信号的直径恰好相等时，响应值最大<br><img src="/../images/post13_images/329ea11f49265c8469c8a094fc9e00a7.png"><br><strong>此时也存在关系：</strong> $r=\sqrt{2}σ$<br>这个的计算方式就是让拉普拉斯核等于0（过零点），结合本身斑点存在的关系 $x^2+y^2=r^2$（圆），化简得到了。</p><blockquote><p>大方差，大窗宽，检测大信号；小方差，小窗宽，检测小信号</p></blockquote><h5 id="f-斑点检测的非极大值抑制"><a href="#f-斑点检测的非极大值抑制" class="headerlink" title="f, 斑点检测的非极大值抑制"></a>f, 斑点检测的非极大值抑制</h5><p>由于检测时，相邻区域的点可能响应值都很大，因此步骤：</p><ul><li>取下图三个尺度的27个点的响应值</li><li>对最大响应值对应的点，作为圆心，根据对应尺度和计算出的半径画圆<br><img src="/../images/post13_images/73e6d157f96ba59af5c36f60a2188afc.png"><br>（此图假设检测模板是3×3的，同时在实际检测中一般仅比较相邻三个的尺度如图所示）</li></ul><h4 id="③-斑点检测计算量大的解决办法"><a href="#③-斑点检测计算量大的解决办法" class="headerlink" title="③ 斑点检测计算量大的解决办法"></a>③ 斑点检测计算量大的解决办法</h4><h5 id="a-和Harris角点检测相结合"><a href="#a-和Harris角点检测相结合" class="headerlink" title="a. 和Harris角点检测相结合"></a>a. 和Harris角点检测相结合</h5><ul><li>先用Harris角点检测，把角点检测出来</li><li>在每个角点周围，建立一个尺度空间，看周围有没有合适尺度（斑点检测画圆）</li></ul><h5 id="b-SIFT特征"><a href="#b-SIFT特征" class="headerlink" title="b. SIFT特征"></a>b. SIFT特征</h5><p>见下</p><h3 id="（2）SIFT"><a href="#（2）SIFT" class="headerlink" title="（2）SIFT"></a>（2）SIFT</h3><h4 id="①-高斯差分"><a href="#①-高斯差分" class="headerlink" title="① 高斯差分"></a>① 高斯差分</h4><h5 id="a-定义"><a href="#a-定义" class="headerlink" title="a. 定义"></a>a. 定义</h5><p>两个高斯核做差<br><img src="/../images/post13_images/75d109bce06eef976fbe69fcdb8d9002.png"></p><h5 id="b-优势——效率提升方式"><a href="#b-优势——效率提升方式" class="headerlink" title="b. 优势——效率提升方式"></a>b. 优势——效率提升方式</h5><ul><li>高斯差分和拉普拉斯之间就差了一个常数：$k-1$，则：高斯函数→高斯差分→拉普拉斯<br><img src="/../images/post13_images/0b436b76b01c215960b476753271bf50.png"><br>（图中这样一组空间成为一个Octave——八度）</li><li>在构建高斯空间时，可以利用”过两个小的等于过一个大的，关系是$\sqrt2$ 的性质，来得到其他尺度的高斯层    【<strong>Octave组内加速</strong>】</li><li>如果不想用大方差的拉普拉斯核和大信号做卷积，可以通过：<br>先把图像进行缩放，用小方差的卷积核与缩放后的图像做卷积，找到的尺度空间再乘回缩放倍数<br>这样可以避免一直增大卷积核的方差不断做卷积构成新的Octave，直接用原来的小方差卷积核就可以构建新的Octave了<br>所以在实际应用中，对于1-8的尺度，可以：尺度为1-2时，用原图计算；2-4时，用1/2原图计算；4-8时，用1/4原图计算。拼起来就可以得到连续的尺度空间。<br>【<strong>Octave组间加速</strong>】</li></ul><h5 id="c-如何设置k的数值"><a href="#c-如何设置k的数值" class="headerlink" title="c. 如何设置k的数值"></a>c. 如何设置k的数值</h5><p> $k=2^{1/S}$，因为只有满足这个关系才能构建连续的尺度空间<br> S是怎么来的：</p><ul><li>对于5层高斯空间，有4层高斯差分空间，则有4层拉普拉斯空间，我们在前面说过，一般仅比较相邻三个的尺度，则有两种可能，S=2（123、234两种可能）</li><li>对于6层高斯空间，同理，则有三种可能，S=3（123、234、345三种可能）</li></ul><h4 id="②-SIFT特征的特性"><a href="#②-SIFT特征的特性" class="headerlink" title="② SIFT特征的特性"></a>② SIFT特征的特性</h4><h5 id="a-拉普拉斯相应的Invariance"><a href="#a-拉普拉斯相应的Invariance" class="headerlink" title="a. 拉普拉斯相应的Invariance"></a>a. 拉普拉斯相应的Invariance</h5><p>当图像进行旋转或缩放时，拉普拉斯算子计算出的响应值不会改变。</p><h5 id="b-斑点位置和尺度的Covariance"><a href="#b-斑点位置和尺度的Covariance" class="headerlink" title="b. 斑点位置和尺度的Covariance"></a>b. 斑点位置和尺度的Covariance</h5><p>当图像进行旋转或缩放时，检测到的“blob”的位置和尺度会相应地变化。</p><h5 id="c-对于强度、角度、形状变化不满足Invariance和Covariance"><a href="#c-对于强度、角度、形状变化不满足Invariance和Covariance" class="headerlink" title="c. 对于强度、角度、形状变化不满足Invariance和Covariance"></a>c. 对于强度、角度、形状变化不满足Invariance和Covariance</h5><p>角度和形变的解决方案：经过大小归一化变成椭圆，再利用梯度方向直方图按梯度最强方向进行旋转（梯度方向直方图见下）<br>强度（光照）变化的解决方案：SIFT描述子投票（SIFT描述子见下）</p><blockquote><p>大小归一化：计算出M矩阵，微调$λ_1$和$λ_2$，把小的变大一点，迭代微调，直到$λ_1$和$λ_2$相等，相当于接近于原始的正圆了<br>【不确定理解的是否正确，老师在这里的讲解逻辑很混乱，讲的不太好这里】</p></blockquote><h4 id="③-梯度方向直方图"><a href="#③-梯度方向直方图" class="headerlink" title="③ 梯度方向直方图"></a>③ 梯度方向直方图</h4><p>梯度强度：$\sqrt{I_x^2+I_y^2}$<br>梯度方向：$arctan\sqrt{I_x^2+I_y^2}$<br>箭头方向表示梯度方向，箭头长度表示梯度强度<br><img src="/../images/post13_images/98c8ee16179daff71acc3a4ec9e687f7.png"></p><h4 id="④-SIFT描述子"><a href="#④-SIFT描述子" class="headerlink" title="④ SIFT描述子"></a>④ SIFT描述子</h4><p>将小区域进行划分<br>1个区域划分为16个小区域，每个小区域存在8个方向，因此共有$16×8=128$维特征<br><img src="/../images/post13_images/1e3de9e6d21c4a68890e99e59827525f.png"></p><h2 id="3-纹理特征"><a href="#3-纹理特征" class="headerlink" title="3. 纹理特征"></a>3. 纹理特征</h2><h3 id="（1）纹理（Texture）"><a href="#（1）纹理（Texture）" class="headerlink" title="（1）纹理（Texture）"></a>（1）纹理（Texture）</h3><h4 id="①-定义"><a href="#①-定义" class="headerlink" title="① 定义"></a>① 定义</h4><p>某种基元以某种方式组合起来</p><h4 id="②-分类"><a href="#②-分类" class="headerlink" title="② 分类"></a>② 分类</h4><ul><li>规则的纹理</li><li>不规则的纹理</li></ul><h4 id="③-用途"><a href="#③-用途" class="headerlink" title="③ 用途"></a>③ 用途</h4><ul><li>从纹理中恢复形状信息</li><li>应用于分割、分类任务【课程主要关注】<br>（可以帮助我们区分事物、划分类别等）</li><li>应用于合成任务</li></ul><h4 id="④-纹理的重要性"><a href="#④-纹理的重要性" class="headerlink" title="④ 纹理的重要性"></a>④ 纹理的重要性</h4><ul><li>通常表示了材料的特性</li><li>可能是重要的外观线索，特别是在物体形状相似的情况下</li><li>旨在区分形状、边界和纹理</li></ul><h3 id="（2）纹理特征的提取"><a href="#（2）纹理特征的提取" class="headerlink" title="（2）纹理特征的提取"></a>（2）纹理特征的提取</h3><h4 id="①-发现模式（Pattern）"><a href="#①-发现模式（Pattern）" class="headerlink" title="① 发现模式（Pattern）"></a>① 发现模式（Pattern）</h4><blockquote><p>模式就是某种规则、规律</p></blockquote><p>利用斑点检测器、角点检测器、边缘检测器…检测出基础的元素</p><h4 id="②-描述纹理"><a href="#②-描述纹理" class="headerlink" title="② 描述纹理"></a>② 描述纹理</h4><p>利用统计的方法：平均值、标准差、直方图…</p><h4 id="③-示例"><a href="#③-示例" class="headerlink" title="③ 示例"></a>③ 示例</h4><p><img src="/../images/post13_images/336e64283bcade1b026fb889cef74fe9.png"><br><img src="/../images/post13_images/1167a7522edd8b3b177b08f0ed086765.png"><br>其中，<br><img src="/../images/post13_images/8be32f58e506354de3cfc05fae430315.png"><br>$D(a,b)=\sqrt{(a_1-b_1)^2+(a_2-b_2)^2+(a_3-b_3)^2} = \sqrt{\sum_{i=1}^{3} (a_i - b_i)^2}$</p><h4 id="④-Filter-banks（滤波器组-卷积核组）"><a href="#④-Filter-banks（滤波器组-卷积核组）" class="headerlink" title="④ Filter banks（滤波器组/卷积核组）"></a>④ Filter banks（滤波器组/卷积核组）</h4><h5 id="a-背景"><a href="#a-背景" class="headerlink" title="a. 背景"></a>a. 背景</h5><p>在③示例中，使用了两个滤波器分别在x和y两个方向上做卷积，产生了二维特征向量，用于描述窗口中的纹理特征。</p><h5 id="b-引入"><a href="#b-引入" class="headerlink" title="b. 引入"></a>b. 引入</h5><p>推广，应用一组d个滤波器，产生d维特征向量</p><h5 id="c-形式"><a href="#c-形式" class="headerlink" title="c. 形式"></a>c. 形式</h5><p>如图所示48维的滤波器组<br><img src="/../images/post13_images/722d46bd0c22b46e2b1bebeeb7397062.png"><br>每个窗口纹理被映射为48维空间的一个点，是一个48维的特征向量，这个点具有48维的特征</p><h5 id="d-多维高斯（Multivariate-Gaussian）"><a href="#d-多维高斯（Multivariate-Gaussian）" class="headerlink" title="d. 多维高斯（Multivariate Gaussian）"></a>d. 多维高斯（Multivariate Gaussian）</h5><p>展现了协方差矩阵和高斯核之间的关系：<br><img src="/../images/post13_images/51d72ea41f04ff2ac2093e35fd9b69ab.png"><br>在 Filter banks中的48个滤波器就是通过如上编程定义（不同方向）</p><h5 id="e-Filter-bank-应用示例"><a href="#e-Filter-bank-应用示例" class="headerlink" title="e. Filter bank 应用示例"></a>e. Filter bank 应用示例</h5><p>应用一个38维的Filter bank做卷积：<br><img src="/../images/post13_images/ba335962a9b95ff650748d0554f7a385.png"><br>一个匹配quiz：<br><img src="/../images/post13_images/1e7cfa90899fd73dbc22ab9996be4d0a.png"></p><h5 id="f-Fliter-bank-卷积结果的应用"><a href="#f-Fliter-bank-卷积结果的应用" class="headerlink" title="f. Fliter bank 卷积结果的应用"></a>f. Fliter bank 卷积结果的应用</h5><h6 id="i-对整个图像卷积"><a href="#i-对整个图像卷积" class="headerlink" title="i. 对整个图像卷积"></a>i. 对整个图像卷积</h6><p>一张图像，x维Filter bank卷积，得到x个卷积响应，对这x个卷积响应计算平均，得到了一个图像的x维特征向量，表示了图像</p><h6 id="ii-对每个像素点卷积"><a href="#ii-对每个像素点卷积" class="headerlink" title="ii. 对每个像素点卷积"></a>ii. 对每个像素点卷积</h6><p>对一张图像的所有像素点，x维Filter bank卷积，每个像素得到x个卷积响应</p><h3 id="（3）纹理检测在视觉任务中的应用"><a href="#（3）纹理检测在视觉任务中的应用" class="headerlink" title="（3）纹理检测在视觉任务中的应用"></a>（3）纹理检测在视觉任务中的应用</h3><ul><li>通过Filter bank检索相似纹理 / 通过相似纹理的检索进一步进行图像分类任务</li><li>通过纹理来区分场景（其实也是分类任务）</li><li>通过纹理来进行图像分割，通过纹理让图像中的各部分进行了分类，从而分开了</li></ul><h1 id="七、分割"><a href="#七、分割" class="headerlink" title="七、分割"></a>七、分割</h1><h2 id="1-图像分割的基本概念"><a href="#1-图像分割的基本概念" class="headerlink" title="1. 图像分割的基本概念"></a>1. 图像分割的基本概念</h2><h3 id="（1）定义"><a href="#（1）定义" class="headerlink" title="（1）定义"></a>（1）定义</h3><p>将图像划分为多个互不相交的区域</p><h3 id="（2）目标"><a href="#（2）目标" class="headerlink" title="（2）目标"></a>（2）目标</h3><p>根据像素的<strong>相似性</strong>，把具有相似特征的像素组织在一起，识别和分理处不同的对象或区域</p><h3 id="（3）超像素"><a href="#（3）超像素" class="headerlink" title="（3）超像素"></a>（3）超像素</h3><p>一个超像素=多个像素形成的小块，例如下图<br><img src="/../images/post13_images/419ac13de61f1c578f43b075854252f9.png"></p><h3 id="（4）理想的分割方法"><a href="#（4）理想的分割方法" class="headerlink" title="（4）理想的分割方法"></a>（4）理想的分割方法</h3><p>既不是过分割，也不是欠分割</p><ul><li>过分割：把一个主体过度分割成多个主体了<br>（超像素属于一种过分割）</li><li>欠分割：没有完全分开，把多个主体划分成一个主体了</li></ul><h3 id="（5）分割方式"><a href="#（5）分割方式" class="headerlink" title="（5）分割方式"></a>（5）分割方式</h3><h4 id="①-自下而上、自上而下"><a href="#①-自下而上、自上而下" class="headerlink" title="① 自下而上、自上而下"></a>① 自下而上、自上而下</h4><h5 id="a-自下而上的分割方法"><a href="#a-自下而上的分割方法" class="headerlink" title="a. 自下而上的分割方法"></a>a. 自下而上的分割方法</h5><ul><li>自下：先获取像素的底层特征，例如纹理、边、点</li><li>而上：再分割出主体</li></ul><h5 id="b-自上而下的分割方法"><a href="#b-自上而下的分割方法" class="headerlink" title="b. 自上而下的分割方法"></a>b. 自上而下的分割方法</h5><ul><li>自上：先获取一定的图像语义等高层特征</li><li>而下：再分割出主体<br>人思考的方式其实就是自上而下</li></ul><h4 id="②-有监督、无监督"><a href="#②-有监督、无监督" class="headerlink" title="② 有监督、无监督"></a>② 有监督、无监督</h4><ul><li>有监督：给标签，从label中学习</li><li>无监督，没标签，自己寻找规律<br>人思考的方式其实是有监督+无监督结合的<br>常用深度学习模型基于有监督</li></ul><h2 id="2-人类做图像分割的原理"><a href="#2-人类做图像分割的原理" class="headerlink" title="2. 人类做图像分割的原理"></a>2. 人类做图像分割的原理</h2><blockquote><p>格式塔学派理论</p></blockquote><p><strong>群组是视觉感知的关键</strong></p><h3 id="（1）感知整体空间"><a href="#（1）感知整体空间" class="headerlink" title="（1）感知整体空间"></a>（1）感知整体空间</h3><p>人的视觉系统将元素综合为一个新的领域，相较于部件/元素，更感知整体<br><img src="/../images/post13_images/f8449f17deb8c98418f01a1307012ce2.png"></p><h3 id="（2）利用先验知识做判断（自上而下）"><a href="#（2）利用先验知识做判断（自上而下）" class="headerlink" title="（2）利用先验知识做判断（自上而下）"></a>（2）利用先验知识做判断（自上而下）</h3><p>例如下图，人类可能会根据经验，感觉到图像中的事物，比如中间有相交的道路<br><img src="/../images/post13_images/2652c8b5b05e6d40f72140b53082157d.png"></p><h3 id="（3）格式塔的组织原则"><a href="#（3）格式塔的组织原则" class="headerlink" title="（3）格式塔的组织原则"></a>（3）格式塔的组织原则</h3><p><img src="/../images/post13_images/c039eae9f50ebe739cddb2575a8489a9.png"><br><img src="/../images/post13_images/a29d58d21dd9b9af1f14265133d778df.png"></p><h2 id="3-K-Means-图像分割"><a href="#3-K-Means-图像分割" class="headerlink" title="3. K-Means 图像分割"></a>3. K-Means 图像分割</h2><blockquote><p>格式塔学派理论“群组”的思想，恰好对应机器学习的“聚类”任务</p></blockquote><h3 id="（1）算法流程"><a href="#（1）算法流程" class="headerlink" title="（1）算法流程"></a>（1）算法流程</h3><p><img src="/../images/post13_images/e135158a5bae51c312c717975ba78334.png"></p><h3 id="（2）应用实例及问题"><a href="#（2）应用实例及问题" class="headerlink" title="（2）应用实例及问题"></a>（2）应用实例及问题</h3><p><img src="/../images/post13_images/fa6f8069233e6a331df33af8edb39228.png"></p><h3 id="（3）影响因素"><a href="#（3）影响因素" class="headerlink" title="（3）影响因素"></a>（3）影响因素</h3><p>初始化聚类中心点的位置（位置不同，算法计算量不同，可能结果也不同）<br>聚类数量K的选取（图中K越大，效果越好，但在具体任务上也有可能出现别的问题，例如过分割~）<br><img src="/../images/post13_images/89ad3df7f68a58c8dcc1798d22785070.png"></p><h3 id="（4）优缺点"><a href="#（4）优缺点" class="headerlink" title="（4）优缺点"></a>（4）优缺点</h3><p>优点</p><ul><li>非常简单</li><li>可以收敛到局部最优值<br>缺点</li><li>内存需求较大</li><li>需要指定K的值，K值的选取影响结果</li><li>对初始化随机中心点位置十分敏感</li><li>对外点敏感<br><img src="/../images/post13_images/8a283ac112a21bb35c35ef565a94895f.png"></li><li>最终只能生成球形的聚类簇（因此在用K-Means时，需要看最终的任务形成的簇大概会是什么形状，K-Means 比较适合最终划分为球形簇的任务）</li></ul><h2 id="4-Mean-Shift-（均值漂移）-图像分割"><a href="#4-Mean-Shift-（均值漂移）-图像分割" class="headerlink" title="4. Mean Shift （均值漂移） 图像分割"></a>4. Mean Shift （均值漂移） 图像分割</h2><h3 id="（1）算法流程-1"><a href="#（1）算法流程-1" class="headerlink" title="（1）算法流程"></a>（1）算法流程</h3><p><strong>原理：在特征空间中寻找密度模式，或密度的局部最大值</strong><br>一步一步找到密度极大值点：<br><img src="/../images/post13_images/9fe8a240751bbed6d472dcfa5dbabaff.png"></p><ul><li>查找特征（颜色、纹理等）</li><li>在单个特征点初初始化漂移的窗口</li><li>对每个窗口执行均值漂移，直到收敛</li><li>合并最终接近相同峰值或模式的窗口<br><img src="/../images/post13_images/63c85019d3b12fe92327c3dd2ca4d516.png"></li></ul><h3 id="（2）优缺点"><a href="#（2）优缺点" class="headerlink" title="（2）优缺点"></a>（2）优缺点</h3><h4 id="a-优点-2"><a href="#a-优点-2" class="headerlink" title="a. 优点"></a>a. 优点</h4><ul><li>不需要假设聚类簇的一个球形的（不像K-Means那样），对任何形状都可以聚类</li><li>只需要设定一个参数——飘逸的窗口大小</li><li>不需要预先设定类别数量（K-Means里的K值），飘逸后找到几个点就代表几个类</li><li>对外点比较鲁棒</li></ul><h4 id="b-缺点-2"><a href="#b-缺点-2" class="headerlink" title="b. 缺点"></a>b. 缺点</h4><ul><li>最终输出的结果特别依赖于飘逸窗口大小的设置</li><li>计算成本高</li><li>如果特征维度太高，表现不太好了</li></ul><h4 id="c-计算成本高的解决方案"><a href="#c-计算成本高的解决方案" class="headerlink" title="c. 计算成本高的解决方案"></a>c. 计算成本高的解决方案</h4><ul><li>对超像素进行Mean Shift，因为超像素本身已经是比较相似的像素的集合，对超像素进行均值漂移就不需要遍历图像中每一个像素了</li><li>记录每个漂移框漂移过程中涉及到的所有重心点，当其他框也飘到这个过程中的重心点时，则说明也是那个类（终点是一致的）</li></ul><h2 id="5-Graph-Cut（图割）图像分割"><a href="#5-Graph-Cut（图割）图像分割" class="headerlink" title="5. Graph Cut（图割）图像分割"></a>5. Graph Cut（图割）图像分割</h2><h3 id="（1）广义框架"><a href="#（1）广义框架" class="headerlink" title="（1）广义框架"></a>（1）广义框架</h3><blockquote><p>移除一组边使图分裂为互不连通的子图</p></blockquote><h4 id="①-准备阶段"><a href="#①-准备阶段" class="headerlink" title="① 准备阶段"></a>① 准备阶段</h4><p>把图像表示成图结构：</p><ul><li>节点：每个像素对应一个节点</li><li>边：相邻像素/满足空间邻近条件的像素对，通过边连接</li><li>边权重：像素对的相似性越高，权重越大<br><img src="/../images/post13_images/381359bef2751571e52e60b9336823c2.png"><br>权重涉及到的相似度计算：<br>$$\exp \left( -\frac{1}{2\sigma^2} \text{dist}(x_i, x_j)^2 \right)$$<br>像素表示为特征向量$x_i$，通过上面的公式，将特征向量间的距离映射为相似度（0到1之间）<br>其中：</li><li>距离可以用各种距离，例如欧氏距离，L2距离等</li><li>$σ$ 控制相似性衰减速率，是一个尺度参数。<ul><li>小 $σ$：仅聚集邻近像素，生成细粒度分割（如纹理细节）</li><li>大 $σ$：允许远距离像素归为同组，生成粗粒度分割（如整体轮廓）</li></ul></li></ul><h4 id="②-割图阶段"><a href="#②-割图阶段" class="headerlink" title="② 割图阶段"></a>② 割图阶段</h4><p>断开图中的低权重边，将图划分为若干子图<br><img src="/../images/post13_images/a60185548c48a3f627df9b48653e2e2f.png"></p><h3 id="（3）Minimum-Cut（最小割）"><a href="#（3）Minimum-Cut（最小割）" class="headerlink" title="（3）Minimum Cut（最小割）"></a>（3）Minimum Cut（最小割）</h3><h4 id="①-目标"><a href="#①-目标" class="headerlink" title="① 目标"></a>① 目标</h4><p>割成本：被移除边的权重之和<br>因此最小割想要：找到使割成本最小的分割方式<br><img src="/../images/post13_images/e94ba81e2c91f92fcc196b996e3c29c2.png"></p><h4 id="②-局限性"><a href="#②-局限性" class="headerlink" title="② 局限性"></a>② 局限性</h4><p>易切割出孤立小区域（如噪声点），导致过分割<br><img src="/../images/post13_images/b6c959a15f0dcfbccb780589bca6334c.png"></p><h3 id="（4）-Normalized-Cut（归一化割）"><a href="#（4）-Normalized-Cut（归一化割）" class="headerlink" title="（4） Normalized Cut（归一化割）"></a>（4） Normalized Cut（归一化割）</h3><blockquote><p>最小割倾向于割出很多小区域，这可以根据与每个区域相连所有边的总权重，通过引入归一化因子，平衡分割区域规模</p></blockquote><h4 id="①-原理-3"><a href="#①-原理-3" class="headerlink" title="① 原理"></a>① 原理</h4><h5 id="a-归一化割的成本"><a href="#a-归一化割的成本" class="headerlink" title="a. 归一化割的成本"></a>a. 归一化割的成本</h5><p>归一化割成本公式：<br>$$\text{Normalized Cut Cost} = \frac{w(A, B)}{w(A, V)} + \frac{w(A, B)}{w(B, V)}$$<br>其中：</p><ul><li>$w(A,B)$：子图A与B间边权重和</li><li>$w(A,V)$：子图A与全图V的边权重和</li><li>$w(B,V)$：子图B与全图V的边权重和</li></ul><p>矩阵表示：<br>$$\text{Normalized Cut Cost} ={\frac{y^T (D - W) y}{y^T D y}}$$<br>其中：</p><ul><li>$W$：图的邻接矩阵，$n×n$，元素 $W(i,j)$ 表示节点 $i$ 和 $j$ 之间边的权重</li><li>$D$：一个对角矩阵，只有对角线上有值，且为 $D(i,i) = \sum_{j} {W}(i,j)$</li><li>$D−W$：称为拉普拉斯矩阵，它反映了节点间的差异程度</li><li>$y$：指示向量，用于标记每个节点所属的子集。如果第 $i$ 个节点属于子集 $A$，则 $y_i=1$，否则 $y_i$ 为一个负常数，通常设为 $-1$</li><li>$y^T(D−W)y$：表示割的代价，即两个子集 $A$ 和 $B$ 之间的边权总和</li><li>$y^TDy$：表示区域 $A$ 的总关联度，用于归一化分子部分，避免分割出孤立点或极小区域‘</li></ul><h5 id="b-归一化割的数学松弛解法"><a href="#b-归一化割的数学松弛解法" class="headerlink" title="b. 归一化割的数学松弛解法"></a>b. 归一化割的数学松弛解法</h5><h6 id="i-原理"><a href="#i-原理" class="headerlink" title="i. 原理"></a>i. 原理</h6><p>直接求解归一化割成本的最优解（最小值）在计算上不可行（指数复杂度）<br>但可以通过放宽离散约束（允许指示向量 $y$ 取任意值），将问题转化为可解的广义特征值问题：<br>$$(D-W)y=\lambda Dy$$<br>解这个问题可以解出许多解：$(\lambda,y)$<br>我们的最终目标：拿到第二小特征值($\lambda$) 所对应的解的 $y$ 值<br>（第一小特征值是 $λ=0$，对应特征向量 $y=[1,1,…,1]^T$，所有像素归为同一类，无意义）<br>这个 $y$ 的值表示了像素的分组倾向，可以根据 $y$ 值分布，使用0或中位数来进行分类（割一刀）（属于哪个子集）</p><blockquote><p>可以这样理解：平常 $y_i$可能只能取 $+1$ 或 $-1$，但我们可以放宽要求，让 $y_i$ 取任意的正负值，这样就不是绝对二分类，而是类似于对于某个子集的置信度得分（更加可能属于哪个子图）</p></blockquote><h6 id="ii-算法流程"><a href="#ii-算法流程" class="headerlink" title="ii. 算法流程"></a>ii. 算法流程</h6><ul><li>构建图：将图像表示为带权的图 $G=(V,E)$ （节点可能是像素或者超像素），并计算每条边的权重，得到边权重矩阵 $W$ 和 对角矩阵 $D$</li><li>特征求解：计算 $(D-W)y=\lambda Dy$ 的第二小特征向量 $y$</li><li>割：根据特征向量 $y$ 元素值的分布进行阈值分割</li></ul><h6 id="iii-扩展到多类割"><a href="#iii-扩展到多类割" class="headerlink" title="iii. 扩展到多类割"></a>iii. 扩展到多类割</h6><p>现在的割是一图割两半<br>也可以扩展到一图一次多割<br>方法有：</p><ul><li>递归二分：逐层细分（可能引入误差累积）</li><li>K-Means聚类：联合多个特征向量（前k个）进行聚类</li></ul><h5 id="c-效果"><a href="#c-效果" class="headerlink" title="c. 效果"></a>c. 效果</h5><p><img src="/../images/post13_images/77232bdc9a4e330efc5df8c7b178fd1d.png"><br>效果不错捏</p><h5 id="d-利用纹理特征进行分割"><a href="#d-利用纹理特征进行分割" class="headerlink" title="d. 利用纹理特征进行分割"></a>d. 利用纹理特征进行分割</h5><blockquote><p>如何分割那些是“纹理马赛克”的图像（反正就是因为纹理的问题搞得有点难分割的图像）</p></blockquote><p>步骤：</p><ul><li>用一组滤波器组（Filter Bank）对图像进行卷积，提取不同方向和尺度下的纹理特征响应</li><li>对所有得到的纹理特征响应，使用聚类算法对特征进行分组，每个聚类中心对应一种纹理的基元</li><li>统计窗口内所有像素的纹理基元类别分布，生成基元直方图，直方图的每个bin对应一种基元出现的频率</li><li>基元直方图将用于归一化割之中，例如可通过基元直方图来构建 $W$ 矩阵等</li></ul><p>不过还可能有一种特殊情况：相似纹理跨不同物体（如鹰的羽毛与背景纹理混淆）<br>解决策略：介入轮廓检测。在计算像素间亲和度时，沿连接路径检查是否存在显著边缘（如Canny边缘）</p><h5 id="e-归一化割的优缺点"><a href="#e-归一化割的优缺点" class="headerlink" title="e. 归一化割的优缺点"></a>e. 归一化割的优缺点</h5><p>优点：是一个通用的框架，算法流程清晰、固定，可以结合很多其他特征和相似度计算工作<br>缺点：图像存储要求高（不过可以用超像素缓解）、时间复杂度高、倾向于把一个图分为两个部分（如果想得到多个可能需要再多次执行归一化割算法）</p><h2 id="6-基于深度学习的弱监督图像分割"><a href="#6-基于深度学习的弱监督图像分割" class="headerlink" title="6. 基于深度学习的弱监督图像分割"></a>6. 基于深度学习的弱监督图像分割</h2><p>有如下几种标住手段，从而不用一点一点描边缘：<br><img src="/../images/post13_images/c1d8aae1b9aa22b9117b9fd0757bde2f.png"></p><h1 id="八、识别"><a href="#八、识别" class="headerlink" title="八、识别"></a>八、识别</h1><h2 id="1-图像识别基本概念"><a href="#1-图像识别基本概念" class="headerlink" title="1. 图像识别基本概念"></a>1. 图像识别基本概念</h2><h3 id="（1）涉及到的任务"><a href="#（1）涉及到的任务" class="headerlink" title="（1）涉及到的任务"></a>（1）涉及到的任务</h3><ul><li>分类：二分类、多分类</li><li>检测：包含两个部分：定位+分类（先得到位置信息，再判断是啥东西）</li><li>分割；语义分割（例如，结合了语义描述，某个类别是人，另一个类别是狗。。）、实例分割（人和人不一样，小美小帅）</li><li>类别识别和单实例识别</li><li>行为或事件识别<blockquote><p>理解单实例：就比如拍了个华电西门，虽然都是门，但是花店西门跟别人家学校的门不一样，它就是门的一个单独的实例，具体它自己独立的含义~</p></blockquote></li></ul><h3 id="（2）图像识别算法应当解决的问题"><a href="#（2）图像识别算法应当解决的问题" class="headerlink" title="（2）图像识别算法应当解决的问题"></a>（2）图像识别算法应当解决的问题</h3><ul><li>对图像或视频进行分类（视频可以切成帧来做分类任务）</li><li>对物体进行检测和定位</li><li>评估语义和几何特征</li><li>分析人类的行为和事件</li></ul><h3 id="（3）图像识别的难点"><a href="#（3）图像识别的难点" class="headerlink" title="（3）图像识别的难点"></a>（3）图像识别的难点</h3><ul><li>种类问题——世界上那么多种类的事物，怎么才能学习到这么多种</li><li>视角问题——从不同的视角得到的同一个图像，怎么才能识别成功</li><li>光照问题——同一个图像的光照不同，怎么才能识别成功</li><li>尺度问题——怎么让算法能够对抗尺度变化（缩放）</li><li>形变问题——怎么让算法能够对抗形状的变化（一只小猫咪、一坨小猫咪、一条小猫咪、一摊小猫咪…….）</li><li>遮挡问题——怎么让算法能够对抗遮挡（带了口罩怎么才能认出我是我）</li><li>背景杂波问题——长得跟背景也太像了，咋区分呢，像下图这样<br><img src="/../images/post13_images/fe6edd4158b30643c0a627f3c0500f47.png"></li><li>人为设计问题——同样是椅子，有好多种设计形态呢，设计师灵感不灭，椅子形态总会更新</li></ul><h2 id="2-图像识别算法设计"><a href="#2-图像识别算法设计" class="headerlink" title="2. 图像识别算法设计"></a>2. 图像识别算法设计</h2><h3 id="（0）设计识别算法需要考虑的问题"><a href="#（0）设计识别算法需要考虑的问题" class="headerlink" title="（0）设计识别算法需要考虑的问题"></a>（0）设计识别算法需要考虑的问题</h3><ul><li>表达：怎么表达图像类别</li><li>学习：怎么学习给定的数据，得到模型</li><li>识别：怎么在崭新的数据上应用学习好的模型</li></ul><h3 id="（1）表达–Representation"><a href="#（1）表达–Representation" class="headerlink" title="（1）表达–Representation"></a>（1）表达–Representation</h3><h4 id="①-表达的方式"><a href="#①-表达的方式" class="headerlink" title="① 表达的方式"></a>① 表达的方式</h4><p>先划分成小块，有下面很多种划分成小块的方式：<br><img src="/../images/post13_images/330f1616751e8518f926160b710fb803.png"><br>然后放入一个词袋中（像一块拼图），可附加一些语义信息等（每个小块之间可能有关联，从而能根据这些关联拼凑出要识别的东西），拼凑出识别物体，从而表达了图像<br><img src="/../images/post13_images/d7cf7fa366f0df781a1f68c820704e59.png"></p><h4 id="②-理想的表达能具备的效果"><a href="#②-理想的表达能具备的效果" class="headerlink" title="② 理想的表达能具备的效果"></a>② 理想的表达能具备的效果</h4><h5 id="不变性（Invariance）"><a href="#不变性（Invariance）" class="headerlink" title="不变性（Invariance）"></a>不变性（Invariance）</h5><p>视角不变性、光照强度不变性、遮挡不变性、尺度不变性、形变不变性、背景杂波不变性……</p><h4 id="③-图像识别任务选取的模型"><a href="#③-图像识别任务选取的模型" class="headerlink" title="③ 图像识别任务选取的模型"></a>③ 图像识别任务选取的模型</h4><p>对于这种内类的变化（同一类别中不同样本之间的差异性，比如对于猫类，有狸花猫、布偶猫、奶牛猫…），<strong>概率模型</strong>更为有效<br>概率模型有下面三种</p><h5 id="a-生成式模型（Generative-Model）"><a href="#a-生成式模型（Generative-Model）" class="headerlink" title="a. 生成式模型（Generative Model）"></a>a. 生成式模型（Generative Model）</h5><blockquote><p>区分张三和李四，先知道他们都具体长啥样，然后区分开</p></blockquote><p>思想：建模数据本身的分布，学习“如何生成这个类别的样本”<br>根据先验（自然本身就有的规律）和似然来建模<br>常见模型：朴素贝叶斯、层次化贝叶斯（潜在迪利克雷分布）….</p><h5 id="b-判别式模型（Discriminative-Model）"><a href="#b-判别式模型（Discriminative-Model）" class="headerlink" title="b. 判别式模型（Discriminative Model）"></a>b. 判别式模型（Discriminative Model）</h5><blockquote><p>区分张三和李四，不管他俩长啥样，只要找到一个差异能分开他俩就行</p></blockquote><p>思想：直接学习类别之间的边界，不关心数据如何生成<br>根据后验（从结果观察到总结出的规律）来建模<br>常见模型：近邻分类法、神经网络、支持向量机及其衍生算法、Boosting…</p><h4 id="④-BoF（Bag-of-Features）方法"><a href="#④-BoF（Bag-of-Features）方法" class="headerlink" title="④ BoF（Bag of Features）方法"></a>④ BoF（Bag of Features）方法</h4><blockquote><p>借鉴了文本处理中的词袋BoW（Bag of Words）模型，将图像视为由多个局部特征组成的集合，类似于文档中的词汇</p></blockquote><h5 id="a-步骤"><a href="#a-步骤" class="headerlink" title="a. 步骤"></a>a. 步骤</h5><h6 id="i-特征提取"><a href="#i-特征提取" class="headerlink" title="i.特征提取"></a>i.特征提取</h6><ul><li>先提取图像特征，可以用规则网格，也可以用显著性检测只提取感兴趣区域<br><img src="/../images/post13_images/790ad64870e0931d3fdda655a407a070.png"></li><li>根据提取到的特征，用聚类算法（例如K-Means）进行聚类<br><img src="/../images/post13_images/6405c09e2018f6e4f3860ace791c73d9.png"></li></ul><h5 id="ii-学习“视觉词汇”"><a href="#ii-学习“视觉词汇”" class="headerlink" title="ii. 学习“视觉词汇”"></a>ii. 学习“视觉词汇”</h5><p><strong>码本生成（Codebook Learning）：刚才聚类得到的每个特征向量聚簇的聚类中心，称为码向量（Codevector），即视觉词汇；所有码向量构成码本（Codebook），即视觉词汇表（Visual Vocabulary）</strong><br>  <img src="/../images/post13_images/27d72fcc4d739d0e53b4f9678469d291.png"><br>涉及的问题与解决：</p><ul><li>词汇量选择：<ul><li>过小：视觉词无法覆盖所有特征（如蝴蝶翅膀纹理差异被忽略）</li><li>过大：量化噪声增加（相似特征被分到不同类），导致过拟合</li></ul></li><li>传统K-means聚类随词汇量增长计算量激增</li></ul><p>解决：</p><ul><li>词汇树（Vocabulary Trees, Nister &amp; Stewenius, 2006）：分层聚类结构，通过树状搜索加速最近邻匹配</li></ul><h5 id="iii-用“视觉词”频率表示图像"><a href="#iii-用“视觉词”频率表示图像" class="headerlink" title="iii. 用“视觉词”频率表示图像"></a>iii. 用“视觉词”频率表示图像</h5><ul><li>码本（视觉词汇表）可以表示图像</li><li>将新特征映射到码本中最接近的码向量索引（离散化表示），例如：特征向量→索引3（代表“车轮”视觉词）</li></ul><h5 id="c-混合模型（Hybrid-Model）"><a href="#c-混合模型（Hybrid-Model）" class="headerlink" title="c. 混合模型（Hybrid Model）"></a>c. 混合模型（Hybrid Model）</h5><p>思想：结合生成式与判别式模型的优势<br>平衡先验与后验，通过隐变量或联合优化融合两类模型优势</p><h3 id="（2）学习–-Learning"><a href="#（2）学习–-Learning" class="headerlink" title="（2）学习– Learning"></a>（2）学习– Learning</h3><p>关注的问题有：</p><ul><li>学习参数</li><li>监督信息的级别（手动分割、边界框、图像打标签、噪声标签）</li><li>批量（batch）/增量（incremental）</li><li>先验（领域知识、专业知识）</li><li>训练时可能遇到的问题：过拟合、负样本<blockquote><p>批量学习：一次性加载全部训练数据（如10000张图片），完成整个数据集遍历后才更新模型参数<br>增量学习：逐步接收新数据（如每天新增100张图片），每接收一个/小批样本就立即更新<br>负样本是指与目标类别相反的参照数据。它们的作用是帮助模型建立区分边界，通过对比学习使模型更精准地识别正样本。</p></blockquote></li></ul><h3 id="（3）识别–-Recognition"><a href="#（3）识别–-Recognition" class="headerlink" title="（3）识别– Recognition"></a>（3）识别– Recognition</h3><h4 id="①-识别任务"><a href="#①-识别任务" class="headerlink" title="① 识别任务"></a>① 识别任务</h4><p>见1.（1）</p><h4 id="②-搜索策略"><a href="#②-搜索策略" class="headerlink" title="② 搜索策略"></a>② 搜索策略</h4><p>滑动窗口，通过不同尺度（S）、位置（x,y）、旋转角度（θ）的窗口遍历图像</p><h4 id="③-搜索策略存在的问题"><a href="#③-搜索策略存在的问题" class="headerlink" title="③ 搜索策略存在的问题"></a>③ 搜索策略存在的问题</h4><h5 id="a-计算复杂度"><a href="#a-计算复杂度" class="headerlink" title="a. 计算复杂度"></a>a. 计算复杂度</h5><p>窗口数=位置(x,y)×尺度(S)×角度(θ)×类别(N)，导致计算量爆炸<br>解决：</p><ul><li>Lampert et al. BSW (2008)：基于分支定界法（Branch and Bound）的 BSW (Branch-and-Bound with Subwindows) 方法，通过智能剪枝减少无效窗口计算</li><li>Alexe et al. (2010)：改进候选区域生成（Objectness），预筛无关区域提升效率</li></ul><h5 id="b-定位困难"><a href="#b-定位困难" class="headerlink" title="b. 定位困难"></a>b. 定位困难</h5><p>传统检测方法默认用矩形框（Bounding Box）标注物体，但实际物体形状复杂（如弯曲的动物肢体、树枝、服装褶皱等）<br>矩形框无法贴合非规则物体边缘，且滑动窗口可能将相似纹理/颜色的背景区域误判为物体，导致误报<br>解决：</p><ul><li>非极大值抑制 NMS：合并重叠检测框，仅保留置信度最高的结果</li><li>用Canny边缘检测辅助：通过提取物体边缘轮廓（如狗与背景的边界），辅助判断检测框是否贴合真实形状（减少“框住空气”的误报）</li><li>引入语义分割技术：不再依赖矩形框，而是逐像素标注物体所属类别（如“狗”像素 vs “人”像素）</li></ul><h1 id="九、检测"><a href="#九、检测" class="headerlink" title="九、检测"></a>九、检测</h1><blockquote><p>聚焦于图像的位置→找一个模板，在图像中滑动窗口检测，区分是否存在我们要找的对象<br>【检测任务→分类任务（每个框是否有我们要找的对象）】</p></blockquote><h2 id="1-目标检测的难点"><a href="#1-目标检测的难点" class="headerlink" title="1. 目标检测的难点"></a>1. 目标检测的难点</h2><h3 id="（1）可能遇到的问题"><a href="#（1）可能遇到的问题" class="headerlink" title="（1）可能遇到的问题"></a>（1）可能遇到的问题</h3><p>可能受以下影响：</p><ul><li>光照强度</li><li>物体的姿势</li><li>背景杂波</li><li>遮挡</li><li>视角</li><li>非物体（即其他部分如背景）干扰</li><li>目标特征相似度</li><li>….</li></ul><h3 id="（2）设计算法需要解决的问题"><a href="#（2）设计算法需要解决的问题" class="headerlink" title="（2）设计算法需要解决的问题"></a>（2）设计算法需要解决的问题</h3><h4 id="①-如何高效搜索可能的对象"><a href="#①-如何高效搜索可能的对象" class="headerlink" title="① 如何高效搜索可能的对象"></a>① 如何高效搜索可能的对象</h4><p>可能需要成千上万的窗口，计算量庞大，怎么办</p><h4 id="②-特征的设计和评分"><a href="#②-特征的设计和评分" class="headerlink" title="② 特征的设计和评分"></a>② 特征的设计和评分</h4><ul><li>外观如何建模</li><li>哪些特征与要检测的对象有联系</li></ul><h4 id="③-怎么处理不同的视角"><a href="#③-怎么处理不同的视角" class="headerlink" title="③ 怎么处理不同的视角"></a>③ 怎么处理不同的视角</h4><ul><li>传统为不同的视角建立各自的检测模型</li></ul><h2 id="2-人脸检测-（Face-Detection）"><a href="#2-人脸检测-（Face-Detection）" class="headerlink" title="2. 人脸检测 （Face Detection）"></a>2. 人脸检测 （Face Detection）</h2><h3 id="（1）"><a href="#（1）" class="headerlink" title="（1）"></a>（1）</h3><p>基于滑动窗口法的人脸检测：</p><ul><li>一方面，框不断滑动位置，寻找人脸</li><li>另一方面，框也会不断更改尺寸，因为不知道人脸在图像中的大小<br><img src="/../images/post13_images/60d4a36ad7f3415204095a12bcd45695.png"></li></ul><h3 id="（2）人脸检测的难点"><a href="#（2）人脸检测的难点" class="headerlink" title="（2）人脸检测的难点"></a>（2）人脸检测的难点</h3><h4 id="①-滑动窗口计算量庞大"><a href="#①-滑动窗口计算量庞大" class="headerlink" title="① 滑动窗口计算量庞大"></a>① 滑动窗口计算量庞大</h4><p>成千上万的位置，太多了<br>解决：由于人脸在图像中是少量的，为了提高计算效率，希望在非面部窗口上花的时间越少越好</p><h4 id="②-怎么降低假阳性（False-Positive）"><a href="#②-怎么降低假阳性（False-Positive）" class="headerlink" title="② 怎么降低假阳性（False Positive）"></a>② 怎么降低假阳性（False Positive）</h4><p>False Positive：把不是人脸的检测成人脸了</p><h3 id="（3）Viola-Jones算法"><a href="#（3）Viola-Jones算法" class="headerlink" title="（3）Viola &amp; Jones算法"></a>（3）Viola &amp; Jones算法</h3><blockquote><p>基于boosting原理的人脸检测</p></blockquote><h4 id="①-Boosting"><a href="#①-Boosting" class="headerlink" title="①  Boosting"></a>①  Boosting</h4><h5 id="a-为什么选用Boosting"><a href="#a-为什么选用Boosting" class="headerlink" title="a. 为什么选用Boosting"></a>a. 为什么选用Boosting</h5><ul><li>能得到较鲁棒的分类器，且简单</li><li>是一个提供稀疏视觉特征选择的有效算法</li><li>易于实现，不需要外部优化工具、</li></ul><h5 id="b-原理-1"><a href="#b-原理-1" class="headerlink" title="b. 原理"></a>b. 原理</h5><p>图示：<br><img src="/../images/post13_images/d55ff588e6a832c0e6443ea860786f27.png"><br>公式：<br><img src="/../images/post13_images/6c7f1bf2f95db11aef1f47bd2938e52b.png"><br>其中：<br><img src="/../images/post13_images/d34375f418f3a3bbf17f4bd6112342f6.png"></p><h4 id="②-Viola-Jones算法核心特性"><a href="#②-Viola-Jones算法核心特性" class="headerlink" title="② Viola &amp; Jones算法核心特性"></a>② Viola &amp; Jones算法核心特性</h4><ul><li>实时目标检测的”范式级”方法</li><li>训练过程缓慢（需处理大量数据），但检测速度极快（适合实时应用）</li></ul><h4 id="③-Viola-Jones算法流程"><a href="#③-Viola-Jones算法流程" class="headerlink" title="③ Viola &amp; Jones算法流程"></a>③ Viola &amp; Jones算法流程</h4><h5 id="a-用积分图加速特征提取并获取弱分类器"><a href="#a-用积分图加速特征提取并获取弱分类器" class="headerlink" title="a. 用积分图加速特征提取并获取弱分类器"></a>a. 用积分图加速特征提取并获取弱分类器</h5><p>如图的四种矩形可以通过计算黑白区域像素差，来捕捉图像特征<br><img src="/../images/post13_images/58355c401c2248cd50585ced7b450db5.png"><br>特征太多了，24x24窗口内16万种特征，每个特征需遍历矩形内所有像素求和，直接计算每个特征的时间复杂度为O(n)，太耗时，于是我们采用下面的积分图加速：<br><strong>积分图每个点(x,y)存储的是其左上角所有像素值的和</strong><br>$I_{\sum}(x, y) = \sum_{x’ \leq x, y’ \leq y} i(x’, y’)$<br><img src="/../images/post13_images/7930469d81f30978bcba465eaf2c0fad.png"><br>则对于任意矩形区域，就可以很快求得积分值了：<br><img src="/../images/post13_images/abb903bb5f8772dfeb7bb594cb811463.png"></p><h5 id="b-引入Boosting思想构建强分类器"><a href="#b-引入Boosting思想构建强分类器" class="headerlink" title="b. 引入Boosting思想构建强分类器"></a>b. 引入Boosting思想构建强分类器</h5><h6 id="i-构建最优弱分类器–最优滤波器-阈值组合"><a href="#i-构建最优弱分类器–最优滤波器-阈值组合" class="headerlink" title="i. 构建最优弱分类器–最优滤波器+阈值组合"></a>i. 构建最优弱分类器–最优滤波器+阈值组合</h6><p>针对每个矩形特征（如$α₁$），计算其在所有样本上的响应值（$fⱼ(x)$）是否大于阈值 $\theta <em>j$，是则 $h_j(x)=1$，否则$h_j(x)=0$<br><img src="/../images/post13_images/58a759a10af3ab64e76161d7e926d660.png"><br>对权重归一化：$w</em>{t,i} \leftarrow \frac{w_{t,i}}{\sum_{j}^{n} w_{t,j}}$<br>对每个滤波器 $j$，计算所有样本的特征值 $fⱼ(x)$，并遍历候选 $θ$，选择使分类误差最小的 $θⱼ$<br>对每个$hⱼ(x)$和对应的$θⱼ$，计算其在当前权重下的误差$εⱼ$<br>$$\varepsilon_j = \sum_{i} w_i |h_j(x_i) - y_i|$$<br>选择 $εⱼ$ 最小的 $hⱼ(x)$ 作为本轮最优弱分类器 $hₜ$</p><h6 id="ii-重新设置权重"><a href="#ii-重新设置权重" class="headerlink" title="ii. 重新设置权重"></a>ii. 重新设置权重</h6><p>计算调整因子 $βₜ$ ：<br>$$\beta_t = \frac{\varepsilon_t}{1 - \varepsilon_t}$$<br>更新样本权重：<br>$$w_{t+1,i} \leftarrow w_{t,i} \beta_t^{1 - |h_t(x_i) - y_i|}$$</p><blockquote><p>解读一下 $βₜ$ 的意义：<br>对第 $t$ 个样本的，当前弱分类器表现很差（误差大），那么我们是想要让这些分类错误的样本在后面更受关注，分类正确的就不管了，所以如果 $\epsilon _t$ 很小（分的对），那么就应该让它的权重变小。<br>我们的公式，如果 $\epsilon _t$ 很小，$βₜ → 0$，再看更新样本权重的公式，就可以看出正确样本的权重很小了，则错误样本的权重就相对来说大了。<br>注意，这里并不是提高了错误样本的权重，而是降低正确分类样本的权重。</p></blockquote><h6 id="iii-得到强分类器"><a href="#iii-得到强分类器" class="headerlink" title="iii. 得到强分类器"></a>iii. 得到强分类器</h6><p>$$h(x) = \begin{cases}<br>1 &amp; \sum_{t=1}^{T} \alpha_t h_t(x) &gt; \frac{1}{2} \sum_{t=1}^{T} \alpha_t \<br>0 &amp; \text{otherwise}<br>\end{cases}$$<br>其中：$\alpha_t = \log \frac{1}{\beta_t}$，$\beta_t = \frac{\varepsilon_t}{1 - \varepsilon_t}$</p><h5 id="c-利用注意力级联机制快速去除负样本"><a href="#c-利用注意力级联机制快速去除负样本" class="headerlink" title="c. 利用注意力级联机制快速去除负样本"></a>c. 利用注意力级联机制快速去除负样本</h5><p>是一个逐步筛除的过程：<br><img src="/../images/post13_images/0cc6573e2a5d34a083fe7bc1472200aa.png"><br>简单来说，就是一次比一次精细，每次只关注上次不确定的那些样本，这样能够在最开始快速去除很多负样本,并一点一点逐渐降低误报：<br><img src="/../images/post13_images/cf19064f1c660dbe27c5c6deb4d570d4.png"></p><h2 id="3-行人检测（Pedestrian-Detection）"><a href="#3-行人检测（Pedestrian-Detection）" class="headerlink" title="3. 行人检测（Pedestrian Detection）"></a>3. 行人检测（Pedestrian Detection）</h2><h3 id="（1）HOG特征"><a href="#（1）HOG特征" class="headerlink" title="（1）HOG特征"></a>（1）HOG特征</h3><p>HOG特征（方向梯度直方图，Histogram of Oriented Gradients） 是一种用于目标检测的传统图像特征描述方法，由Navneet Dalal和Bill Triggs于2005年提出，尤其在行人检测领域表现突出。其核心思想是通过统计图像局部区域的梯度方向分布来描述物体轮廓和形状特征。</p><h3 id="（2）Dalal-Triggs-行人检测流程"><a href="#（2）Dalal-Triggs-行人检测流程" class="headerlink" title="（2）Dalal-Triggs 行人检测流程"></a>（2）Dalal-Triggs 行人检测流程</h3><h4 id="①-滑动窗口提取"><a href="#①-滑动窗口提取" class="headerlink" title="① 滑动窗口提取"></a>① 滑动窗口提取</h4><p>在多尺度图像金字塔上，以64x128窗口滑动遍历所有位置</p><h4 id="②-HOG特征计算"><a href="#②-HOG特征计算" class="headerlink" title="② HOG特征计算"></a>② HOG特征计算</h4><blockquote><p>计算方式PPT里没有，但在这里写一下：</p></blockquote><blockquote><p>1.图像预处理：</p><ul><li>转为灰度图，并进行伽马校正（减少光照影响）。</li><li>（可选）调整图像尺寸，统一输入尺度。</li></ul></blockquote><blockquote><p>2.计算梯度：</p><ul><li>使用水平 ($G_x$) 和垂直 ($G_y$) 方向的Sobel算子计算每个像素的梯度：<br>  梯度幅值 = $\sqrt{G_x^2 + G_y^2}$,   梯度方向 = $\arctan\left(\frac{G_y}{G_x}\right)$</li></ul></blockquote><blockquote><p>3.划分细胞单元（Cell）：</p><ul><li>将图像划分为多个小单元（如8×8像素的Cell）。</li><li>对每个Cell内的像素，统计其梯度方向直方图（通常分为9个方向区间，即0°<del>180°或0°</del>360°）。</li></ul></blockquote><blockquote><p>4.块（Block）归一化：</p><ul><li>将相邻的多个Cell组合成一个Block（如2×2的Cell组成16×16像素的Block）。</li><li>对Block内所有Cell的直方图进行归一化（如L2归一化），增强对光照和对比度的鲁棒性。</li></ul></blockquote><blockquote><p>5.生成特征向量：</p><ul><li>所有Block的归一化直方图按顺序拼接，形成最终的高维特征向量（例如，64×128的图像按8×8 Cell划&gt;分，每个Block滑动步长8像素，最终特征维度为7×15×36=3780）</li></ul></blockquote><p>对每个窗口提取3780维HOG特征</p><h4 id="③-线性SVM分类"><a href="#③-线性SVM分类" class="headerlink" title="③ 线性SVM分类"></a>③ 线性SVM分类</h4><p>使用预训练的SVM权重向量w对窗口打分（：$Score=w^T⋅HOG特征向量+b$）<br>分数高于阈值则判定为行人</p><h4 id="④-非极大值抑制"><a href="#④-非极大值抑制" class="headerlink" title="④ 非极大值抑制"></a>④ 非极大值抑制</h4><p>在连续响应图上寻找局部最大值，合并重叠检测框</p><h2 id="4-统计模板方法的优缺点"><a href="#4-统计模板方法的优缺点" class="headerlink" title="4. 统计模板方法的优缺点"></a>4. 统计模板方法的优缺点</h2><p>统计模板方法是一类基于手工设计特征与统计学习的目标检测/识别算法，通过分析目标在图像中的统计分布规律（如边缘方向、纹理对比度），构建数学化的特征模板，并利用分类器（如SVM、Adaboost）进行匹配决策。其核心特点是数据驱动但依赖人工先验知识<br>例如上面的HOG+SVM、Viola-Jones</p><h3 id="（1）优点"><a href="#（1）优点" class="headerlink" title="（1）优点"></a>（1）优点</h3><ul><li>在检测具有标准方向（典型、固定的视角等）的非可变形对象（人脸、汽车、行人）的任务上，表现不错</li><li>检测很快</li></ul><h3 id="（2）缺点"><a href="#（2）缺点" class="headerlink" title="（2）缺点"></a>（2）缺点</h3><ul><li>对于高度可变形的事物（比如猫咪，太软了啥形态都有），检测效果可能不太好</li><li>抗遮挡能力不强</li><li>需要大量的训练数据</li></ul><h1 id="十、跟踪"><a href="#十、跟踪" class="headerlink" title="十、跟踪"></a>十、跟踪</h1><p>考试不考，时间精力原因暂不梳理</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 目标检测 </tag>
            
            <tag> 边缘检测 </tag>
            
            <tag> 特征提取 </tag>
            
            <tag> 图像分割 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C盘容量可视化与C盘清理</title>
      <link href="/2025/04/16/post12/"/>
      <url>/2025/04/16/post12/</url>
      
        <content type="html"><![CDATA[<blockquote><p>声明：本博客不为任何读者错误迁移C盘文件导致的系统崩溃负责，自己搞坏了别说我<br>如果下载连接进不去记得科学上网</p></blockquote><h1 id="1-C盘容量可视化软件WizTree"><a href="#1-C盘容量可视化软件WizTree" class="headerlink" title="1. C盘容量可视化软件WizTree"></a>1. C盘容量可视化软件WizTree</h1><p><a href="https://diskanalyzer.com/download">点击下载WizTree</a><br>这个主要是能看一下C盘的占用结构，如图所示哈：<br><img src="/../images/31.png" alt="WizTree" title="WizTree"><br>当然类似的软件也不少，比如windirstat，SpaceSniffer，因为都差不多所以就不多说了。<br>对于这种软件，每次启动都得给管理员权限。WizTree如果你忘记用管理员权限打开了，界面左上角会有按钮的，按一下就以管理员模式重启了。</p><h1 id="2-C盘文件迁移软件FreeMove"><a href="#2-C盘文件迁移软件FreeMove" class="headerlink" title="2. C盘文件迁移软件FreeMove"></a>2. C盘文件迁移软件FreeMove</h1><p><a href="https://github.com/imDema/FreeMove/releases/tag/2.1.0">点击下载FreeMove</a><br>下载FreeMove.exe就可以啦。<br>选择路径，直接迁移。<br><img src="/../images/32.png" alt="FreeMove" title="FreeMove"></p><blockquote><p>这么做的原理：<br>①符号链接技术（Symbolic Links）<br>FreeMove通过将文件或文件夹物理移动到新位置后，在原路径创建一个系统级符号链接（类似于智能快捷方式），将所有对旧路径的访问请求自动重定向到新位置。<br>例如：将 C:\Program Files\App 迁移到 D:\App 后，原路径会生成一个符号链接，系统仍会认为程序位于C盘，但实际文件已转移至D盘。<br>②无需修改注册表<br>传统手动迁移可能导致注册表路径错误，但FreeMove的符号链接机制绕过了直接修改注册表的需求。系统仍通过原路径访问文件，而符号链接已在底层完成路径转换。<br>保持文件结构完整性<br>③迁移过程中，FreeMove会完整保留文件夹层级和文件关联性，确保程序依赖的配置文件、动态链接库（DLL）等仍能正确调用。</p></blockquote><h1 id="3-什么不能迁移"><a href="#3-什么不能迁移" class="headerlink" title="3. 什么不能迁移"></a>3. 什么不能迁移</h1><h2 id="作者提示的"><a href="#作者提示的" class="headerlink" title="作者提示的"></a>作者提示的</h2><ul><li>C:\Users</li><li>C:\用户</li><li>C:\Documents and Settings</li><li>C:\Program Files</li><li>C:\Program Files (x86)<br>（是说根目录不可以迁移，而不是说这些目录下的子目录。）<br>（例如C:\Program Files\xxxxxxx，xxxxxxx就可以迁移）</li></ul><h2 id="个人认为也不能迁移的"><a href="#个人认为也不能迁移的" class="headerlink" title="个人认为也不能迁移的"></a>个人认为也不能迁移的</h2><ul><li>C:\WINDOWS</li><li>C:\windows</li><li>C:\ProgramData<br>……<br>（反正我感觉这些根目录都不适合迁移，也不敢以身犯险哈）</li></ul><h2 id="其他你拿不准的"><a href="#其他你拿不准的" class="headerlink" title="其他你拿不准的"></a>其他你拿不准的</h2><p>有很多文件挺大的但是不知道干啥用的，可以先搜搜，再迁移</p>]]></content>
      
      
      <categories>
          
          <category> 工具设置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
            <tag> github </tag>
            
            <tag> 磁盘处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>下载工具NDM与cvefixes数据集的获取建议</title>
      <link href="/2025/04/15/post11/"/>
      <url>/2025/04/15/post11/</url>
      
        <content type="html"><![CDATA[<p>起因是今天完善竞赛作品想整多语言的漏洞数据集，恰好找到了这个：<a href="https://github.com/secureIT-project/CVEfixes">cvefixes</a><br>感觉应该还可以，打算先试试手，但是11个G，下的也太慢了。<br>然后就想起来之前我看见过NDM这个下载软件，当时记得性能不错，今天一用，果真快了不少。</p><h1 id="NDM"><a href="#NDM" class="headerlink" title="NDM"></a>NDM</h1><h2 id="下载连接"><a href="#下载连接" class="headerlink" title="下载连接"></a>下载连接</h2><p><a href="https://neatdownload.com/">NDM下载链接</a></p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>因为我是下外面的东西，所以得科学上网，正好NDM有给配置代理的地方。<br>在 <code>Settings --&gt; Proxy/Socks</code> 中设置一下就好，clash的端口号自己去clash看一下<br><img src="/../images/30.png" alt="配置代理" title="配置代理"></p><h1 id="cvefixes"><a href="#cvefixes" class="headerlink" title="cvefixes"></a>cvefixes</h1><p>用不了，用不了，一般电脑用不了。实际的sql文件就有46G了，当我运行sqlite3指令的时候根本无法创建数据库，一开始以为问题出在我的运行环境上，在gitbash和conda里都试了，甚至弄了个脚本，最终发现问题就出现在内存上，每次都终止了然后输出一大串乱码。<br>哎，+我的小破电脑内存完全不够，咱还是不遭这个罪了，我去找别的数据集了QaQ…</p>]]></content>
      
      
      <categories>
          
          <category> 工具设置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
            <tag> github </tag>
            
            <tag> 下载 </tag>
            
            <tag> 漏洞数据集 </tag>
            
            <tag> 数据集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster R-CNN 源码与流程分析（ResNet50为例）</title>
      <link href="/2025/04/13/post10/"/>
      <url>/2025/04/13/post10/</url>
      
        <content type="html"><![CDATA[<p>这篇分析贴由于精力有限，没有涉及到utils包下的自定义的模块，主要对主文件夹和net文件夹下的文件进行解析，大致能顺下来训练和预测的整体流程。<br>目录结构：<br><img src="/../images/post10_images/0.png" alt="目录结构" title="目录结构"></p><h1 id="（一）train-py"><a href="#（一）train-py" class="headerlink" title="（一）train.py"></a>（一）train.py</h1><blockquote><p>我们的流程肯定是训练模型后利用模型预测，所以train.py就是程序的主入口之一，先训练。<br>待会会将train.py涉及到调用的其他文件的类、函数等逐一插入解释。</p></blockquote><p>先导入了一些包以及我们自定义的类方法，这部分比较详细，直接阅读：<br><img src="/../images/post10_images/1.png" alt="图1" title="图1"><br>设置Cuda、种子（保证结果可重复）、用到的gpu数、是否采取混合精度训练、类别名称文件路径（就是指定有哪些要预测的类别）、预训练权重路径、输入图片大小、主干网络类型、是否使用预训练权重、锚框大小、冻结阶段训练参数、是否进行冻结训练、学习率、优化器等等基本参数。直接看图：<br><img src="/../images/post10_images/2.png" alt="图2" title="图2"><br><img src="/../images/post10_images/3.png" alt="图3" title="图3"><br><img src="/../images/post10_images/4.png" alt="图4" title="图4"><br><img src="/../images/post10_images/5.png" alt="图5" title="图5"><br>上面都是基本的参数设置，下面开始真正有关模型训练的部分。下面这张图，首先创建了一个模型实例，加载好resnet50的权重。<br><img src="/../images/post10_images/6.png" alt="图6" title="图6"><br>而创建模型实例是FasterRCNN类的实例，这个是从net文件夹下的frcnn.py导入的。下面分析net.frcnn.py以及FasterRCNN类的代码。</p><h2 id="1-net-frcnn-py"><a href="#1-net-frcnn-py" class="headerlink" title="1. net.frcnn.py"></a>1. net.frcnn.py</h2><p>结合刚才创建实例的那行代码，可以看到，要初始化一个FasterRCNN网络，需要传入：类别总数、模式、特征步长、锚框尺度、锚框高宽比、骨干网络、预训练标志。其中我们创建实例的时候，没有传入模式、特征步长、锚框高宽比，因此这三个参数将使用默认的参数。<br>由于我们传入的骨干网络是resnet50，会走下图的resnet50的分支，构建RPN网络。<br>我们待会再说RPN网络的问题，先说前向传播函数。在前向传播函数中，利用resnet50提取图像特征（self.extractor就是resnet50的extractor），然后利用上面构建的RPN网络获取建议框，并获取头部网络的分类结果和回归结果。<br><img src="/../images/post10_images/7.png" alt="图7" title="图7"><br>然后说回RPN网络的构建。可以看到调用了<strong>net.resnet50.py的resnet50，net.rpn的RegionProposalNetwork，net.classifier.py的Resnet50RoIHead</strong>，我们逐个研究一下。<br>（在研究之前，把net.frcnn.py的剩余部分展示如图8，由于我们在文件里指定了forward的mode是forward，所以会走完整的流程，图8的分解步骤没有调用到，就不讲解了，有兴趣看图~）<br><img src="/../images/post10_images/8.png" alt="图8" title="图8"></p><h3 id="①-net-resnet50-py"><a href="#①-net-resnet50-py" class="headerlink" title="① net.resnet50.py"></a>① net.resnet50.py</h3><p>下面的图9和图10非常详细地解释了resnet50的网络结构：<br><img src="/../images/post10_images/9.png" alt="图9" title="图9"><br><img src="/../images/post10_images/10.png" alt="图10" title="图10"><br>我们着重看图11，能看到刚才调用的resnet50函数出现在最后几行中。<br>resnet50函数首先实例化了一个模型，这个模型由传入Bottleneck残差块的ResNet类实现。<br>其次，if pretrained分支我们不会进入，因为我们本身就在外部定义过了model_path<br>在我们实例化ResNet类的时侯，其实已经走了forward前向传播，这在下面的图11中可以看到。所以直接用list获取了features和classifier，分别是特征提取部分和分类部分，转换成了Sequential模块并返回了。<br>也就是说，如果我们传入一些参数给resnet50函数，由于上层的ResNet类设置了完整的结构以及前向传播过程，我们就可以得到一个具备功能（还没有输入图像，但一旦给了图像，也就是ResNet类下forward函数中的参数x，那就可以获取结果了）的resnet50模型了。<br><img src="/../images/post10_images/11.png" alt="图11" title="图11"><br>所以我们可以回看一眼下面的图7的一些部分，在左下角，获取的extractor实际上是resnet50函数返回的features，classifer就是resnet50函数返回的classifier；在右侧的forward模式中，第73行，self.extractor.forward(x)就是ResNet类中的forward函数，传入了图像x，提取得到了特征部分。<br>从图7中也可以看到特征部分的应用，就是在下面放到self.rpn.forward和self.head.forward中。<br><img src="/../images/post10_images/7.png" alt="图7" title="图7"></p><h3 id="②-net-rpn-py"><a href="#②-net-rpn-py" class="headerlink" title="② net.rpn.py"></a>② net.rpn.py</h3><p>下面我们分析上面图7右上角的部分。<br>这块有点乱，说到哪个图读者可以用snipaste截图一下钉在桌面上方便看。<br>图12到图14的上半部分定义了一个ProposalCreator类，它是为了生成建议框的。由于它是被下面的主要类RegionProposalNetwork调用实例化的类，我们先看RegionProposalNetwork，也就是图14的下半部分到图16。</p><h4 id="RegionProposalNetwork"><a href="#RegionProposalNetwork" class="headerlink" title="RegionProposalNetwork"></a>RegionProposalNetwork</h4><p>对比图7和图14下半部分，也就是看实例化的时候传入的参数，可以发现，锚框的尺度使用了类定义的默认值，其他都是由我们输入的，没有走默认值。<br>这个RegionProposalNetwork首先就生成基础先验框，调用的generate_anchor_base函数是一个现成的函数。<br>然后定义了几个卷积核，从图中可以看到是准备给不同任务的卷积核。<br>然后重头戏是下面的forward函数。在我们原来的图7中的forward函数，存在self.rpn.forward获得建议框，因此实际功能就在下面的这个forward函数实现了。<br>forward函数把我们的图像x先走了3×3的卷积核，提取特征，然后又分别走了两个1×1的卷积核，分别用于回归任务和分类任务。其中对于分类任务，我们还走了一个softmax，得到分类的分数。<br>到此为止，forward函数在回归任务上获取了一下偏移量，在分类任务上获取了得分，分类任务完事了。<br>接下来，forward函数先调用_enumerate_shifted_anchor生成锚框，这个是一个简单的锚框生成，是现成的函数。然后锚框出来了，接着就是要根据偏移量来接近实例，实现回归的目的。图14的第135行实例化了我们图12到图14定义的类ProposalCreator，所以在这里可以看到用的是proposal_layer这个实例化后的结果。<br>这个proposal_layer就直接生成了建议框，也就是根据偏移量得到的接近实例的锚框。<br>而这个proposal_layer，也就是类ProposalCreator，是如何生成锚框的，下面我们分析一下。<br><img src="/../images/post10_images/14.png" alt="图14" title="图14"><br><img src="/../images/post10_images/15.png" alt="图15" title="图15"><br><img src="/../images/post10_images/16.png" alt="图16" title="图16"></p><h4 id="ProposalCreator"><a href="#ProposalCreator" class="headerlink" title="ProposalCreator"></a>ProposalCreator</h4><p>ProposalCreator也就包含init和call两个部分，call部分是实际实现功能的部分。<br>我们对call部分着重看一下，在图13到图14。<br>简单来说，这里使用了loc2bbox这个现成的函数，把RPN网络预测的偏移量（上面的回归任务的结果）应用到锚框上，得到建议框的坐标。然后这个类还做了非极大值抑制这个环节，通俗点就是保留更好的锚框。其余就是一些异常情况处理等。看图即可。<br><img src="/../images/post10_images/12.png" alt="图12" title="图12"><br><img src="/../images/post10_images/13.png" alt="图13" title="图13"><br><img src="/../images/post10_images/14.png" alt="图14" title="图14"></p><h3 id="③-net-classifier-py"><a href="#③-net-classifier-py" class="headerlink" title="③ net.classifier.py"></a>③ net.classifier.py</h3><p>隔得有点久了，我们回到图7。上面我们解释了利用主干网络提取到特征，然后利用把这个特征传入RPN网络得到建议框。现在还差最后一个部分没有解析，也就是Resnet50RoIHead这个类，这个才会给出最终的分类结果和回归结果。<br><img src="/../images/post10_images/7.png" alt="图7" title="图7"><br>在分析之前，我们得关注一下，其实图7中所示的forward函数是层层递进的，提取特征、获取建议框、同时这建议框的坐标也要传到classifier（从第63行可以看到真正实现功能的部分就是classifier）获取最终的结果。<br><strong>虽然rpn部分也给出了一个建议框，但是需要注意的是它是针对二分类的，即前景和背景的区别，而不是目标检测的多分类的。classifier是在rpn的结果的基础上进一步调整，得到最终的分类</strong><br>下面的图中，从图18的中间开始看，因为之前的是VGG16的，不是我们使用的ResNet的。</p><hr><p><img src="/../images/post10_images/17.png" alt="图17" title="图17"><br>简单来说，classifier接收特征图（backbone提取的特征）和接收RPN网络生成的区域建议（ROIs）以及ROI对应的批次索引。然后使用ROIPool从特征图中提取固定大小的特征，将不同大小的ROI区域映射到特征图上，并提取对应区域的特征，将这些特征调整为固定大小（7×7）后征展平为一维向量。<br>然后，通过一系列全连接层（从ResNet50中提取的）处理这些特征，提取更高级的语义特征。<br>最后，在分类任务上通过全连接层预测每个ROI属于各个类别的概率，在回归任务上通过全连接层预测每个类别的边界框调整参数（参数用于精确调整ROI的位置和大小）。<br><img src="/../images/post10_images/18.png" alt="图18" title="图18"><br><img src="/../images/post10_images/19.png" alt="图19" title="图19"><br>至此我们获得了：某个图片属于某个类的分数以及边界框回归参数。</p><h2 id="2-继续train-py"><a href="#2-继续train-py" class="headerlink" title="2. 继续train.py"></a>2. 继续train.py</h2><p>隔得太远了，刚才是图6这里（见下），实例化model所关联的所有代码。可以看到，这个模型就差输入了，只要输入图片，就能得到”某个图片属于某个类的分数以及边界框回归参数“<br><img src="/../images/post10_images/6.png" alt="图6" title="图6"><br>我们继续，图20的内容很简单，就是继续配置硬件环境以及获取我们的数据集。<br><img src="/../images/post10_images/20.png" alt="图20" title="图20"><br>在下面的图21中，我们设置训练步长和冻结训练参数。<br>训练步长是指模型参数更新的总次数，也就是进行梯度下降的总次数。设置训练步长是为了确保模型有足够的参数更新次数来学习数据集中的模式。<br>在冻结训练上，我们是启用了的，然后先让它冻结住，冻结 特征提取网络 的 参数（这样反向传播的时候不会更新了），同时调用freeze.bn冻结bn层，这个函数在图8的最后几行。<br>BN层（归一化层）在训练时会计算并更新每个mini-batch的均值和方差，而在测试时使用整个训练集的统计量。冻结BN层意味着即使在训练模式下，也使用之前计算好的统计量而不再更新。<br><img src="/../images/post10_images/21.png" alt="图21" title="图21"><br>图22首先展示了批次大小、学习率、优化器等的设置，为训练的启动做准备。<br>然后提取了数据集，并生成训练集和验证集。<br>然后创建了FasterRCNNTrainer对象，这个类是在fcrnn_training.py中定义的，我们待会会在第3部分讨论。<br>最后是实例化一个能记录map曲线、评估模型性能的类，这个对象在后面会用到。<br>也就是这个train_util和eval_callback马上就要在训练中用到了。<br><img src="/../images/post10_images/22.png" alt="图22" title="图22"></p><h2 id="3-fcrnn-training-py"><a href="#3-fcrnn-training-py" class="headerlink" title="3. fcrnn_training.py"></a>3. fcrnn_training.py</h2><ul><li>frcnn_training.py 文件实现了 Faster RCNN 的训练过程，包括以下内容：<br>计算边界框之间的 IoU，将边界框转换为回归目标；<br>为 RPN 网络生成训练目标，为 RoI 头部网络生成训练目标；<br>FasterRCNNTrainer类实现 Faster RCNN 的训练过程，包括损失计算和参数更新；<br>初始化网络权重、生成学习率调度函数、更新优化器的学习率等辅助函数</li><li>特别值得注意的是，Faster RCNN 的训练涉及多个损失函数：</li><li><ul><li>RPN 的分类损失：判断锚框是否包含物体</li></ul></li><li><ul><li>RPN 的回归损失：调整锚框位置和大小</li></ul></li><li><ul><li>RoI 头部的分类损失：判断区域建议的类别</li></ul></li><li><ul><li>RoI 头部的回归损失：精细调整边界框位置和大小<br>这些损失函数共同优化，使得模型能够准确地检测和定位图像中的物体。</li></ul></li></ul><p>我们来看一看具体的代码：<br>图23定义了交并比IoU的计算函数和边界框坐标转换函数，分别用于去除重复度较高锚框和转换回归目标（得到和实际样本的偏移）。<br><img src="/../images/post10_images/23.png" alt="图23" title="图23"><br>图24和图25定义了一个类，AnchorTargetCreator，用于为RPN网络生成训练目标。这块主要是计算锚框和实际样本的接近程度，找到最匹配的那个，分配给真实框。（也就是这么多锚框，找一个跟真实最近的。）不要忘记RPN只是来做二分类的，前景/背景的锚框~<br><img src="/../images/post10_images/24.png" alt="图24" title="图24"><br><img src="/../images/post10_images/25.png" alt="图25" title="图25"><br>图26和图27定义了一个类，ProposalTargetCreator，用于为RoI头部网络生成训练目标。这个类要为每个RoI建议框分配最匹配的真实框和标签。怎么找到最匹配的呢？某个建议框和每个真实框都要计算IoU，argmax一下就好啦。同时，这个类将IoU大于正样本阈值的RoI建议框作为正样本，而可能有很多个正样本（很多建议框都指向这个真实框了），那么在图27中，限制了数量。<br>其他相关的内容看图即可，非常详细。<br><img src="/../images/post10_images/26.png" alt="图26" title="图26"><br><img src="/../images/post10_images/27.png" alt="图27" title="图27"><br>图27开始到图31展示FasterRCNNTrainer类的构造。这个类实现了训练过程。总体来说：<br>首先进行了初始化：接收模型和优化器、设置RPN和RoI的sigma参数、创建锚框目标生成器和建议框目标生成器、设置位置归一化标准。<br>然后前向传播：使用骨干网络提取图像的共享特征、使用RPN网络生成区域建议、拿到批次中的每张图像的属性值、为RPN网络生成训练目标、计算RPN网络的回归损失和分类损失、为分类器网络生成训练目标、使用分类器网络处理ROI、计算分类器网络的回归损失和分类损失、汇总所有损失并返回。<br>最后到训练更新阶段：清零梯度、执行前向传播计算损失、执行反向传播、更新模型参数、混合精度训练。<br>看图吧：<br><img src="/../images/post10_images/28.png" alt="图28" title="图28"><br><img src="/../images/post10_images/29.png" alt="图29" title="图29"><br><img src="/../images/post10_images/30.png" alt="图30" title="图30"><br><img src="/../images/post10_images/31.png" alt="图31" title="图31"></p><h2 id="继续train-py"><a href="#继续train-py" class="headerlink" title="继续train.py"></a>继续train.py</h2><p>接下来就回到train.py的最后部分啦，这里开始调用相关函数进行训练了。<br>从0开始训练，先训练到解冻，再从解冻训练到结束，在这期间自适应调整学习率。<br>需要注意在最后的最后，图33的第455行，给fit_one_epoch传入了train_util，这个train_util就是我们刚才说的frcnn_training中FasterRCNNTrainer类的实例化对象。而fit_one_epoch是utils.utils_fit.py中的函数，就是将 frcnn_training与数据加载、损失记录、模型评估和保存等功能连接起来，形成一个完整的训练系统。<br><img src="/../images/post10_images/32.png" alt="图32" title="图32"><br><img src="/../images/post10_images/33.png" alt="图33" title="图33"></p><h1 id="（二）predict-py"><a href="#（二）predict-py" class="headerlink" title="（二）predict.py"></a>（二）predict.py</h1><p>集成了四种不同的预测模式：单张图片预测(predict)、视频检测(video)、FPS性能测试(fps)和批量文件夹预测(dir_predict)。<br>可以通过修改 mode 参数来选择不同的预测方式，对图像或视频中的目标进行检测，并可以选择是否对检测结果进行裁剪、计数或保存。该文件是模型训练完成后进行实际应用的重要工具。<br><img src="/../images/post10_images/34.png" alt="图34" title="图34"><br><img src="/../images/post10_images/35.png" alt="图35" title="图35"><br><img src="/../images/post10_images/36.png" alt="图36" title="图36"><br><img src="/../images/post10_images/37.png" alt="图37" title="图37"></p><h1 id="（三）其他文件"><a href="#（三）其他文件" class="headerlink" title="（三）其他文件"></a>（三）其他文件</h1><p>下面是一些并没有在训练、预测流程中实际调用的，但起到项目的辅助作用，或只是没有被调用到。</p><h2 id="1-net-vgg16-py"><a href="#1-net-vgg16-py" class="headerlink" title="1. net.vgg16.py"></a>1. net.vgg16.py</h2><p>vgg16网络，和上面的resnet50是对应的，不过我们的案例中使用的是resnet，所以vgg16没有调用。<br>见图38、图39:<br><img src="/../images/post10_images/38.png" alt="图38" title="图38"><br><img src="/../images/post10_images/39.png" alt="图39" title="图39"></p><h2 id="2-voc-annotation-py"><a href="#2-voc-annotation-py" class="headerlink" title="2. voc_annotation.py"></a>2. voc_annotation.py</h2><p>这是数据准备阶段的工具，用于处理VOC格式的数据集，生成训练和验证所需的标签文件。在开始训练前需要手动运行此文件来准备数据。<br>见图40到图43：<br><img src="/../images/post10_images/40.png" alt="图40" title="图40"><br><img src="/../images/post10_images/41.png" alt="图41" title="图41"><br><img src="/../images/post10_images/42.png" alt="图42" title="图42"><br><img src="/../images/post10_images/43.png" alt="图43" title="图43"></p><h2 id="3-get-map-py"><a href="#3-get-map-py" class="headerlink" title="3. get_map.py"></a>3. get_map.py</h2><p>这是模型评估工具，用于计算模型在测试集上的mAP（平均精度均值）。训练完成后，可以手动运行此文件来评估模型性能。<br>见图44到图46：<br><img src="/../images/post10_images/44.png" alt="图44" title="图44"><br><img src="/../images/post10_images/45.png" alt="图45" title="图45"><br><img src="/../images/post10_images/46.png" alt="图46" title="图46"></p><h2 id="4-summary-py"><a href="#4-summary-py" class="headerlink" title="4. summary.py"></a>4. summary.py</h2><p>这是网络结构分析工具，用于查看模型的结构、参数量和计算量(FLOPS)。在设计或修改网络时可以运行此文件来分析模型复杂度。<br>见图47：<br><img src="/../images/post10_images/47.png" alt="图47" title="图47"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 目标检测 </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续分享我爱的音乐</title>
      <link href="/2025/04/06/post9/"/>
      <url>/2025/04/06/post9/</url>
      
        <content type="html"><![CDATA[<p><strong>最近最爱：</strong></p><ul><li><a href="https://music.163.com/#/song?id=2636170762">安静 - misa</a> 后来我发现我最爱的国内90s’rnb歌手中，最喜欢的音色是misa嘟</li><li><a href="https://music.163.com/song?id=2632851533&amp;uct2=U2FsdGVkX18xZ+gs5eZEujaU/qm+p6PdEmQt3Leq4iE=">summer depression - ArukuZan</a> 编曲很舒服，嗓音、咬字也很舒服，豪庭！</li><li><a href="https://music.163.com/song?id=2673768687&amp;uct2=U2FsdGVkX18FGyslgGhylpiOLL3yceI5qesMa7G5B9M=">苦涩愛part3 - Skiluv / Dearkey7</a> 咱偶尔就乐意听点emo小儿歌，其实pt2我当时也循环好久hhh</li><li><a href="https://music.163.com/song?id=1422215325&amp;uct2=U2FsdGVkX1905fBsfUS/aDXkVzpiB7+dsjze+QRo4KU=">Wanting (feat. Lukrative) - mixed matches / Lukrative</a> mixed matches在我心里的特殊点在于，高级的同时，欣赏门槛却很低，这才是好的作品，适合更多人享受到高级的音乐。</li></ul><p><strong>历史：</strong></p><ul><li><a href="https://music.163.com/song?id=2608712871&amp;uct2=U2FsdGVkX19OrGnhCBJPxxIUVQMHMGeeWmtvX9O56Zo=">OD妹 - 极品贵公子 / 1CEKary艾斯凯瑞</a> 提到这歌我就不明白为什么抖音上那么多人去听泪痕，质量差距太大了好吧</li><li><a href="https://music.163.com/song?id=2047729462&amp;uct2=U2FsdGVkX186215Wi6yFSOfsXSN3mq202l7No41vt4E=">omg!//spedup - redwhite</a> 我的红白入坑曲，优雅</li><li><a href="https://music.163.com/song?id=2032722955&amp;uct2=U2FsdGVkX1+Qb+xNIspHYJqehF85QYCXBOc19W7pwGQ=">记忆里那我们的情节 - 黑松 / Tphunk</a> 谁听了这玩意不迷糊，前奏就给我听迷了</li><li><a href="https://music.163.com/song?id=1936298319&amp;uct2=U2FsdGVkX19Vfabh8lJH/+iME+E8gjrN2ap4JpZNy5Q=">刘屎咪(=^･ｪ･^=) - LoMo / siick</a> 梦回2022，那个时候真的超喜欢这首，lomo入坑曲</li><li><a href="https://music.163.com/song?id=2689471347&amp;uct2=U2FsdGVkX1+31gFWf1Lro6RUebTm+nOYbK3wdJeEHhM=">只是我不能够 - Tphunk</a> pk酱的歌是真的没几首难听的，出品超级稳定哈</li><li><a href="https://music.163.com/song?id=2673406259&amp;uct2=U2FsdGVkX1/TgJD9bdfEoeFyvyWl0UcjXz2VPTMkU1A=">th4ts r!ght - siick / soldoutsoul</a> siick的声音感觉从坠入二次元男高pt2之后就变了，但是现在的风格很新，音色也很适配！</li><li><a href="https://music.163.com/song?id=2627373619&amp;uct2=U2FsdGVkX19DcPUnXk39Q7HeuYd/z+ucSLyTXMnIcaA=">姑蘇城 - sakurabuko /1oKo</a> 就这个beat爽</li><li><a href="https://music.163.com/song?id=2165726950&amp;uct2=U2FsdGVkX19jNrW09DFGWM7SpF2dzFel2WCUFNU2NLk=">solitude - tonser</a> tonser的歌我只能说帅麻了，他和jssr!极大程度丰富我的音乐审美</li><li><a href="https://music.163.com/song?id=2660498865&amp;uct2=U2FsdGVkX1+U0GBRzUF2KCxoJLAP0P0T0Mmf5lsooiA=">暗号 - skiboyvv / Tphunk</a> 很喜欢这种vibe，不过mv是有点恐怖了</li><li><a href="https://music.163.com/song?id=2034655263&amp;uct2=U2FsdGVkX1/3Xiqco9jdbgssOcTqv6/Qjz63jHKxyio=">T^T - skiboyvv / mixed matches</a> 第一次听mixed matches就是这首歌，虽然是feat，但是实话实说在这首歌mixed才是重头戏。记得是23年5月第一次听到，后来过了一年多就发现mixed的歌全被拿去做影视氛围感剪辑了hhhh</li><li><a href="https://music.163.com/song?id=2654201707&amp;uct2=U2FsdGVkX19SV1foh8kPqGkUyzOd9BQB0BeP8aalOog=">爱情是勇气，不是运气 - redwhite</a> 李爽老师的pluggnb太舒服了，好听</li><li><a href="https://music.163.com/song?id=1417125661&amp;uct2=U2FsdGVkX19uui4aRg5OvOI4EXBszqTkkqEbXI6TTw4=">美梦 - 周公</a> 我也会听些大众的歌的hhh，小众哥</li><li><a href="https://music.163.com/song?id=1966429470&amp;uct2=U2FsdGVkX1+JzPbHgmjdaMxglkKQpc3SgGh6y7JDtMQ=">uh uh uh o(≧v≦)o - LoMo / Victor☆</a> 我就这样喜欢萌味很浓的plugg音乐</li></ul><p><strong>我的音乐观：</strong><br>俺是非常热爱音乐的人，所以对音乐是有些刁钻的。如果认为音乐没有高低贵贱，那无敌了，难道周杰伦的歌和庞麦郎的歌可以相提并论？<br>但是俺不是自我高潮的人，我听的歌虽然小众，但是我不会鄙夷大众爱听的，更不会有任何优越感。周杰伦的歌和mixed matches的歌都是好歌，都很棒，没有办法去比较高低贵贱；但如果比较对象是鼠来宝说唱，那就可以比较了。<br>但我依旧认为如果只会听些很大众的歌，比如华语乐坛脍炙人口的/抖音爆火的/Kpop的等等，那也算不上多高的审美能力。我不是说审美不高，审美能力一方面是审美质量，另一方面也是多元化。但我认为一个人有品，并不需要审美多元，毕竟听了很多种曲风结果每种喜欢的都是很拉垮的口水歌，那可夸不上审美有多好。<br>喜欢和能欣赏也是两个概念。能欣赏代表审美多元，而喜欢则是自己的偏好了。认为一个东西是好的但自己并不喜欢是完全ok的。比如我对很多g-funk音乐就是如此。</p><p><img src="/../images/29.png" alt="Fetyloi's Profile" title="我的网易云~"></p>]]></content>
      
      
      <categories>
          
          <category> 音乐 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 音乐 </tag>
            
            <tag> sexnb </tag>
            
            <tag> pluggnb </tag>
            
            <tag> 90&#39;s rnb </tag>
            
            <tag> hiphop </tag>
            
            <tag> hyperpop </tag>
            
            <tag> trap </tag>
            
            <tag> memphis </tag>
            
            <tag> jerk </tag>
            
            <tag> phonk </tag>
            
            <tag> newjazz </tag>
            
            <tag> rage </tag>
            
            <tag> rap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CodeQL生成数据库报错Spawned process exited abnormally处理</title>
      <link href="/2025/04/06/post8/"/>
      <url>/2025/04/06/post8/</url>
      
        <content type="html"><![CDATA[<h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>解决的是参考这篇教程学习CodeQL时遇到的问题：<a href="https://www.freebuf.com/articles/web/283795.html">CodeQL从入门到放弃</a></p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>原命令</p><pre class="line-numbers language-none"><code class="language-none">database create ~/CodeQL/databases/micro-service-seclab-database  --language="java"  --command="mvn clean install --file pom.xml" --source-root=~/CodeQL/micro-service-seclab/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>改为</p><pre class="line-numbers language-none"><code class="language-none">database create ~/CodeQL/databases/micro-service-seclab-database  --language="java"  --command="mvn clean install -DskipTests --file pom.xml" --source-root=~/CodeQL/micro-service-seclab/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也就是在 <code>mvn clean install</code> 后加上 <code>-DskipTests</code> 跳过项目单元测试。</p><h1 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h1><h2 id="核心报错："><a href="#核心报错：" class="headerlink" title="核心报错："></a>核心报错：</h2><pre class="line-numbers language-none"><code class="language-none">Caused by: org.hibernate.HibernateException: Access to DialectResolutionInfo cannot be null when 'hibernate.dialect' not set<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>说明 SpringBoot 在加载应用上下文时尝试连接数据库，但找不到 <code>hibernate.dialect</code>，也无法从数据库连接中自动推断，因此失败。</p><h2 id="解决逻辑"><a href="#解决逻辑" class="headerlink" title="解决逻辑"></a>解决逻辑</h2><p>CodeQL 构建数据库的本质是追踪项目的编译过程，因此不需要运行测试。只要项目代码能成功编译，CodeQL 就能生成数据库。所以直接跳过。</p><h1 id="其他注意点"><a href="#其他注意点" class="headerlink" title="其他注意点"></a>其他注意点</h1><p>还是应该尊重教程的环境（JDK版本和Maven版本）</p><ul><li>JDK版本切换建议阅读这篇教程：<a href="https://blog.csdn.net/qq_40543170/article/details/88391838">三个步骤教会你自由切换JDK版本，超级简单！</a></li><li>JDK 1.8下载在这篇教程找链接：<a href="https://blog.csdn.net/JasonXu94/article/details/143726390">Java8（JDK1.8）最新下载安装教程</a></li><li>Maven 3.6.3下载在这篇教程找链接：<a href="https://blog.csdn.net/qq_46554590/article/details/119428896">maven3.6.3下载与安装。</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 报错处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络安全 </tag>
            
            <tag> 报错处理 </tag>
            
            <tag> CodeQL </tag>
            
            <tag> 代码审计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Joplin存储路径问题</title>
      <link href="/2025/04/02/post7/"/>
      <url>/2025/04/02/post7/</url>
      
        <content type="html"><![CDATA[<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>  不用Desktop版本，转去用Portable版本就行了。<br>  Portable版本下载链接：<a href="https://objects.joplinusercontent.com/v3.2.13/JoplinPortable.exe?source=JoplinWebsite&amp;type=New">Joplin Protable</a><br>  记得把Desktop卸载干净。</p><h1 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h1><p>  Portable版本比Desktop版本启动要慢一些，不过终于是可以自定义位置，适合我这种C盘爆满用户。其实感觉启动速度也没差多少。<br>  网上的方案一般是在 <code>快捷方式&gt;属性&gt;目标</code> 添加 <code>--profile+新路径</code>。反正我这么做了之后出现了Bug，而且看很多人说重启后又回去了。<br>  找了官方文档，开发者就是建议用Portable或者用mklink去链接，我感觉还是Portable比较适合。<br><img src="/../images/26.png" alt="Portable Version" title="Portable Version"></p>]]></content>
      
      
      <categories>
          
          <category> 工具设置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
            <tag> github </tag>
            
            <tag> Joplin </tag>
            
            <tag> 自定义设置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决hexo d上传失败（Spawn failed）问题</title>
      <link href="/2025/03/30/post6/"/>
      <url>/2025/03/30/post6/</url>
      
        <content type="html"><![CDATA[<h1 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h1><p>想上传博客，但是发现执行 <code>hexo d</code> 出现如下报错：</p><pre class="line-numbers language-none"><code class="language-none">FATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.htmlError: Spawn failed    at ChildProcess.&lt;anonymous&gt; (F:\myweb\myblog\node_modules\hexo-deployer-git\node_modules\hexo-util\lib\spawn.js:51:21)    at ChildProcess.emit (node:events:524:28)    at cp.emit (F:\myweb\myblog\node_modules\cross-spawn\lib\enoent.js:34:29)    at ChildProcess._handle.onexit (node:internal/child_process:293:12)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后就思考是不是网络问题，于是我 <code>ping github.com</code> 发现全是请求超时，花了好长时间去搜索如何解决这个问题。但是在看报错的时候，忽略了一行信息：</p><pre class="line-numbers language-none"><code class="language-none">ssh: connect to host github.com port 22: Connection timed outfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看出是ssh连接的问题，且问题出现在22端口。需要说明的是由于最开始部署博客的时候，采用http协议就出现过超时问题，所以转用ssh了。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><ol><li>执行 <code>ssh -T git@github.com</code> 发现抛出异常：<code>ssh: connect to host github.com port 22: Connection timed out</code> ，和刚才<code>hexo d</code> 出现的报错一样。</li><li>我们 <code>ping ssh.github.com</code>，发现可以ping通。同时可以和 <code>ping github.com</code> 返回的ip对比，发现是两个不同的ip，ssh.github.com对应的是&nbsp;20.205.243.160，而github.com对应的是20.205.243.166。所以端口应该是没有毛病的，我们把要访问的改为ssh.github.com即可。</li><li>在 <code>C:\Users\用户名\.ssh</code> 下新建一个 <code>config.txt</code> 文件，写入如下内容：<pre class="line-numbers language-none"><code class="language-none">Host github.com    Hostname ssh.github.com    Port 22<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>把.txt后缀删掉</li><li>重新执行 <code>ssh -T git@github.com</code> ，发现成功了。</li><li>回到博客目录执行 <code>hexo d</code> 发现一切都好了。</li></ol><h1 id="其他情况的解决方案"><a href="#其他情况的解决方案" class="headerlink" title="其他情况的解决方案"></a>其他情况的解决方案</h1><p>可以采取一些尝试：</p><ol><li>如果在根目录下的config.yml中的deploy的repo里用的是http，改用SSH试试，需要自己创建和仓库的ssh连接，可以自行搜索</li><li>参见大佬的一些解决方案 <a href="https://blog.zhheo.com/p/128998ac.html">Hexo错误：spawn failed的解决方法 | 张洪Heo</a>，本文的解决其实就对应大佬这篇博客的<code>ssh -T git@github.com</code> 连接失败的解决方案。/侵删</li></ol><h1 id="关于Github无法ping通的问题（未解决）"><a href="#关于Github无法ping通的问题（未解决）" class="headerlink" title="关于Github无法ping通的问题（未解决）"></a>关于Github无法ping通的问题（未解决）</h1><p>情况是：能ping通8.8.8.8或1.1.1.1，但ping不通github.com或者google.com，科学上网可以直接访问所有外部网站，但就是ping不通。甚至在github可不科学上网直接打开网页的时候，也ping不通。同时不是校园网的问题，隔壁师兄可以ping通。分析了半天，问题定位在ICMP。<br>用WireShark抓包发现所有的ICMP报文都被拦截了，不太清楚到底是什么原因，我做了以下尝试，但均以失败告终：</p><ol><li>关闭防火墙，或在防火墙中出站规则允许关于ICMP的一切规则</li><li>将DNS从DHCP切换手动配置为8.8.8.8或1.1.1.1</li><li>修改hosts文件，在其中添加github.com和问题ip</li><li>执行 <code>ipconfig /flushdns</code>刷新dns缓存</li><li>执行 <code>netsh int ip reset</code> 和 <code>netsh winsock reset</code> 重置TCP/IP协议栈</li><li>用telnet/tcping测试，全都是依旧显示有问题</li><li>禁用ipv6</li><li>更换网络为手机热点<br>最终还是没有解决，不太清楚为什么，不过现在不影响博客上传了，所以也没有处理了。</li></ol><h1 id="感谢"><a href="#感谢" class="headerlink" title="感谢"></a>感谢</h1><p>非常感谢下面这篇博客，解决了问题。<br><a href="https://icemyst.github.io/posts/5161.html">GitHub连接超时问题解决 | 冰刻无痕</a><br>感谢可爱小柴陪我解决了半天。<br><a href="https://zycreverse.netlify.app/">Home - 我要当黄牛!</a></p>]]></content>
      
      
      <categories>
          
          <category> 报错处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> github </tag>
            
            <tag> hexo </tag>
            
            <tag> 报错处理 </tag>
            
            <tag> 网络问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Datacon2024漏洞分析赛道作品Vuln_wp漏洞挖掘源码分析</title>
      <link href="/2025/03/29/post5/"/>
      <url>/2025/03/29/post5/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="7947053db4b9560d898db434ff75710a30e155d57f5f08e781039b744cae0f84">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 漏洞 </tag>
            
            <tag> LLM </tag>
            
            <tag> 大模型 </tag>
            
            <tag> 网络安全 </tag>
            
            <tag> DataCon </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vulnhuntr大模型漏洞检测工具源码分析</title>
      <link href="/2025/03/25/post4/"/>
      <url>/2025/03/25/post4/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="5f5c90d270c004b0ab33b6f2a59bcaf2b2aa2ab75027e60539a7bcb7ba3a7c55">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> github </tag>
            
            <tag> 漏洞 </tag>
            
            <tag> LLM </tag>
            
            <tag> 大模型 </tag>
            
            <tag> 网络安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读：两篇关于LLM Agents利用漏洞的能力研究论文</title>
      <link href="/2025/03/22/post3/"/>
      <url>/2025/03/22/post3/</url>
      
        <content type="html"><![CDATA[<h1 id="一、LLM-Agents-can-Autonomously-Hack-Websites"><a href="#一、LLM-Agents-can-Autonomously-Hack-Websites" class="headerlink" title="一、LLM Agents can Autonomously Hack Websites"></a>一、LLM Agents can Autonomously Hack Websites</h1><blockquote><p>发表：arXiv:2402.06664v3 [cs.CR] 16 Feb 2024</p></blockquote><h2 id="1-先看动机和结论"><a href="#1-先看动机和结论" class="headerlink" title="1. 先看动机和结论"></a>1. 先看动机和结论</h2><h3 id="①-动机"><a href="#①-动机" class="headerlink" title="① 动机"></a>① 动机</h3><p>如title，研究模型构建的agent能不能自动攻击网站</p><h3 id="②-结论"><a href="#②-结论" class="headerlink" title="② 结论"></a>② 结论</h3><ul><li>GPT-4 能够在事先不了解特定漏洞的情况下进行攻击（直接告诉模型给我攻击网站就完事了）</li><li>消融实验表明，对于agent来说，文档读取【document reading】、详细系统指令【,detailed system instructions】这两个Tool是至关重要的</li></ul><h2 id="2-数据集与评估指标、模型"><a href="#2-数据集与评估指标、模型" class="headerlink" title="2. 数据集与评估指标、模型"></a>2. 数据集与评估指标、模型</h2><h3 id="①-数据集、评估指标"><a href="#①-数据集、评估指标" class="headerlink" title="① 数据集、评估指标"></a>① 数据集、评估指标</h3><p>共15个漏洞组成用于测试的数据集：<br><img src="/../images/15.png"><br><strong>评估指标：</strong> 为每个漏洞指定了目标，按agent在10分钟内是否实现来定义成功/失败<br><strong>测试次数：</strong> 每个漏洞5次实验，成功一次就ok </p><h3 id="②-构建Agent的模型"><a href="#②-构建Agent的模型" class="headerlink" title="② 构建Agent的模型"></a>② 构建Agent的模型</h3><p><img src="/../images/16.png"><br>这个表顺便显示了一下成功率，GPT-4失败的四个漏洞是：<br>权限绕过、Javascript 攻击、困难 SQL 注入 和 XSS + CSRF</p><h2 id="3-一些很有趣的论点"><a href="#3-一些很有趣的论点" class="headerlink" title="3. 一些很有趣的论点"></a>3. 一些很有趣的论点</h2><h3 id="①-探究智能体在网安领域的能力【GPT-4】"><a href="#①-探究智能体在网安领域的能力【GPT-4】" class="headerlink" title="① 探究智能体在网安领域的能力【GPT-4】"></a>① 探究智能体在网安领域的能力【GPT-4】</h3><p>例如对困难的SQL注入，智能体能够成功地做到：</p><ul><li>在页面之间导航，以确定攻击哪个页面。</li><li>尝试默认的用户名和密码（例如，admin）。</li><li>确定默认尝试失败，并尝试经典的 SQL 注入（例如，附加 OR 1 = 1）。</li><li>读取源代码，以确定 SQL 查询中有一个 GET 参数。</li><li>确定该网站易受 SQL 联合攻击。</li><li>执行 SQL 联合攻击。<br>例如对服务器端模板注入（SSTI）攻击，智能体能够成功地做到：</li><li>确定一个网站是否容易受到 SSTI 攻击。</li><li>使用一个小的测试脚本测试 SSTI 攻击。</li><li>确定要窃取的文件的位置。</li><li>执行完整的 SSTI 攻击。</li></ul><h3 id="②-评估指标有”成本”"><a href="#②-评估指标有”成本”" class="headerlink" title="② 评估指标有”成本”"></a>② 评估指标有”成本”</h3><p>如果要从公司应用开发角度来看，成本这个指标确实很重要，在学术论文里感觉大多评估指标还是经典四件套：accuracy/precision/recall/f1-score，或者构建其他科学性指标评估检测效果，而不是关注成本。但是做竞赛作品的话，注意这个点应该还挺好的。<br>论文的研究结果是：“每次成功利用漏洞的成本将是 8.80 美元”</p><h1 id="二、LLM-Agents-can-Autonomously-Exploit-One-day-Vulnerabilities"><a href="#二、LLM-Agents-can-Autonomously-Exploit-One-day-Vulnerabilities" class="headerlink" title="二、LLM Agents can Autonomously Exploit One-day Vulnerabilities"></a>二、LLM Agents can Autonomously Exploit One-day Vulnerabilities</h1><blockquote><p>发表：arXiv:2404.08144v2 [cs.CR] 17 Apr 2024</p></blockquote><h2 id="1-先看动机和结论-1"><a href="#1-先看动机和结论-1" class="headerlink" title="1. 先看动机和结论"></a>1. 先看动机和结论</h2><h3 id="①-动机-1"><a href="#①-动机-1" class="headerlink" title="① 动机"></a>① 动机</h3><p>如title，研究模型构建的agent利用漏洞信息的能力</p><h3 id="②-结论-1"><a href="#②-结论-1" class="headerlink" title="② 结论"></a>② 结论</h3><ul><li>GPT-3.5/其他大模型/开源漏洞扫描器 Agent —— 0%</li><li>GPT-4 Agent —— 7%</li><li>GPT-4 Agent <strong>+ CVE描述</strong> —— 86.7%</li></ul><p>所以CVE描述很重要，如果没有CVE描述，很可能在布局中找不到触发点或者超过工具相应大小限制，以及可能列出所有可能的攻击方式并只尝试其中一种就下班了</p><h2 id="2-数据集、模型、扫描器"><a href="#2-数据集、模型、扫描器" class="headerlink" title="2. 数据集、模型、扫描器"></a>2. 数据集、模型、扫描器</h2><h3 id="①-数据集"><a href="#①-数据集" class="headerlink" title="① 数据集"></a>① 数据集</h3><p>共15个漏洞组成用于测试的数据集：<br>人工挑选了14个现实世界<strong>one-day漏洞</strong>（都是开源软件的可重现CVE） + “ACIDRain”漏洞<br><img src="/../images/12.png"></p><p><img src="/../images/13.png"></p><h3 id="②-构建Agent的模型-1"><a href="#②-构建Agent的模型-1" class="headerlink" title="② 构建Agent的模型"></a>② 构建Agent的模型</h3><p><img src="/../images/14.png"><br>都用的api而不是本地部署，所以要衡量成本<br>这个表顺便显示了一下成功率，GPT-4失败的两个漏洞是：</p><ul><li>Iris 跨站脚本漏洞（XSS）</li><li>Hertzbeat 远程代码执行漏洞（RCE）</li></ul><h3 id="③-开源漏洞扫描器"><a href="#③-开源漏洞扫描器" class="headerlink" title="③ 开源漏洞扫描器"></a>③ 开源漏洞扫描器</h3><p>ZAP和Metasploit<br>效果上就是啥也没检测出来</p><h2 id="3-一些很有趣的论点-1"><a href="#3-一些很有趣的论点-1" class="headerlink" title="3. 一些很有趣的论点"></a>3. 一些很有趣的论点</h2><h3 id="①-已经有构建Agent来打CTF的尝试了"><a href="#①-已经有构建Agent来打CTF的尝试了" class="headerlink" title="① 已经有构建Agent来打CTF的尝试了"></a>① 已经有构建Agent来打CTF的尝试了</h3><p>Llm agents can autonomously hack websites, 2024. —Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, and Daniel Kang. </p><h3 id="②-评估指标有”成本”-1"><a href="#②-评估指标有”成本”-1" class="headerlink" title="② 评估指标有”成本”"></a>② 评估指标有”成本”</h3><p>如果要从公司应用开发角度来看，成本这个指标确实很重要，在学术论文里感觉大多评估指标还是经典四件套：accuracy/precision/recall/f1-score，或者构建其他科学性指标评估检测效果，而不是关注成本。但是做竞赛作品的话，注意这个点应该还挺好的。<br>论文的研究结果是：“每次成功利用漏洞的成本将是 8.80 美元”</p><h1 id="三、结语"><a href="#三、结语" class="headerlink" title="三、结语"></a>三、结语</h1><h2 id="1-关于开源模型"><a href="#1-关于开源模型" class="headerlink" title="1. 关于开源模型"></a>1. 关于开源模型</h2><p>这两篇论文所示的结果都是GPT-4和GPT-3.5这种闭源模型有效果，而Llama这种开源模型效果不佳，因为工具的调用失败。如果后续研究想要探究开源模型的对应效果，应该着重看一下对工具的调用上是否可以改进。<br>同时，DeepSeek热潮虽然让我们很想利用DeepSeek-R1或DeepSeek-V3进行研究，但是DeepSeek系列模型当前没有调用工具的能力，从而无法构建智能体。</p><h2 id="2-关于这两篇论文"><a href="#2-关于这两篇论文" class="headerlink" title="2. 关于这两篇论文"></a>2. 关于这两篇论文</h2><blockquote><p>The most related work to ours is a recent study that showed that LLM agents can hack websites (Fang et al., 2024). This work focused on simple vulnerabilities in capture-the-flag style environments that are not reflective of real-world systems.<br>与我们的研究最为相关的是最近的一项研究，该研究表明大语言模型智能体能够攻击网站（方等人，2024）。这项工作聚焦于 “夺旗” 式环境中的简单漏洞，而这些漏洞并不能反映现实世界中的系统情况。</p></blockquote><p>也就是说第二篇论文是第一篇在真实世界漏洞上的进一步研究<br>这两篇论文属于同一个团队</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Agent </tag>
            
            <tag> 漏洞 </tag>
            
            <tag> LLM </tag>
            
            <tag> 大模型 </tag>
            
            <tag> 网络安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fetyloi&#39;s 《神经网络与深度学习》 学习笔记</title>
      <link href="/2025/03/21/post2/"/>
      <url>/2025/03/21/post2/</url>
      
        <content type="html"><![CDATA[<p><font color="blue"><strong>附上我的语雀文档链接吧，导出的.md文件貌似不太好使：</strong></font><br><a href="https://www.yuque.com/yuqueyonghucoit3e/wefx9h/dlk9gxsk9fbg91uq?singleDoc#">https://www.yuque.com/yuqueyonghucoit3e/wefx9h/dlk9gxsk9fbg91uq?singleDoc#</a> 《《神经网络与深度学习》（邱锡鹏）》 密码：bz42<br>第1章 绪论</p><h2 id="tRQk9">1.表示学习</h2>①表示学习：自动将输入信息转换为有效的特征，提高最终模型性能。<p>②语义鸿沟：输入数据的底层特征和高层语义信息之间的不一致性和差异性。</p><p>③嵌入：用神经网络将高维局部表示空间映射到非常低维的分布式表示空间，并尽可能保持不同对象间的拓扑关系。</p><h2 id="HbCi1">2.深度学习</h2>①深度学习：原始数据特征进行多步特征转换，得到特征表示，进一步输入到预测函数，得到最终结果。<p>②深度：原始数据进行非线性特征转换的次数。</p><h2 id="EkK7z">3.赫布型学习</h2>赫布型学习：俩神经元总相关联地受到刺激，使得它们之间的突触强度增加。<h1 id="Ea6dm">第2章 机器学习概述</h1><h2 id="JZqGp">1.机器学习三要素</h2>模型、学习准则、优化算法<h2 id="N0xH1">2.线性模型与非线性模型</h2>线性模型的假设空间为一个参数化的线性函数族；<p>广义的非线性模型可以写为多个非线性基函数的线性组合。</p><h2 id="UMZEI">3.损失函数</h2>&gt; 0-1损失；平方损失（不适用分类）；交叉熵损失（一般用于分类）；Hinge损失函数&gt;<h2 id="eQAeE">4.优化问题与优化算法</h2><h3 id="EA07U">优化问题与优化算法</h3>优化问题：参数优化、超参数优化<p>优化算法：梯度下降、提前停止、随机梯度下降、小批量梯度下降</p><p>（.提前停止：在快要发生过拟合的时候停止迭代——使用验证集，在验证集上错误率不再下降就停止迭代）</p><h3 id="vIfQg">超参数</h3>超参数：定义模型结构或优化策略的一类参数<p>常见超参数：聚类中类别个数、梯度下降中学习率/步长，正则化项系数，神经网络层数，SVM核函数</p><h2 id="tjxc4">5.参数估计方法</h2>&gt; 经验风险最小化、结构风险最小化、最大似然估计、最大后验估计&gt;<p>经验风险最小化–&gt;过拟合–&gt;结构风险最小化–&gt;正则化</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1730373430149-accedfba-3c10-44eb-8311-4b83b1352b11.png"></p><h2 id="GikeT">6.偏差-方差分解</h2>偏差-方差分解的目的是：在模型拟合能力和复杂度之间取得较好平衡<p>降低偏差：增加数据特征、提高模型复杂度、减小正则化系数</p><p>降低方差：降低模型复杂度、加大正则化系数、引入先验、集成模型</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1730373401347-fa1537ac-88f1-41f2-ac87-8e9ff167a8d3.png"></p><h2 id="F3MbP">7.数据的特征表示</h2>&gt; 图像特征、文本特征&gt;<h3 id="gvR7J">图像特征表示：每一维的值为图像中对应像素的灰度值</h3><h3 id="jZfVf">文本特征表示——词袋模型：</h3>①思想：向量表示，向量维度为与词表大小相同，向量第i维值为1表示词表第i个词在向量中出现<p>②缺点：不考虑词序，不能精确表示文本信息</p><p>③改进：使用N元特征——每N个连续词构成一个基本单元再放进词袋模型</p><h2 id="pAlno">8.传统特征学习【亦称维数约简/降维】</h2>&gt; **特征选择、特征抽取**&gt;<h3 id="eWlhj">特征选择：保留有用的、去除没用的，方法有子集搜索、正则化等：</h3>①子集搜索：<p>  i.过滤式方法：每次增加最有信息量（信息增益高）/删除最没信息量（信息增益低）的特征</p><p>  ii.包裹式方法：每次增加对模型预测效果提升最有用/删除对模型预测效果提升最没用的特征</p><p>【从空增加是前向搜索，从原始特征集合删是反向搜索】</p><p>②正则化：会导致稀疏特征，因此间接实现了特征选择</p><h3 id="Ffvnd">特征抽取：原始特征投影到新的特征空间得到新表示，方法有监督和无监督：</h3>①监督方法：eg.线性判别分析LDA<p>②无监督方法：eg.主成分分析PCA；自编码器AE</p><h2 id="QSova">9.指标</h2>准确率、错误率、精确率（查准率）、召回率（查全率）、F值、宏平均、微平均、交叉验证。。。<h2 id="uFh7Z">10.理论和定理</h2>&gt; PAC学习理论（可能近似正确学习理论）、没有免费的午餐定理、奥卡姆剃刀原理、丑小鸭定理、归纳偏置（贝叶斯中的先验）&gt;<p>①可能近似正确学习理论：就是模型泛化错误小到一个差不多的程度ε就行，而且能以一定概率1-δ（也就是有可能）学到这个模型。从而得出了一个公式描述，如果固定了上面所说的ε和δ，可以得出学习需要的样本数量。</p><p>②没有免费的午餐定理：任何算法都有局限性，如果算法对某个问题有效，那么对一些其他问题一定比纯随机算法要差</p><p>③奥卡姆剃刀原理：如果俩模型性能相近，选简单的那个</p><h1 id="EAfSR">第3章 线性模型</h1><h2 id="IInLg">1.Logistic回归（逻辑斯谛回归/对数几率回归）</h2>Logistic回归采用交叉熵作为损失函数，可用梯度下降法、牛顿法等来优化参数<h2 id="rcM4D">2.Softmax回归（多项/多类的Logistic回归）</h2>Softmax回归也采用交叉熵作为损失函数。Softmax回归核心是应用Softmax函数将线性模型的输出转化为一个类别概率分布，其中Softmax函数会将每个类别计算得到的分数转换为概率<h2 id="oLdq2">3.感知器</h2>二分类：普通感知器--&gt;投票感知器--&gt;平均感知器<p>多分类：广义感知器</p><p>逻辑：</p><p>感知器学习的参数和训练样本顺序相关：根据前面的样本学好了，预测很不错，结果在最后一个错了，更新参数，反而学的参数变差了。</p><p>解决这种问题需要提高感知器鲁棒性和泛化能力，给每个参数一个置信系数，最终分类结果由不同参数的感知器投票决定——投票感知器。</p><p>投票感知器对参数的保存记录有开销，因此通过参数平均策略减少参数数量——平均感知器</p><h2 id="BjJEa">4.支持向量机</h2>【大部分都已经学习过了 不重复写入】<h1 id="BSbRW">第4章 前馈神经网络</h1><h2 id="aY6wr">1.激活函数：</h2>①Sigmoid型函数：(Hard)Logistic/(Hard)Tanh<p>②ReLU函数：带泄露的/带参数的/ELU/Softplus</p><p>③Swish函数</p><p>④GELU函数</p><p>⑤Maxout单元</p><h2 id="B21rh">2.网络结构：前馈/记忆/图</h2><h2 id="ZHX5m">3.反向传播：</h2>①前馈计算每层净输入和激活值，直到最后一层<p>②反向传播计算每一层的误差项</p><p>③计算每一层参数的偏导数</p><h2 id="cCZ8z">4.自动梯度计算：数值微分/符号微分/自动微分</h2><h2 id="QBIO2">5.详细与补充</h2>①误差项：目标损失函数关于某层的神经元（的净输入）的偏导数，用δ(l)来表示。<p>②数值微分就是取很少的非零扰动Δx计算梯度，符号微分就是通过迭代或递归使用一些事先定义好的规则进行变换。</p><p>③自动微分可分为前向模式和反向模式，前向按照计算图中的计算方向递归计算梯度，反向按照相反方向、与反向传播计算梯度的方式相同。都是基于链式法则的。</p><h1 id="RvC5i">第5章 卷积神经网络</h1><h2 id="UqNkx">1.卷积咋算，一维卷积和二维卷积是啥，卷积核/滤波器是啥</h2>①卷积核/滤波器就是信息的衰减率，每个时刻的信号乘上各自对应的衰减率，再加一起，就是卷积。标准来讲，信号序列和滤波器/卷积核的卷积定义为y=w*x，*就是卷积运算。<p>②一维卷积就是信号序列是一行，二维卷积就是信号序列是一个二维表，二维卷积的算法就是从这个表里找到和卷积核表一样大小的一块区域，并对应卷积核表的相对位置，每个数都按位去乘起来，然后加起来得到这个数放到刚才说的对应位置里，其中在乘之前，需要把卷积核翻转一下。</p><p>③特征映射的概念：一幅图像卷积后得到的结果。</p><h2 id="uNV5G">2.卷积和互相关是啥关系</h2>互相关和卷积的区别是卷积核是否翻转，互相关也可以称为不翻转卷积。<h2 id="RQ4Kn">3.卷积的步长、零填充是干啥的</h2>步长是卷积核滑动时的时间间隔，零填充是在输入向量两端进行补0，根据不同步长和填充有常用卷积：窄/宽/等宽卷积<h2 id="qGazF">4.卷积的数学性质</h2>卷积的数学性质是交换性和导数。<p>其中导数说的是：卷积后通过激活函数，这个激活值关于输入序列的偏导，等于其对卷积的偏导和卷积核的卷积结果</p><h2 id="Zp6sp">5.卷积神经网络的构成，三个部分分别干啥的</h2>卷积层：提取局部区域特征，不同卷积核是不同的特征提取器；<p>汇聚层：选择特征、降低特征数量，从而减少参数数量。</p><p>汇聚层汇聚函数常用的有最大汇聚和平均汇聚，分别是取区域内神经元最大活性值和平均活性值。就是说，卷积层提取特征，汇聚层把特征压缩从而减少参数量。</p><p>【汇聚层=池化层; 最大/平均汇聚=最大/平均池化】</p><p>全连接层</p><h2 id="ywvHx">6.卷积网络的参数学习，也就是卷积网络的反向传播咋进行的，学习的参数是哪些</h2>学习的参数是卷积核和偏置，汇聚层和卷积层反向传播的不同在于误差项的计算不同<h2 id="LBQH1">7.典型的卷积神经网络</h2>&gt; LeNet-5,AlexNet,Inception 网络,残差网络&gt;<p>①LeNet-5网络：值得注意的是用了连接表来定义输入和输出特征映射之间的依赖关系</p><p>【连接表：写出来关系，从而指导我们，让每一个输出特征都依赖于少数几个特征映射】</p><p>②AlexNet网络：将网络拆成两半分别放在俩GPU上</p><p>③Inception网络：特点是一个卷积层包含多个不同大小的卷积操作</p><p>④残差网络：思想是在用非线性单元逼近目标函数时拆分一下，h(x)=x+(h(x)-x)，前后两项分别是恒等函数和残差函数，让非线性单元近似残差函数简单点，然后+x就逼近了目标函数</p><h2 id="E2SWE">9.其他卷积方式：转置卷积、微步卷积、空洞卷积都分别是干啥的</h2>①转置卷积：转置的是卷积核，作用是实现低维到高维的反向映射<p>②微步卷积：想让步长小于1从而提高特征维数，但是步长没法小于1，所以在输入特征之间插入0间接减小步长</p><p>③空洞卷积：给卷积核加入一些空洞来增加卷积核的大小，从而能够不增加参数数量，同时增加输出单元感受野</p><p>【感受野：神经元只接受其所支配的刺激区域内的信号，只有这个区域内的刺激才能激活该神经元】</p><h1 id="KqUh4">第6章 循环神经网络</h1><h2 id="JiXEg">1.延时神经网络TDNN、有外部输入的非线性自回归模型NARX、循环神经网络RNN，三者分别是啥概念，之间有啥不同点和联系</h2><h3 id="TRMuo">三者的概念</h3>**TDNN**给前馈网络非输出层加了延时器，延时器可以记录神经元最近几次活性值，l层活性值依赖于l-1层神经元最近K个时刻的活性值；<p><strong>NARX</strong>也用延时器，延时器记录最近几次的外部输入和最近几次的输出，把这些输入、输出传入一个非线性函数，得到某时刻的输出；</p><p><strong>RNN</strong>用了带自反馈的神经元，将前一个活性值（由延迟器记录）和当前输入序列传入非线性函数，从而更新带反馈边的隐藏层的活性值（称为状态/隐状态）</p><h3 id="qioFq">三者的联系</h3>**TDNN**仅依赖固定窗口的输入，不能捕捉长时间依赖，不使用反馈。<p><strong>NARX</strong>显式依赖过去的输入和输出，有反馈机制，能处理短期依赖的输入-输出关系。</p><p><strong>RNN</strong>通过隐藏状态隐式记忆所有历史信息，能处理长时间依赖，但训练复杂。</p><p>TDNN适合处理短期依赖和固定窗口长度的任务，NARX适用于有明确输入输出关系，RNN适合处理复杂、长依赖关系的任务</p><h2 id="QdVQL">2.从简单循环网络SRN理解RNN的具体原理</h2>SRN=两层前馈神经网络+隐藏层到隐藏层的反馈连接。隐藏层状态的计算见笔记图。<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1730374448373-16f7a3ea-b431-41a5-b467-0c403b2d16bf.png"></p><h2 id="b0jK3">3.图灵完备是什么概念</h2>图灵完备：可以实现图灵机的所有功能的数据操作规则称为图灵完备，如主流编程语言。<p>p.s. 所有的图灵机都可以被一个由sigmoid型激活函数的神经元构成的全连接RNN来进行模拟</p><h2 id="NkCe6">4.RNN应用到不同类型机器学习任务对应的三种模式：序列到类别模式、同步的序列到序列模式、异步的序列到序列模式</h2>①序列到类别模式：输入为序列，输出为类别。将整个序列的最终表示传入分类器进行分类。最终表示可以选最后时刻的状态，也可以选择整个序列所有的状态的平均（一个平均状态）<p>②同步的序列到序列模式：每一时刻都有输入和输出，输入序列和输出序列长度相同。例如用于词性标注。</p><p>:::info<br>一个疑问：词性标注似乎只取决于当前词本身，而与上下文无关，为什么要采取RNN呢？</p><p>对应的解释：</p><p> a.多义词： 很多词具有多个词性，其确切词性往往取决于上下文。例如“银行”可以是名词（去银行办业务），也可以是动词（银行贷款）。             </p><p> b.同形异义词： 不同的词可能具有相同的形式，但词性不同。例如“打”可以是动词（打篮球），也可以是量词（一打啤酒）。                  </p><p> c.长距离依赖： 词性标注有时需要考虑较长的上下文信息。例如，一个代词的词性往往取决于它所指代的名词，而这个名词可能出现在较远的前面。</p><p>:::</p><p>③异步的序列到序列模式（编码器-解码器模型）：输入序列输出序列不一定严格对应，也不一定长度相等。编码器和解码器是两个不同的RNN，样本x按不同时刻输入编码器得到编码，再把编码传入解码器得到输出序列</p><h2 id="qynpL">5.RNN怎么进行参数学习—梯度下降—BPTT/RTRL</h2>RNN的参数学习BPTT和RTRL见图。BPTT计算少，但要存所有时刻中间梯度，空间复杂度高；RTRL不需要梯度回传。<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1730374448373-16f7a3ea-b431-41a5-b467-0c403b2d16bf.png"></p><h2 id="cVKXX">6.什么是梯度爆炸问题，什么是梯度消失问题，什么是长程依赖问题，怎么解决这些问题</h2>①长程依赖问题：时刻t的输出依赖时刻k的输入，但t和k间隔很长，神经网络很难建模这种长距离依赖关系，称长程依赖问题。为什么难建模，是因为t和k间隔很长的情况下，引发梯度爆炸问题和梯度消失问题。【梯度爆炸问题、梯度消失问题见上图】<p>②怎么解决：</p><p>梯度爆炸——权重衰减（正则化，限制参数取值范围使γ&lt;=1）/梯度截断（大于阈值就截断成较小的数）；</p><p>梯度消失——改变模型；为了解决俩问题，引入门控机制。</p><h2 id="vKftk">7.基于门控的RNN：什么是长短期记忆网络LSTM，什么是长短期记忆，LSTM的变体</h2>①引入内部状态、候选状态、门控机制<p>a. LSTM引入的内部状态：专门进行线性的循环信息传递，同时（非线性地）输出信息给隐藏层的外部状态；</p><p>b. LSTM引入的候选状态：从非线性函数输出得到。</p><pre><code>  c. 门控机制：输入门（控制当前时刻候选状态要保存多少信息）、遗忘门（控制上一时刻内部状态要遗忘多少信息）、输出门（控制当前时刻内部状态有多少要输出给外部状态）。三个门取值都在0，1之间表示以一定比例让信息通过。</code></pre><p>②长期记忆：隐含从训练数据学到的经验，更新周期远远慢于短期记忆。长短期记忆的生命周期介于长期记忆和短期记忆之间。</p><p>③LSTM变体：</p><p>a.无遗忘门的；</p><p>b.三个门不但依赖于输入和上一时刻的隐状态，也依赖于上一个时刻的记忆单元的peephole连接；</p><p>c.耦合输入门和遗忘门（因为在LSTM中这两个门有一定的互补关系，所以合并成一个）</p><h2 id="fDylK">8.基于门控的RNN：门控循环单元网络GRU</h2>GRU：不引入额外记忆单元，引入更新门——控制当前状态需要从历史状态中保留多少信息（不经过非线性变换，以及需要从候选状态中接受多少新信息。<p>更新门=0时当前状态和前一时刻状态间为非线性函数关系；=1时为线性函数关系。引入重置门控制候选状态的计算是否依赖上一时刻状态。</p><p>重置门=0时候选状态只与当前输入有关，与历史无关；重置门=1时与当前输入和历史都有关，和简单RNN一致</p><h2 id="s8PiL">9.什么是深层RNN，怎么增加RNN的深度（堆叠RNN，双向RNN）</h2>单看网络输入到输出间路径，RNN很浅。<p>增加深度以增强RNN能力，方式主要是增加同一时刻网络输入到输出间路径。</p><p>①堆叠RNN：第l层网络输入是第l-1层网络输出，每层内部计算自己时时刻刻的隐状态。</p><p>②双向RNN：增加按时间逆序传递信息的网络层。有两层RNN构成，两个的输入相同，信息传递方向不同。</p><h2 id="UjjwK">10.RNN扩展到图结构：递归神经网络RecNN与图神经网络GNN</h2>①RecNN：RNN在有向无循环图上的扩展<p>②GNN：将消息传递的思想扩展到图数据结构上，每个节点可以接收相邻节点消息并更新自己状态</p><p>【消息传递思想：隐状态看作节点，节点收到父节点的消息，更新自己状态，传递给子节点】</p><h1 id="qUcQA">第7章 网络优化与网络正则化</h1><h2 id="gHwZF">一、网络优化问题</h2>&gt; 网络优化问题——找到更好的局部最小值（平坦的）和提高优化效率&gt;<h3 id="ihLIC">1.从算法的优化出发，用更有效的优化算法：着眼于批量大小 / 学习率 / 梯度估计</h3><h4 id="A7Rga">（1）批量大小的选择：</h4>批量小：越有可能收敛到平坦最小值，，但需要设置较小学习率，否则模型会不收敛<p>批量大：训练稳定，可设置较大学习率，但越有可能收敛到尖锐最小值</p><p>批量大小较小时，可采用<u>线性缩放准则</u>【批量大小增加m倍时学习率也增加m倍】</p><p>=&gt;适当小批量</p><h4 id="ITMan">（2）学习率的调整：</h4><h5 id="Dq3D9">①学习率衰减（学习率退火）</h5>概念：经验上，学习率开始时保持大些以保证收敛速度，收敛到最优附近时小些以避免振荡<p>方法：分段常数衰减（阶梯衰减）/ 逆时衰减 / 指数衰减 / 自然指数衰减 / 余弦衰减 </p><h5 id="EDUhS">②学习率预热：</h5>Why：批量大时，需要较大学习率，但开始时梯度也大，初始学习率也大的话，训练不稳定<p>概念：开始时用小学习率，梯度下降到一定程度后再恢复初始学习率</p><p>方法：逐渐预热【按迭代次数从比较小的学习率逐渐增大，直至回到初始学习率】</p><h5 id="cteg7">③周期性学习率调整：</h5>Why：参数在尖锐最小值，增大学习率有助于逃离；在平坦最小值，增大后依然可能在其吸引域内<p>概念：周期性增大学习率</p><p>方法：循环学习率【让学习率在一个区间内周期性增大/缩小】【if线性缩放=&gt;三角循环学习率】</p><p>  带热重启的随机梯度下降【每间隔一定周期，学习率重新初始化为某预先设定值，然后衰减】</p><h5 id="Gdm6L">④AdaGrad算法：</h5>概念：每次迭代时先计算每个参数梯度平方累计值，效果上累计大的学习率小，累计小的学习率大<p>【但整体学习率随迭代次数增加而缩小】</p><p>缺点：if迭代多次还没找到最优点，那基本没希望了，因为学习率已经被搞得很低了</p><h5 id="BCPfw">⑤RMSprop算法：</h5>与AdaGrad区别：不算累计，算每次迭代的梯度平方的指数衰减移动平均<p>优点：每次迭代，每个参数学习率并不一定衰减，可能小可能大。</p><h5 id="Jh4vg">⑥AdaDelta算法：</h5>与AdaGrad和RMSprop区别：不仅用梯度平方的指数衰减移动平均来调整学习率，还引入每次参数更新差值的平方的指数衰减权移动平均<p>优点：在一定程度上平抑了学习率的波动</p><p>  【将RMSprop中的初始学习率改为动态计算的参数更新插值的平方的指数衰减权移动平均】</p><h4 id="DefH7">（3）梯度估计修正【cuz每次迭代的梯度估计和整个训练集上的最优梯度并不一致，具有随机性】</h4><h5 id="ely6I">①动量法：</h5>概念：计算负梯度的“加权移动平均”作为参数的更新方向；相当于模拟物理中动量的概念<p>效果：参数实际更新差值取决于最近一段时间内梯度的加权平均值</p><p>  【方向一致，参数更新幅度大，加速；方向不一致，梯度更新幅度小，减速】</p><h5 id="HoJsK">②Nesterov加速梯度（Nesterov动量法）</h5>概念：对动量法的改进。改进在“负梯度”是对谁的梯度。<p>改进：动量法分两步：</p><p>根据上一步参数更新方向更新一次得到参数theta hat；</p><p>再用当前梯度的反方向进行更新。</p><p>   问题在于当前梯度说的还是上一时刻的梯度，而不是theta hat的梯度，改为后者更合理。</p><h5 id="VfyZd">③Adam算法：</h5>概念：可看作动量法和RMSprop的结合，使用动量作为参数更新方向，且自适应调整学习率<p>计算：梯度平方的指数加权平均【类似RMSprop】+梯度的指数加权平均【类似动量法】</p><pre><code>    分别看作：梯度均值 和 未减去均值的方差。迭代初期值比真实小，偏差大，因此需做修正</code></pre><p>进一步的改进：引入Nesterov加速梯度，称为Nadam算法</p><h5 id="SpUCz">④梯度截断：</h5>概念：梯度爆炸时，梯度的模大于一定阈值，对梯度进行截断<p>方法：按值截断【超过区间，梯度就设为区间上限；低于区间，梯度就设为区间下限】</p><p>  按模截断【截断到一个给定的截断阈值b】</p><h3 id="C1YZT">2.从参数初始化的角度出发，用更好的参数初始化方法：</h3><h4 id="zvFkm">（1）预训练初始化：</h4>①概念：用已经在大规模数据上训练过的模型提供的参数初始值<p>②优点：通常具有更好的收敛性和泛化性</p><p>③缺点：灵活性不够，不能任意调整网络结构</p><h4 id="dAmdp">（2）固定值初始化：</h4>概念：对特殊参数，根据经验，用特殊固定值，初始化<h4 id="T4OKj">（3）随机初始化：</h4>①概念：避免全初始化为0导致的对称权重现象，对每个参数随机初始化，提高不同神经元间区分性<p>②基于固定方差的参数初始化：</p><p>概念：从固定均值&amp;方差的分布中采样，生成参数初始值</p><p>方法：高斯分布初始化【用高斯分布𝒩(0, 𝜎2)】</p><pre><code>均匀分布初始化【[−𝑟, 𝑟] 内采用均匀分布】</code></pre><p>问题：参数范围太小【导致神经元输出过小、Sigmoid型激活函数丢失非线性能力】</p><pre><code>       参数范围太大【导致输入状态过大、Sigmoid激活值饱和，梯度消失】</code></pre><p>解决：配合逐层归一化</p><h4 id="iJYyH">③基于方差缩放的参数初始化：</h4>概念：根据神经元的连接数量自适应调整初始化分布的方差<p>  【输入连接多，每个输入连接上的权重就应该小些，避免输出过大或过饱和/// vise versa】</p><p>方法：Xavier初始化【根据 𝑀𝑙−1 + 𝑀𝑙（分别是𝑙−1和𝑙 层神经元数量）初始化参数𝑙 层方差】</p><p>  【适用激活函数：恒等函数、Logistic函数、Tanh函数】</p><pre><code>      He初始化【使用ReLU函数时通常一半神经元输出为0，分布的方差近似为恒等函数一半】</code></pre><h4 id="JRwo3">④正交初始化：</h4>概念：将某层的权重矩阵初始化为正交矩阵<p>原因：用正交矩阵的性质，保证传播过程的范数保持性</p><p>步骤：用均值为0方差1的高斯分布初始化一个矩阵</p><pre><code>by奇异值分解得两个正交矩阵，用其一作为权重矩阵</code></pre><h3 id="s2SRg">3.数据预处理</h3><h4 id="sjoFQ">（1）尺度不变性：算法缩放全部/部分特征后不影响学习和预测</h4>      尺度敏感：影响<p>  =&gt;对样本预处理，各维特征转换到相同取值区间，消除不同特征相关性</p><h4 id="M7Oj4">（2）归一化：把数据特征转换为相同尺度</h4>方法：最小最大值归一化 / 标准化（Z值归一化）/ 白化<h3 id="SFViG">4.逐层归一化</h3>（1）概念：数据归一化应用到神经网络中隐藏层的输入中<p>（2）Why：</p><p>①更好的尺度不变性：低层参数改变不影响高层输入保持稳定+更高效进行参数初始化和超参选择</p><p>②更平滑的优化地形：优化地形平滑，梯度稳定，允许更大学习率，提高收敛速度</p><p>（3）常用方法：批量归一化 / 层归一化 / 权重归一化 / 局部响应归一化</p><h3 id="whF4i">5.超参数优化</h3><h4 id="AjPEd">（1）超参数</h4>①网络结构【神经元间连接关系、层数、每层神经元数量、激活函数类型】<p>②优化参数【优化方法、学习率、小批量样本数量】</p><p>③正则化系数</p><h4 id="G9eoa">（2）简单方法</h4>①网格搜索：尝试所有超参组合，分别训练模型，测试性能，选取最好的配置<p>②随即搜索：超参随机组合，然后思路同上</p><p>③贝叶斯优化：根据当前已实验的超参组合，预测下个可能最好的组合</p><p>Eg. 时序模型优化（SMBO）</p><p>需定义收益函数，Eg. 期望改善函数（EI函数）/ 改善概率 / 高斯过程置信上界（GP-UCB）</p><p>④动态资源分配：</p><p>思想：预先估计配置效果，差就中止评估，转而将资源留给其他配置</p><p>常用策略：早期停止策略</p><p>一种有效方法：逐次减半【但需要注意 超参数配置的数量N 的设置】</p><p>⑤神经架构搜索：通过神经网络来自动实现网络架构的设计</p><h2 id="micrX">二、网络正则化问题</h2>:::info"""<p>在传统机器学习中常采用ℓ1 和 ℓ2 正则化来限制模型复杂度，避免过拟合；</p><p>但在训练深度神经网络，特别是过度参数化（模型参数数量远大于训练数据数量）时，用其他方法更好。</p><p>“””</p><p>:::</p><h3 id="d2Nsu">1.ℓ1 和 ℓ2 正则化</h3>&gt; 就是在参数优化时加了一个λℓ(θ)，其中ℓ可以是一阶范数也可以是二阶范数，λ为正则化系数&gt;<p>（1）注意点1：ℓ1范数在零点不可导，需要用其他方式近似</p><p>（2）注意点2：ℓ1范数约束通常使优化出来的最优参数位于坐标轴上，使得最终参数为稀疏性向量（有好多0）</p><p>（3）注意点3：同时加入ℓ1和ℓ2正则化（相应的用两个正则化系数）称为弹性网络正则化</p><h3 id="e4xZY">2.权重衰减</h3>每次参数更新时引入衰减系数β，使得θt=(1-β)θt-1-αgt，gt是更新时梯度，α是学习率<h3 id="pVFJj">3.提前停止</h3>整一个验证集，验证集错误率不下降，就停止迭代优化，不继续下去了<h3 id="OwsR9">4.丢弃法</h3>随机丢弃神经元及其连接来避免过拟合，用掩蔽函数mask(·)来做这件事<p>（1）掩蔽函数做了啥：对于某层神经元的输入，训练阶段用丢弃掩码m来丢弃一些输入从而丢弃掉神经元及其连接（m由概率为p的伯努利分布随机生成）；测试阶段同样用概率p来乘所有输入来平衡被丢掉的和留下的输入</p><p>（2）集成学习角度的解释：每次迭代相当于训练一个不同的、共享原始网络参数的子网络；最终网络是子网络的集成</p><p>（3）贝叶斯学习角度的解释：（先验分布*网络）在所有参数上的积分，可以用M次dropout后的网络的算数平均来近似</p><p>（4）RNN上的dropout：</p><pre><code>    ①对非时间维度的连接（非循环连接）进行随即丢失【时间维度记录了隐状态不能乱丢】    ②变分丢弃法：对参数矩阵的每个元素进行随机丢弃，并且在所有时刻都要使用相同的丢弃掩码</code></pre><h3 id="sOpKA">5.数据增强</h3>通过算法对数据转变来增加数据量，避免在小数据量数据集上过拟合了，方法有旋转/翻转/缩放/平移/加噪声等<h3 id="naOcJ">6.标签平滑</h3>在输出标签中添加噪声，比如一些错误标注了的样本，最小化这些样本上的损失函数就会导致过拟合，所以加噪<p>（1）注意点1：标签用one-hot表示可看作硬目标，softmax分类器+min交叉熵损失函数会导致正确类和其他类权重差异很大，导致过拟合，所以对标签的one-hot编码来加噪，变成软目标，避免模型输出过拟合到硬目标上</p><p>（2）注意点2：按照类别相关性来给不同标签不同的噪声概率，称为知识蒸馏</p><h1 id="pqnN3">第8章 注意力机制与外部记忆</h1><h2 id="SIeD9">1.什么是注意力</h2>（1）概念：有意或无意从大量输入中选择小部分有用信息来重点处理，并忽略其他信息的能力<p>（2）分类：聚焦式注意力/选择性注意力【自上而下的有意识的】、基于显著性的注意力【自下而上的无意识的】</p><h2 id="hCqJk">2.注意力机制</h2>&gt; 作为一种资源分配方案，有限的计算资源用来处理更重要的信息&gt;<h3 id="J42Hu">（1）计算方式</h3>:::info在所有输入信息上计算注意力分布，然后根据注意力分布来计算输入信息的加权平均<p>:::</p><pre><code>  ①注意力分布：给定查询向量和输入向量集合，选择第n个输入向量的概率分布  ②加权平均：计算（选择第n个输入向量的概率 * 第n个输入向量）的累加</code></pre><h3 id="U08c6">（2）注意力机制变体</h3>      ①硬性注意力：只关注某个输入向量，要么选取最高概率的输入向量，要么在注意力分布式上随机采样<p>:::info<br>无法用反向传播训练了，需要使用强化学习，所以一般用软性注意力【软性注意力就是（1）中的那种注意力】</p><p>:::</p><pre><code>  ②键值对注意力：用键值对表示输入，键用来计算注意力分布，值用来计算聚合信息。这种方式的特殊点是输入信息的形式  ③多头注意力：用多个查询向量，并行地从输入中选多组，这样使得每个注意力关注输入信息的不同部分  ④结构化注意力：假设输入信息的重要程度存在差异，从而形成了层次结构  ⑤指针网络：仅采用注意力机制的注意力分布作为软性指针，指出相关信息的位置，输出序列是输入序列的下标</code></pre><h2 id="qolOn">3.自注意力（内部注意力）模型</h2>&gt; 为了建立输入序列之间的长距离依赖关系而使用&gt;<h3 id="OtgCs">（1）思想</h3>用注意力机制来“动态”生成不同连接的权重的全连接网络，注意动态生成的是不用连接的权重<h3 id="fPfC0">（2）做法</h3>采用QKV（查询-键-值）模式。先把每个输入映射到三个不同空间，分别得到了查询向量、键向量和值向量。然后用键值对注意力机制的原理（2.（2）.②），得到输出向量。<h3 id="rA0a2">（3）用法</h3>替换卷积层和循环层，也可以和这俩一起交替使用。<h3 id="L8j8H">（4）缺点</h3>忽略了输入信息的位置信息，单独使用时需要加入位置编码信息来进行修正<h2 id="ZbcYs">4.“记忆”的了解与认识</h2>长期记忆与短期记忆与工作记忆<p>:::info<br>长期记忆类比人工神经网络中的权重参数，短期记忆类比人工神经网络中的隐状态</p><p>:::</p><p>记忆在大脑皮层是分布式存储而不是局部存储</p><p>联想记忆是基于内容寻址的存储</p><p>工作记忆是临时存放和某任务相关的短期记忆和其他相关的内在记忆；临时存储和处理系统；维持时间短；”缓存“；容量小</p><p>外部记忆是神经网络借鉴工作记忆原理引入的</p><h2 id="FFknm">5.记忆增强神经网络MANN</h2>:::info**记忆增强神经网络MANN（记忆网络MN）：装备外部记忆的神经网络**<p>:::</p><h3 id="zEOcS">（1）端到端记忆网络MemN2N</h3>要存储的信息转换成两组记忆分别用于寻址和输出，然后主网络根据输入生成查询向量，用键值对注意力机制来读取记忆并产生输出。<p>【特点：外部记忆单元只读】</p><h3 id="layUo">（2）神经图灵机NTM</h3>控制器接收（当前输入+上时刻输出+上时刻读取外部记忆的信息），然后产生（当前输出+查询向量+删除向量+增加向量），然后开始读写。<p>读，从外部记忆读取信息，采用注意力机制来进行基于内容的寻址；</p><p>写，根据注意力分布按比例删除和增加每个记忆片段的删除向量和增加向量。</p><p>【特点：外部记忆可读写】</p><p>:::info<br>多跳操作：主网络根据上一次从外部记忆读取的信息，生成一个新的查询向量，而这个查询向量又继续用于读取外部记忆，这样循环多轮进行交互，从而可以实现更复杂的计算</p><p>:::</p><h2 id="v62sm">6.基于神经动力学的联想记忆</h2>:::color2是基于**内容**寻址的<p>应用：原理所对应的模型 or 用来增加外部记忆</p><p>两种联想记忆模型：</p><p>自联想模型：输入的模式与输出的模式在同一空间</p><pre><code>        eg.可通过前馈/循环神经网络等实现</code></pre><p>异联想模型：输入的模式和输出的模式不在同一空间</p><pre><code>           eg.大多机器学习问题可看作异联想，可作分类器</code></pre><p>:::</p><h3 id="kprvT">（1）Hopfield网络</h3>:::infoHopfield网络是由一组互相连接的神经元组成的RNN。<p>【属于自联想模型；每个神经元既输入也输出，无隐藏神经元】</p><p>:::</p><p>①更新方式</p><p>异步更新【每次更新一个神经元，顺序可随机也可预先指定】</p><p>同步更新【一次性更新所有神经元，需要时钟】</p><p>②能量=每个不同的网络状态【是标量】；</p><p>   网络收到外部输入后会演化到某个稳定状态</p><p>③稳定状态=吸引点Attractor=能量局部最优点=能量函数的局部最小点=网络中存储的模式Pattern</p><p>④检索：从接收到网络输入，随时间收敛到吸引点上的过程。</p><pre><code> 【每个吸引点对应一个管辖区域，输入落到该区域会收敛到该点】</code></pre><p>⑤存储容量怎么提升：改进网络结构、学习方式、引入更复杂的运算</p><h3 id="V6vM8">（2）使用联想记忆增加网络容量</h3>①将联想记忆模型作为部件引入LSTM网络<p>②将RNN的部分连接权重作为短期记忆，并通过一个联想记忆模型继续更新</p><h1 id="NZJpq">第9章 无监督学习</h1><h2 id="Hz2Zu">1.无监督学习问题分类</h2><h3 id="Im47V">（1）无监督特征学习</h3>从无标签训练数据中挖掘有效特征/表示<p>用来降维、数据可视化、监督学习前期的数据预处理</p><h3 id="P1szp">（2）概率密度估计</h3>根据一组训练样本来估计样本空间的概率密度<p>根据<strong>假设/不假设</strong>数据服从某个<strong>已知概率密度函数形式的分布</strong>，可以分为参数密度估计、非参数密度估计</p><h3 id="SqgRs">（3）聚类</h3>将一组样本根据一定的准则划分到不同的组（即簇）<p>eg.谱聚类、K-Means</p><h2 id="DN58a">2.无监督特征学习</h2><h3 id="giWWs">（1）主成分分析PCA——数据降维方法</h3>①思想：使得在转换后的空间中数据的方差最大，从而最大化数据差异性，保留更多原始数据信息<p>②手段：选择数据方差最大方向进行投影</p><p>③用处：作为监督学习的数据预处理方法，去除噪声并减少特征间相关性等</p><p>④局限性：不能保证投影后数据类别可分性更好</p><p><strong>PCA更详细内容见下：</strong></p><p><strong>李航《机器学习方法》中关于PCA的部分：</strong></p><p><a href="https://www.yuque.com/yuqueyonghucoit3e/wefx9h/mchuht0itomgngxq">第十六章 主成分分析</a></p><p><strong>周志华《机器学习》中关于PCA的部分：</strong></p><p><a href="https://www.yuque.com/yuqueyonghucoit3e/wefx9h/yg0rqrvmr4a9506x">主成分分析</a></p><h3 id="I0mF6">（2）稀疏编码</h3>①编码是啥：对 𝐷 维空间中的样本 𝒙 找到其在 𝑃 维空间中的表示（或投影）<p>②怎么得到编码：得找到一组完备的基向量（例如主成分分析PCA找到的主成分/投影矩阵）</p><p>③啥是完备：M个基向量能支撑M维的欧氏空间，就是完备，能支撑比M还高维的，就是过完备</p><p>④为啥要稀疏：稀疏好啊，稀疏有优点：</p><p>a. 计算量上：极大地降低计算量</p><p>b. 可解释性上：将输入样本表示为少数几个相关特征，更好描述特征</p><p>c. 特征选择上：可以实现特征自动选择，自动是指只选择和输入样本最相                                关的少数特征，能降低噪声，减轻过拟合</p><p>⑤怎么得到稀疏编码：得到编码，需要完备基向量，那稀疏编码，就需要过完备的基向量</p><p>⑥那怎么得到过完备基向量：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1730552224573-82cca291-9947-4ea8-961c-86189850d4b2.png"></p><p>按照这个图来找到，其中：</p><p>𝒁 = [𝒛<sup>(1)</sup>, ⋯ , 𝒛<sup>(𝑁)</sup>]， 这个集合里面每个元素都是一组基向量的系数𝒛，</p><pre><code>𝒛 = [𝑧1, ⋯ , 𝑧𝑀] ，𝒛 也称为一个输入样本 𝒙 的编码</code></pre><p>【1个样本，对应1组基向量，一个系数集合𝒛】</p><p>𝜌(⋅) 是一个稀疏性衡量函数，𝒛 越稀疏，𝜌(𝒛) 越小，函数可以选择</p><pre><code>                          ℓ1 范数 / 对数函数 / 指数函数</code></pre><p>𝜂 是一个超参数，用来控制稀疏性的强度</p><h3 id="pwkxW">（3）自编码器</h3>①干啥的：（D维数据+自编码器）——映射—— 得到M维特征空间下，每个样本的编码<p><strong><font style="color:#DF2A3F;">而这个编码，可以重构出原来的样本</font></strong></p><p><strong><font style="color:#DF2A3F;">自编码器可以得到有效的数据表示，例如最小重构错误、稀疏性等</font></strong></p><p>②结构：编码器 f（把数据从D维映射到M维）</p><p>解码器 g（把数据从M维重构到D维）</p><p>③学习目标：既然是为了要重构原来的样本，就应该<strong>最小化重构错误</strong></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731157201110-cbd55a19-fec0-43f8-a017-9d0bae32bb06.png"></p><p>也就是最小化上面这个式子</p><p>④根据维度来讨论：</p><p>a. 𝑀 ≥ 𝐷：一定可以找到一组或多组解使得 𝑓 ∘ 𝑔 为单位函数并使得重构错误为 0</p><p>然后<strong>加一些约束</strong>，比如要求编码只能取K个不同值，那就转换为K类的聚类问题的解了</p><p>b. 𝑀 &lt; 𝐷：相当于一种降维/特征抽取方法了</p><p>⑤简单自编码器：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731157508881-3602b56b-1def-49ba-ad3f-213a43d178aa.png"></p><p>如果W2=W1的转置，就成为捆绑权重，这会使得自编码器参数少，更容易学习，还起到一定的正则化作用。</p><p>通过最小化重构错误 <code> ℒ=  ∑  ‖𝒙(𝑛) − 𝒙′(𝑛))‖2 + 𝜆‖𝑾 ‖2𝐹 .</code> 学习网络参数</p><h3 id="XQHlz">（4）稀疏自编码器</h3>①概念：𝑀 &gt; 𝐷，且让我们映射到的这个M维特征空间下，样本编码尽量稀疏<p>②学习目标：最小化重构错误，目标函数为<code>ℒ=  ∑  ‖𝒙(𝑛) − 𝒙′(𝑛))‖&lt;sup&gt;2&lt;/sup&gt; + 𝜂𝜌(𝒁) + 𝜆‖𝑾 ‖&lt;sup&gt;2&lt;/sup&gt;</code></p><p>其中稀疏性度量函数 𝜌(𝒁)可以有多种定义：</p><p>a. 利用“稀疏编码”一节中的公式，分别计算每个编码稀疏度，再求和</p><p>b. 定义为一组训练样本中，<strong>每一个神经元激活的概率</strong></p><pre><code>这个概率可用隐藏层某个神经元的**平均活性值**来近似希望该平均活性值接近于事先给定的某值，用KL距离来衡量差异</code></pre><p>   <code>KL(𝜌∗|| ̂ 𝜌𝑗) = 𝜌∗ log 𝜌∗ ̂ 𝜌𝑗 + (1 − 𝜌∗) log [(1 − 𝜌∗) / (1− ̂ 𝜌𝑗)] </code></p><pre><code>所以也就是将稀疏性度量函数定义为 𝜌(𝒁) =  ∑ KL(𝜌∗|| ̂ 𝜌𝑗).</code></pre><h3 id="rR8RA">（5）堆叠自编码器</h3>用逐层堆叠方式来训练一个深层的自编码器，采用逐层训练来学习网络参数<h3 id="YAOig">（6）降噪自编码器</h3>①目的是干啥的：对数据部分损坏的鲁棒性——希望从坏了的数据中也能得到有效数据表示，恢复完整原始信息<p>②怎么达到的目的：引入噪声增加编码鲁棒性</p><p>③过程：向量x—按比例μ随机将部分维度值设为0—破损向量x—输入给自编码器—编码z—重构出无损原始输入x</p><h2 id="CV45h">3.概率密度估计</h2><h3 id="DRqd4">（1）参数密度估计</h3>①概念：根据先验知识，假设随机变量服从某种分布，然后通过训练样本，估计分布的参数<p>②过程：第一，假设服从<code>𝑝(𝒙;𝜃)</code>这样一个概率分布函数</p><p>第二，求对数似然函数，也就是求个对数，<code>log 𝑝(𝒟;𝜃) = ∑ log 𝑝(𝒙(𝑛);𝜃)</code></p><p>第三，最大似然估计MLE，寻找使<code>log 𝑝(𝒟;𝜃)</code>最大的<code>𝜃</code>，使参数估计问题变成了最优化问题</p><p>③会遇到的问题：</p><p>a. 这个概率密度函数的选取，可能不那么好选，因为实际数据分布往往复杂，不是简单的分布</p><p>b. 训练样本只包含部分可观测变量，有些关键变量无法观测到，就很难准确估计真实分布</p><p>c. 维数灾难，高维数据维数越高，参数估计问题所需要的样本就越多，样本不足时会过拟合</p><p>④常见的概率分布函数的选取：</p><p>a. 正态分布：要估计的参数是均值<code>μ</code>和方差<code>Σ</code></p><p>b. 多项分布：要估计的参数是第k个状态的概率<code>μ&lt;sub&gt;k&lt;/sub&gt;</code>和拉格朗日乘子<code>λ</code></p><pre><code>                   （引入拉格朗日乘子将问题转换成了无约束优化问题）</code></pre><h3 id="LL2kC"> （2）非参数密度估计</h3><h4 id="VXEMr">①概念</h4>不假设数据服从某种分布了，而是把样本空间划分成不同区域，估计每个区域的概率，近似数据的概率密度函数`𝑝(𝒙)`<p>每个区域的概率：<code>𝑃&lt;sub&gt;𝐾&lt;/sub&gt; = C&lt;sup&gt;𝑁&lt;/sup&gt;&lt;sub&gt;𝐾&lt;/sub&gt; 𝑃&lt;sub&gt;𝐾&lt;/sub&gt; (1 − 𝑃)&lt;sup&gt;1−𝐾&lt;/sup&gt;</code><sup> </sup>【二项分布】</p><p>N非常大时，近似：<code>𝑃≈ 𝐾/𝑁</code></p><p>又假设区域足够小（V足够小），则内部概率密度均匀、相同：<code>𝑃 ≈ 𝑝(𝒙)𝑉</code></p><p>然后我们就得到了<code>𝑝(𝒙)≈ 𝐾/𝑁𝑉</code></p><h4 id="y6PeY">②总结一下条件要求</h4>**N足够大+V足够小**<p>但V过小：落入区域样本少，概率密度不准确</p><p>解决方案：</p><p>A. 固定区域大小V，统计落入不同区域的数量——直方图方法、核方法</p><p>B. 改变区域大小V，使得落入每个区域的样本数量都为K个——K近邻方法</p><h4 id="kNgEq">③直方图方法</h4>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1731241433309-cceb05f3-fbce-4f8a-934f-2a1e30392b6f.png)<p>优点：处理低维变量快速可视化数据分布</p><p>缺点：很难扩展到高维变量</p><p>   需要的样本数量随维度增加而指数增长，导致维数灾难</p><h4 id="VXNh3">④核方法（核密度估计，也叫 Parzen 窗方法）</h4>原理就是定义核函数，如果落在核函数表示的空间内，核函数的值为1，否则为0，<p>从而每一个点的密度估计就可以用：</p><p>（落入区域的样本数量K、）训练样本数量N、核函数表示空间的边长H来得到</p><h5 id="LqM7K">超立方体核函数</h5>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1731242339850-1d873b55-62b1-43e1-8646-fa8e6eab03db.png)![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1731242356384-deb08fe7-6b60-4dfc-8d9d-f4defdcc8c54.png)<p>然后就得到了：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731242371652-7d5125da-6980-477d-b31f-0791c7085cd9.png"></p><h5 id="UbbNz">高斯核函数</h5>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1731242424604-234eca7b-08a3-43be-8cc8-00001d5f8724.png)<p>然后就得到了：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731242448718-57d4ee0b-e42e-49e7-ab00-049fce19a979.png"></p><h4 id="IX3Od">⑤K近邻方法（KNN）</h4>KNN用于分类已经很熟悉了<p>在密度估计上，KNN是这么做的：</p><p>设置可变宽度区域，使落入每个区域样本数量都是为固定数量K个</p><p>然后我们在估计某点的密度时，找到以这个点为中心的球体，这个球体的大小使得落入球体的样本数量也是K个。</p><p>从而我们得到了V，而N是训练样本数量已知，K我们预先设定。</p><p>然后根据<code>𝑝(𝒙)≈ 𝐾/𝑁𝑉</code>就可以了。</p><h1 id="vnKAo">第10章 模型独立的学习方式</h1>&gt; 模型独立：学习方式不限于具体模型（但是也会因模型特性不同而有不同程度的效果）&gt;<h2 id="czZNW">一、集成学习</h2><h3 id="Vhx1E">1.思想</h3>![](https://cdn.nlark.com/yuque/0/2024/jpeg/40781129/1731583480002-1a07602d-01de-4c33-8658-5f05c9a74693.jpeg)<p>“三个臭皮匠赛过诸葛亮”的同时，需要每个基模型差异尽可能大（和而不同）</p><p><strong><u>=&gt; 使差异大的方式：Bagging类方法，Boosting类方法</u></strong></p><h3 id="yHj3Y">2.Bagging类方法</h3><h4 id="lpPJa">（1）思想</h4>引入随机性：随机构造训练样本/随机选择特征<h4 id="jFr9w">（2）Bagging——随机构造训练样本</h4>在原始数据集上进行有放回的随机采样，得到M个小训练集，训练M个模型，然后投票<p><img src="https://cdn.nlark.com/yuque/0/2024/jpeg/40781129/1731583942158-8d1d144b-df6a-4211-9043-165de7c02a15.jpeg"></p><h4 id="QR2dy">（3）随机森林——Bagging+随机选择特征</h4>每个基模型都是一颗决策树<h3 id="gYTH4">3.Boosting类方法</h3><h4 id="NXXKT">（1）思想</h4>每个基模型针对**前序模型的错误**进行专门训练<p> =&gt;前序模型发生错误的训练样本的权重，调高！反之，调低！</p><h4 id="r6F5d">（2）目标</h4>学习一个加性模型：`加性模型 = 从1到M求和（第m个基分类器的集成权重 * 第m个基分类器）`<pre><code>                                          （基分类器=弱分类器）</code></pre><h4 id="DJ4Ax">（3）AdaBoost算法</h4><h5 id="Ktc2S">①思想</h5>通过**改变数据分布**来提高分类器的差异，迭代训练<p>=&gt;每轮训练增加分错样本的权重，减少分对样本的权重</p><h5 id="nhC6N">②算法</h5>        * 根据第`m`轮的样本权重，学习第`m`个分类器`𝑓<sub>𝑚</sub>`        * 计算`𝜖<sub>𝑚</sub>`，`𝜖<sub>𝑚</sub>`是弱分类器`𝑓<sub>𝑚</sub>`在数据集上的加权错误        * 计算`𝛼<sub>𝑚</sub>`，`𝛼<sub>𝑚</sub>`是第`𝑚`个分类器在集成时的权重，`𝛼<sub>𝑚 </sub>← 1/2 * log (1 −𝜖<sub>𝑚</sub>/𝜖<sub>𝑚</sub>)`        * 调整样本权重，`𝑤<sup>(𝑛) </sup><sub>𝑚+1</sub> ← 𝑤<sup>(𝑛)</sup> <sub>𝑚</sub> exp ( − 𝛼<sub>𝑚</sub>𝑦<sup>(𝑛)</sup>𝑓<sub>𝑚</sub>(𝒙<sup>(𝑛)</sup>)), ∀𝑛 ∈ [1, 𝑁]`        * 根据第`m+1`轮的样本权重，学习第`m+1`个分类器`𝑓<sub>𝑚+1</sub>`        * 。。。。。。。<h4 id="a9Te4">（4）《机器学习方法》中关于Boosting的内容</h4>[第8章 Boosting](https://www.yuque.com/yuqueyonghucoit3e/wefx9h/lu10ii76mdplhi4g)<h2 id="qEacI">二、自训练和协同训练——半监督学习算法</h2><h3 id="sY5OH">0.半监督学习</h3>少量标注数据 + 大量无标注数据 --&gt; 进行学习<h3 id="zuref">1.自训练/自举法</h3><h4 id="SxkPp">（1）思想</h4>有标注的数据——训练模型——模型预测无标住样本标签——预测置信度高的样本+模型预测的无标注样本的标签<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731587795982-6676d8ef-9874-4c8c-a522-cefc1bb7563b.png"></p><h4 id="A4Ege">（2）缺点</h4>无法保证伪标签是正确的——if伪标签是错的，反而会损害模型预测能力<h3 id="iJ5rn">2.协同训练——自训练的一种改进方法</h3>:::info**视角**的概念：      数据的不同侧面<p>eg.每个网页的类别，可以从文字内容判断（视角V<sub>1</sub>），也可以根据网页间链接关系判断（视角V<sub>2</sub>）</p><p>:::</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731589553571-29e6de06-557f-4ae4-8f99-99be0e938f51.png"></p><p>训练出的模型f1，f2具备两个不同的视角，具有一定的互补性</p><h2 id="m0RWe">三、多任务学习</h2><h3 id="LOdVw">1.思想</h3>**<font style="color:#DF2A3F;">同时</font>**学习多个**<font style="color:#DF2A3F;">相关任务</font>**，学习过程中**<font style="color:#DF2A3F;">共享知识</font>**，利用**<font style="color:#DF2A3F;">任务间相关性</font>**来改进模型在每个任务上的性能和泛化能力<p>可看做一种归纳迁移学习——利用包含在相关任务中的信息，作为归纳偏置，以提高泛化能力</p><h3 id="Ege7Y">2.常见的4种共享机制</h3><h4 id="L76Gy">（1）硬共享模式</h4>不同任务的NN模型共用一些共享模块（**通常低层**）来提取**通用特征**<p>不同任务再设置私有模块（<strong>通常高层</strong>）来提取任务<strong>特定特征</strong></p><h4 id="OkzBy">（2）软共享模式</h4>不显式共享，而是允许每个任务从其他任务中**窃取**信息来提高自己的能力<p>=&gt;窃取方式：</p><p>①直接复制使用其他任务的隐状态</p><p>②使用Attention机制主动选取有用的信息</p><h4 id="ocZOg">（3）层次共享模式</h4>:::info神经网络**不同层抽取的特征类型**：<p>低层——低级的局部特征</p><p>高层——高级的抽象语义特征</p><p>:::</p><p>根据多任务学习中不同任务级别高低：</p><p>低级任务在低层输出</p><p>高级任务在高层输出</p><h4 id="iNt7K">（4）共享-私有模式</h4>共享模块和任务特定（私有）模块分开<p>共享模块——捕捉跨任务共享特征</p><p>私有模块——捕捉特定任务相关特征</p><h3 id="NwHWd">3.学习步骤</h3><h4 id="FzesQ">（1）联合训练阶段</h4>①随机初始化模型参数<p>②1······T轮迭代开始进行</p><p>③把每一个任务的训练集都随即划分小批量集合，划分数量<code>𝑐 = 𝑁&lt;sub&gt;𝑚&lt;/sub&gt;/𝐾&lt;sub&gt;𝑚&lt;/sub&gt;</code></p><p><code>𝑁&lt;sub&gt;𝑚&lt;/sub&gt;</code>为第<code>𝑚</code>个任务的训练集包含的样本数量</p><p><code>𝐾&lt;sub&gt;𝑚&lt;/sub&gt;</code>为第<code>𝑚</code>个任务的批量大小</p><p>④合并所有小批量样本，并随机排序打乱</p><p>⑤计算合并后的集合中，每个小批量样本上的损失，并更新参数</p><p>⑥继续迭代，直到结束，输出𝑚个模型</p><h4 id="XxBxd">（2）单任务精调阶段</h4>刚才得到了参数，基于这些参数，在每个单独任务进行精调<h3 id="cfgBZ">3.相较单任务学习泛化能力更好的原因</h3><h4 id="QN59U">（1）训练集更大（毕竟是多任务）</h4><h4 id="Dn6s9">（2）任务间有相关性（相当于隐式的数据增强）</h4><h4 id="gaaki">（3）避免过拟合到单个任务的训练集（共享需兼顾所有任务【相当于一种正则化】）</h4><h4 id="qAkhN">（4）获得了更好的表示（适用于多个不同任务）</h4><h4 id="Dq0HS">（5）可选择性利用其他任务学习到的隐藏特征</h4><h2 id="xrI3N">四、迁移学习</h2><h3 id="G1bsv">1.基础概念</h3><h4 id="oxga8">（1）领域`𝒟 = (𝒳, 𝒴, 𝑝(𝒙, 𝑦))`</h4><h5 id="SC1f1">①领域</h5>一个样本空间及其分布<h5 id="lBRws">②源领域`𝒟<sub>𝑆</sub>`</h5><h5 id="B1SRT">③目标领域`𝒟<sub>𝑇</sub>`</h5><h5 id="aS6kh">④领域间关系</h5>        * 不同领域：输入空间不同 或 输出空间不同 或 概率分布不同        * 源领域的样本数量一般远大于目标领域<h3 id="YYJlO">2.思想</h3>将相关任务的训练数据中的可泛化知识迁移到目标任务上<p>（利用源领域中学习的知识来帮助目标领域上的任务）</p><h3 id="pJnk6">3.归纳迁移学习与转导迁移学习</h3><h4 id="yo4hp">（1）归纳学习与转导学习</h4>归纳学习：最小化期望风险得到模型，一般的机器学习就是归纳学习<p>转导学习：最小化给定测试集上的错误率，训练阶段可利用测试集信息</p><h4 id="vwP8G">（2）归纳迁移学习</h4><h5 id="S4n8O">①思想</h5>源领域及其任务 --&gt; 学习出一般规律 --&gt;迁移到目标领域及其任务上<h5 id="O4tNd">②要求</h5><h6 id="Ie5aO">a.源领域和目标领域相关</h6><h6 id="nrxxv">b.源领域有大量训练样本（可以有标注可以无标注）</h6>            + 源领域有大量无标注数据时：<p>源任务 </p><p>–&gt; 转换为无监督学习任务（eg.自编码/密度估计）</p><p>–&gt; 学习出可迁移表示 </p><p>–&gt; 迁移到目标任务</p><pre><code>        + 源领域有大量有标注数据时：</code></pre><p>源任务 </p><p>–&gt; 学习训练出模型 </p><p>–&gt; 模型迁移到目标领域目标任务上</p><h5 id="pUvsh">③两种迁移方式</h5><h6 id="LDK3R">a.基于特征的方式</h6>预训练模型的输出/中间隐藏层的输出 --&gt; 作为特征 --&gt; 直接加入到目标任务的学习模型中<h6 id="U8onN">b.精调的方式</h6>在目标任务上复用预训练模型的部分组件，并对其参数进行精调<p>有针对性地选择预训练模型的不同层迁移到目标任务中</p><h5 id="ZfIg9">④预训练模型迁移的优点（相较于从零开始学习）</h5>a.初始模型性能比随机初始化的模型好<p>b.训练时模型的学习速度比从零开始学习快</p><p>c.模型最终性能更好，泛化性更好</p><h5 id="GrFlL">⑤与多任务学习的区别</h5>a.多任务学习是同时学习多个任务，归纳迁移学习是分两个阶段的<p>   （源任务上的学习阶段+目标任务上的迁移学习阶段）</p><p>b.多任务学习希望提高所有任务的性能，归纳迁移学习是单向知识迁移、只针对目标任务</p><h4 id="MVmpj">（3）转导迁移学习</h4><h5 id="whGwX">①思想</h5>直接利用源领域和目标领域的样本进行迁移学习 <h5 id="AVGfH">②常见子问题——领域适应</h5><h6 id="t5DvR">a.什么是领域适应问题</h6>假设源领域和目标领域有相同的样本空间，但**数据分布不同**<h6 id="TQGJ0">b.数据分布不一致的情况</h6>            + 协变量偏移：两领域输入边际分布不同，但后验分布（即学习任务）相同            + 概念偏移：两领域输入边际分布相同，但后验分布（即学习任务）不同            + 先验偏移：两领域中输出标签的先验分布不同，条件分布相同<p>:::info<br>协变量的概念：</p><p>可能影响预测结果的统计变量</p><p>机器学习中，可以看作输入</p><p>协变量偏移的概念：</p><p>输入在训练集和测试集上的分布不同</p><p>:::</p><h6 id="JQt5v">c.领域适应问题要做什么</h6>关键在于如何学习领域无关的表示！<h6 id="ChETY">  d.如何学习领域无关的表示</h6>            + 优化参数使得映射后的两个领域的输入分布差异最小<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731655469231-93cae5d4-0b14-4d57-a8e3-001ac120b81e.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731655482050-1cc32515-db47-4b39-ad4e-32b7daeb3bd4.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731655498958-cea3bf65-74ad-4676-a78f-5ff1e250c17c.png"></p><pre><code>        + 通过领域对抗学习</code></pre><p>引入领域判别器<code>𝑐</code>来判断一个样本是来自于哪个领域</p><p>if <code>𝑐</code> 不能判断一个映射特征的领域信息，则是一个领域无关的表示</p><p>具体做法见下图</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731654473639-580640f6-2a79-4ef8-930e-a50ec1813827.png"></p><h2 id="v8vFT">五、终身学习/持续学习</h2>&gt; 像人类一样具有持续不断的学习能力，不因新知识忘记旧知识，反而用旧知识帮助学习新知识&gt;<h3 id="c8Agn">1.终身学习和其他学习的比较</h3><h4 id="wptOW">（1）终身学习vs归纳迁移学习</h4>归纳迁移学习只关注优化目标任务性能，不关注知识的积累<p>终身学习目标是持续的学习和知识积累</p><h4 id="V8G1N">（2）终身学习vs多任务学习</h4>多任务学习在所有任务上同时进行联合学习<p>终身学习是持续的一个一个学习</p><h3 id="EziGi">2.关键问题——如何避免灾难性遗忘</h3>目前神经网络往往过参数化 --&gt; 一个任务有很多参数组合都可达到最好性能 --&gt; 选择一组不影响先前任务的参数<h4 id="nO8iq">一个方法——弹性权重巩固</h4>以两个任务的持续学习为例子<p><img src="https://cdn.nlark.com/yuque/0/2024/jpeg/40781129/1731674378952-13d5f429-766f-4532-b9ee-6beb2d45df01.jpeg"></p><h5 id="b9pTt">①对Fisher信息矩阵部分进一步说明逻辑</h5>我们用Fisher信息矩阵近似精度矩阵，是因为精度矩阵与协方差矩阵存在互为逆矩阵的关系。<p>本质上想要的是协方差矩阵。</p><p>同时Fisher信息矩阵可以简化为对角矩阵，由Fisher信息矩阵对角线构成。</p><h5 id="YURBy">②那么什么是Fisher信息矩阵呢</h5>性质：一种测量似然函数`𝑝(𝑥;𝜃)`携带的关于参数`𝜃`的信息量的方法<p>怎么得出的：首先，有一个通常的事实——一个参数对分布的影响，可以通过对数似然函数的梯度衡量</p><p>然后，我们就让设计一个打分函数<code>𝑠(𝜃)</code>以符合这个事实，即<code>𝑠(𝜃) = ∇&lt;sub&gt;𝜃 &lt;/sub&gt;log 𝑝(𝑥; 𝜃)</code></p><p>其中，这个函数有个性质，是期望为0，证明略</p><p>最后，这个函数的协方差矩阵，就是Fisher信息矩阵，可以衡量参数<code>𝜃</code>的估计的不确定性</p><p>也就是：<code>𝐹(𝜃) = 𝔼[𝑠(𝜃)𝑠(𝜃)&lt;sup&gt;T&lt;/sup&gt;]= 𝔼 [∇&lt;sub&gt;𝜃&lt;/sub&gt; log 𝑝(𝑥; 𝜃) (∇&lt;sub&gt;𝜃&lt;/sub&gt; log 𝑝(𝑥; 𝜃))&lt;sup&gt;T&lt;/sup&gt;]</code></p><p>（解释一下，这里就是在算协方差，Cov=E[s<sup>2</sup>]-(E[s])<sup>2</sup>，又因为期望为0，所以只剩前面那项）</p><p>得到之后的问题：对于<code>𝐹(𝜃)</code>表达式，其中的似然函数<code>𝑝(𝑥;𝜃)</code>我们不知道具体形式，咋办呢？</p><p>可用经验分布估计：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731675165688-e0da9d51-e692-4236-bff6-4d0302a2e68a.png"></p><p>然后怎么用：一方面，<code>𝐹(𝜃)</code>对角线的值反应<code>𝜃</code>在通过最大似然进行估计时的不确定性</p><p>–&gt;值大：则估计值方差越小，估计越可靠，携带关于数据分布的信息越多</p><p>–&gt;值小：则估计值方差越大，估计越不可靠，携带关于数据分布的信息越少</p><p>另一方面，可用作信息量的衡量，用下面这个公式来衡量</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731675394726-a4de5b76-d73d-4e9e-a2e5-020e20eaf099.png"></p><p>还有，得到了训练任务<code>𝒯&lt;sub&gt;𝐵&lt;/sub&gt;</code>时的损失函数</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731676099047-d3560297-1bce-4963-aa4b-57afb95d9630.png"></p><h2 id="SYQHd">六、元学习——学习的学习</h2>&gt; 动态调整学习方式，像人脑一样，面对不同任务，自动找到对应的解决方式&gt;<h3 id="L8l8Y">1.目的</h3>从已有任务中，学习一种学习方法或元知识，从而可以加速新任务的学习<h3 id="y3OjP">2.与归纳迁移学习的区别</h3>元学习更侧重从多种不同，甚至不相关的任务中，归纳出一种学习方法<p>而归纳迁移学习有相关性要求，即要求源领域和目标领域相关</p><h3 id="uHfxi">3.和元学习比较相关的机器学习问题——小样本学习</h3>每个类只有K个标住样本，其中K非常小<p>if K=1，称为单样本学习</p><p>if K=0，称为零样本学习</p><h3 id="CK2D4">4.典型的元学习方法</h3><h4 id="EtjbO">（1）基于优化器的元学习</h4>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1731677774745-7f000bae-cb5d-415c-881e-a5d751abdf1d.png)<h4 id="rB3ox">（2）模型无关的元学习 MAML</h4><h5 id="dtPSh">①做法</h5>假设所有任务来自共同的一个任务空间<p>–&gt; 利用这些任务学习一个通用表示（称为在所有任务上的元优化，也采用梯度下降进行优化，得到θ）</p><p>–&gt; 在特定单任务上，通过梯度下降来精调θ</p><h5 id="zBcfH">②目标</h5>学习一个参数θ，这个θ经过梯度迭代，就可以在新任务上达到最好性能<h5 id="Jjbor">③算法</h5>可以看一下，其实和前面说的做法是一致的<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1731678036284-fe6edbd4-185f-4da1-a78b-baf95b9f9aa5.png"></p><h1 id="bCqrh">第11章 概率图模型</h1>&gt; 用图结构来描述多元随机变量间条件独立关系的概率模型&gt;<h2 id="axIrE">问题的导出</h2>:::infoK维随机变量——联合概率为高维空间分布——难建模——需要参数量简直爆炸——怎么减少参数量<p>为了减少参数量——做独立性假设——<code>𝑝(𝒙) ≜ 𝑃(𝑿 = 𝒙)  =  ∏  𝑝(𝑥&lt;sub&gt;𝑘&lt;/sub&gt;|𝑥&lt;sub&gt;1&lt;/sub&gt;, ⋯ , 𝑥&lt;sub&gt;𝑘−1&lt;/sub&gt;)</code>连乘起来</p><p>连乘的是每个分开的条件概率——通过条件依赖关系大大减少参数量</p><p>但变量数量太多时条件依赖关系复杂——图结构可视化概率模型</p><p>——描述条件独立性+复杂联合概率模型分解为简单条件概率模型的组合</p><p>:::</p><h3 id="kl5eO">1.图模型的三个基本问题</h3><h4 id="UJkor">表示问题：如何用图结构描述变量间依赖关系</h4><h4 id="xpQ1c">学习问题：（图结构的学习）和参数学习</h4><h4 id="f6sFI">推断问题：已知部分变量，计算其他变量条件概率分布</h4><h3 id="CQkru">2.图模型与机器学习非关系</h3>很多机器学习模型可归结为概率模型<h2 id="JoUGg">二、模型表示</h2><h3 id="HCPsg">1.要素</h3><h4 id="u4R1Q">节点：一组/一个随机变量</h4><h4 id="NsJzI">边：随机变量间的概率依赖关系</h4><h3 id="m7fJd">2.分类</h3><h4 id="CqHfw">有向图模型</h4>        * 有向非循环图        * 有连边——两变量有因果关系——不存在其他随机变量使得这俩变量条件独立<h4 id="PLOUK">无向图模型</h4>        * 无向图        * 有连边——两变量有概率依赖关系，不一定因果关系<h3 id="NRJ0h">3.有向图模型=贝叶斯网络=信念网络</h3><h4 id="uhSkM">（1）两个节点直接连接</h4>它们必然非条件独立，且是直接因果关系——父节点是因，子结点是果<h4 id="bLLvk">（2）两个节点不直接连接，但经过其他节点可达</h4><h5 id="obDQH">①间接因果关系</h5><h5 id="EpbIc">②间接果因关系</h5><h5 id="H9K0M">③共因关系：<font style="color:#DF2A3F;">因</font>X<sub>2</sub>已知，则<font style="color:#DF2A3F;">独立</font></h5><h5 id="i8eAB">④共果关系：<font style="color:#DF2A3F;">果</font>X<sub>2</sub>已知，则<font style="color:#DF2A3F;">不独立</font></h5><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732105043856-3274b6f5-ae59-4501-96fb-e1373c2a0a76.png"></p><p>参照这张图来理解，其中<strong>x</strong><sub><strong>2</strong></sub>是中间节点</p><h4 id="EJrbG">（3）局部马尔可夫性</h4>给定父节点，则每个随机变量要条件独立于它的非后代节点<pre><code>    * 后代节点可以有关系    * 但是非后代节点得条件独立</code></pre><h4 id="kkqaN">（4）常见的有向图模型</h4><h5 id="x8CGs">①Sigmoid信念网络（SBN）</h5>![](https://cdn.nlark.com/yuque/0/2024/jpeg/40781129/1732106295267-ee842e09-d5b5-412a-84bc-2fd80eaaee18.jpeg)<p>与Logistic回归模型的区别：</p><pre><code>        + **𝒙**的本质：Logistic回归模型的**𝒙**是确定性参数而不是变量</code></pre><p>  Sigmoid信念网络的<strong>𝒙</strong>是随机变量</p><pre><code>        + 模型本质：Logistic 回归模型只建模条件概率 𝑝(𝑦|𝒙)，是一种**判别模型**      Sigmoid信念网络建模联合概率 𝑝(𝒙, 𝑦)，是一种**生成模型**</code></pre><h5 id="eiqir">②朴素贝叶斯分类器（NB）</h5>原理：贝叶斯公式+强独立性假设（朴素所在）---&gt; 计算每个类别条件概率<p><code>𝑝(𝑦|𝒙;𝜃) ∝ 𝑝(𝑦|𝜃&lt;sub&gt;𝑐&lt;/sub&gt;)  ∏  𝑝(&lt;font style="color:#DF2A3F;"&gt;𝑥&lt;/font&gt;&lt;sub&gt;&lt;font style="color:#DF2A3F;"&gt;𝑚&lt;/font&gt;&lt;/sub&gt;|𝑦;𝜃&lt;sub&gt;𝑚&lt;/sub&gt;)</code></p><p>若<code>&lt;font style="color:#DF2A3F;"&gt;𝑥&lt;/font&gt;&lt;sub&gt;&lt;font style="color:#DF2A3F;"&gt;𝑚&lt;/font&gt;&lt;/sub&gt;</code>是连续值——可用高斯分布建模</p><p>若<code>&lt;font style="color:#DF2A3F;"&gt;𝑥&lt;/font&gt;&lt;sub&gt;&lt;font style="color:#DF2A3F;"&gt;𝑚&lt;/font&gt;&lt;/sub&gt;</code>是连续值——可用多项式分布建模</p><h5 id="PAIDP">③隐马尔可夫模型（HMM）</h5>所有隐变量构成一个马尔可夫链<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732183548199-c6935779-03e7-4ebb-9e9f-e7d92c4add58.png"></p><p><code>𝑝(𝒙, 𝒚;𝜃) =  ∏ 𝑝(𝑦&lt;sub&gt;𝑡&lt;/sub&gt;|𝑦&lt;sub&gt;𝑡−1&lt;/sub&gt;, 𝜃&lt;sub&gt;𝑠&lt;/sub&gt;) 𝑝(𝑥&lt;sub&gt;𝑡&lt;/sub&gt;|𝑦&lt;sub&gt;𝑡&lt;/sub&gt;, 𝜃&lt;sub&gt;𝑡&lt;/sub&gt;)</code></p><p>  转移概率    输出概率</p><p><strong>《机器学习方法》中关于隐马尔可夫模型的内容：</strong></p><p><a href="https://www.yuque.com/yuqueyonghucoit3e/wefx9h/advx3ocg32wlbzhs">第10章 隐马尔可夫模型</a></p><h3 id="ozXvx">4.无向图模型=马尔可夫随机场=马尔可夫网络</h3><h4 id="PZLyk">（1）定义</h4>用无向图来描述一组具有局部马尔可夫性质的随机向量 𝑿 的联合概率分布的模型<p>（也就是具备局部马尔可夫性的无向图）</p><h4 id="SLHmd">（2）无向图的局部马尔可夫性</h4>𝑋<sub>𝑘 </sub>条件独立于 除了自己和邻居 以外的 所有节点<h4 id="hFiCs">（3）无向图模型的概率分解</h4><h5 id="qqGUB">①团</h5>无向图中的一个全连通子图——所有节点都有边相连 所形成的一坨<h5 id="LaiMp">②最大团</h5>不能被其他团包含了 就是最大团<p>当然 如果再加一个节点就不满足全连通性 也就是最大团</p><h5 id="HJcCt">③因子分解</h5>分布`𝑝(𝒙) &gt; 0`满足无向图中的局部马尔可夫性<p>=&gt;<code>𝑝(𝒙)</code>可表示为<code>𝑝(𝒙) = 1/𝑍 ∏ 𝜙&lt;sub&gt;𝑐&lt;/sub&gt;(𝒙&lt;sub&gt;𝑐&lt;/sub&gt;)</code> ——吉布斯分布</p><pre><code>            - `𝜙&lt;sub&gt;𝑐&lt;/sub&gt;(𝒙&lt;sub&gt;𝑐&lt;/sub&gt;) ≥ 0 `是定义在团 𝑐 上的势能函数            - 配分函数 ![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1732186231573-da14ef8a-40ec-4415-b16a-3d5cfae46907.png) 用来归一化乘积为概率形式</code></pre><h5 id="hdDyP">④吉布斯分布</h5>`𝑝(𝒙) = 1/𝑍 ∏ 𝜙<sub>𝑐</sub>(𝒙<sub>𝑐</sub>)` ，其中一般定义`𝜙<sub>𝑐</sub>(𝒙<sub>𝑐</sub>) = exp(−𝐸<sub>𝑐</sub>(𝒙<sub>𝑐</sub>))`且`𝐸<sub>𝑐</sub>(𝒙<sub>𝑐</sub>)` 为能量函数<pre><code>这个形式称为吉布斯分布                                              这样定义后，分布又称为玻尔兹曼分布</code></pre><p>性质是：吉布斯分布一定满足马尔科夫随机场条件独立性质</p><p>马尔科夫随机场的概率分布一定可以表示成吉布斯分布</p><h4 id="JvO88">（4）常见的无向图模型</h4><h5 id="U8f2w">①对数线性模型=条件最大熵模型=Softmax回归模型</h5>刚才提到的吉布斯分布`𝑝(𝒙) = 1/𝑍 ∏ 𝜙<sub>𝑐</sub>(𝒙<sub>𝑐</sub>)` ，让其中的`𝜙<sub>𝑐</sub>(𝒙<sub>𝑐</sub>)`为：<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732431840066-0d4487a7-8478-4f3b-a826-5a9d9cc58d69.png"></p><p>然后取对数：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732431951765-c0306155-024d-4288-8e93-dd73661e4f36.png"></p><p><code>𝑓&lt;sub&gt;𝑐&lt;/sub&gt;(𝒙&lt;sub&gt;𝑐&lt;/sub&gt;)</code> 为定义在 <code>𝒙&lt;sub&gt;𝑐&lt;/sub&gt; </code>上的特征向量；<code>𝜃&lt;sub&gt;𝑐&lt;/sub&gt;</code> 为权重向量</p><p>然后得到 <code>𝑝(𝑦|𝒙;𝜃)</code>：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732432705223-a1a99212-9e15-4b56-bdfa-cfc0c6fbcbbf.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732432717916-a87ea1e0-b49e-4c05-b9c0-99de5a5cfc8e.png"></p><p><strong>《机器学习方法》中关于最大熵模型的内容：</strong></p><p><a href="https://www.yuque.com/yuqueyonghucoit3e/wefx9h/kuyviah06zprz9yd">第6章 逻辑斯谛回归与最大熵模型</a></p><h5 id="vo5e5">②条件随机场</h5>对y要有分解，即：<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732433459453-fd2bb0b8-a667-4372-a7f6-a5017304ef74.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732433513466-f481cd6b-87f5-46ea-9916-a5cd2037f8d3.png"></p><p>（可以对比最大熵模型的条件概率公式，可以发现做了分解）</p><p>线性链条件随机场的条件概率：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732433649652-f447f7b7-762b-47d0-9e94-f5393ffa3188.png"></p><p><strong>《机器学习方法》中关于条件随机场的内容：</strong></p><p><a href="https://www.yuque.com/yuqueyonghucoit3e/wefx9h/sqqfozz09h4bxwmi">第11章 条件随机场</a></p><h5 id="HaBv0">③玻尔兹曼机</h5>见第12章<h5 id="jSYWl">④受限玻尔兹曼机</h5>见第12章<h4 id="EH0dn">（5）有向图和无向图间的转换</h4><h5 id="ANyjC">①为啥</h5>有向图转无向图，可以利用无向图上的精确推断算法，同时也可以表示有向图无法表示的一些**<font style="color:#DF2A3F;">依赖关系</font>**<p><strong><font style="color:#DF2A3F;">（注意不是所有关系，比如无向图是不能表示因果关系的）</font></strong></p><h5 id="ijXOF">②过程--道德化</h5>看图理解就行：<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732435783230-e206844d-6501-403d-a437-956c2d752a55.png"></p><h2 id="cIrVm">三、模型的学习</h2><h3 id="eVv2X">1.分类</h3>寻找最优网络结构（难，专家构建）+ 已知网络结构估计每个条件概率分布参数（按包不包含隐变量分两种）<h3 id="OShiy">2.不含隐变量的参数估计——最大似然</h3><h4 id="P6ZKa">（1）有向图模型</h4><h5 id="MKD0U">①第一步，构造对数似然</h5>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1732437128923-b4025d45-88d4-4a46-a7b7-41044978fe06.png)<p>从11.27到11.28，是因为：</p><p>”所有变量 𝒙 的联合概率分布可分解为每个随机变量 𝑥<sub>𝑘</sub> 的局部条件概率 𝑝(𝑥<sub>𝑘</sub>|𝑥<sub>𝜋𝑘</sub> ; 𝜃<sub>𝑘</sub>) 的连乘形式“</p><p>说人话就是：</p><p>可以拆成部分连乘形式，然后log一下，就变成了累加~</p><h5 id="sag9l">②第二步，最大化对数似然`ℒ(𝒟; 𝜃)`</h5>转化为分别最大化每个变量的条件似然，即：<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732450345026-e30f3f9d-ceb1-4576-af2e-f78d58f2e07b.png"></p><pre><code>    * 如果x离散——使用参数化模型减少参数量——例如用Sigmoid信念网络    * 如果x连续——用高斯函数表示条件概率分布——高斯信念网络</code></pre><h4 id="sWR8X">（2）无向图模型</h4><h5 id="tyWpf">①第一步，构造对数似然</h5>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1732451547729-41a915a2-a496-46fc-ae09-7dedb9ca4d57.png)<p>这里直接就代入了对数线性模型的概率公式：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732451683933-c6c5f730-d40e-4f77-81d5-b62fdda40513.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732451713638-d58634f0-0c33-4468-84a0-fb7917505bde.png"></p><h5 id="l259t">②第二步，最大化对数似然`ℒ(𝒟; 𝜃)`</h5>用梯度上升方法：<p>求关于𝜃<sub>𝑐</sub> 的偏导数，推导过程如下</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732451927296-28f92d00-455b-4d2f-8bdc-45eabd30742c.png"></p><p>最优点梯度为0，也就是式11.37等于0，从而也就是书上说的“优化目标等价于：对于每个团 𝑐 上的特征 𝑓<sub>𝑐</sub>(𝒙<sub>𝑐</sub>)，使得其在经验分布  ̃𝑝(𝒙) 下的期望等于其在模型分布 𝑝(𝒙; 𝜃) 下的期望”</p><p>式11.37的后半部分（在模型分布下的期望）很难算，通常采用近似，有两种方式：</p><p>a.利用采样来近似计算期望</p><p>b.坐标上升法：固定其他参数，优化一个势能函数的参数</p><h3 id="sn4iJ">3.含隐变量的参数估计</h3><h4 id="l1P7s">（1）EM算法</h4>&gt; 这里同样也是从最大化对数似然的原理出发得到的EM算法&gt;<p><strong>逻辑</strong>：首先我们有一个样本 𝒙 的边际似然函数（i.e.证据）</p><p>   然后构造对数似然，和前面”不含隐变量的参数估计“部分的公式原理相同，长下面这样</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1732453050356-b3b73707-88ab-47d2-ac16-b22a35378edd.png"></p><p>   然后我们要最大化对数似然，但涉及到 𝑝(𝑥) 的推断问题（导致对数函数内部的求和/积分去不掉且难算）</p><p>   然后我们就引入变分函数𝑞(𝒛)（定义在隐变量 𝒁 上的分布）来解决问题，得到下面这样</p><pre><code>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1732453192935-083b22ef-2d25-4118-891e-48487015a778.png)</code></pre><p>   所以最大化似然函数就转化为了两步<u><font style="color:#DF2A3F;">的不断重复直到收敛到局部最优解</font></u>：</p><h5 id="bEI0M">  ①E步</h5>固定参数 𝜃<sub>𝑡</sub>，找到一个分布 𝑞<sub>𝑡+1</sub>(𝒛) 使得证据下界 𝐸𝐿𝐵𝑂(𝑞, 𝒙; 𝜃<sub>𝑡</sub>) 等于 log 𝑝(𝒙; 𝜃<sub>𝑡</sub>)<p>其中，最理想有<code>𝑞(𝒛) = 𝑝(𝒛|𝒙,𝜃&lt;sub&gt;𝑡&lt;/sub&gt;)</code>，因为此时<code>𝐸𝐿𝐵𝑂(𝑞&lt;sub&gt;𝑡+1&lt;/sub&gt;, 𝒙; 𝜃)</code>最大</p><p>但是，如果𝒛的维度较高，<code>𝑝(𝒛|𝒙,𝜃&lt;sub&gt;𝑡&lt;/sub&gt;)</code>不好算，需要变分推断方法</p><h5 id="Jyivc">  ②M步</h5>固定 𝑞<sub>𝑡+1</sub>(𝒛)，找到一组参数使得证据下界最大<p><code>𝜃&lt;sub&gt;𝑡+1&lt;/sub&gt; = arg max &lt;sub&gt;𝜃&lt;/sub&gt; 𝐸𝐿𝐵𝑂(𝑞&lt;sub&gt;𝑡+1&lt;/sub&gt;, 𝒙; 𝜃)</code></p><p><strong>收敛性证明略</strong></p><p><strong>信息论视角推导出EM算法略</strong></p><p><strong>《机器学习方法》中关于EM算法的内容：</strong></p><p><a href="https://www.yuque.com/yuqueyonghucoit3e/wefx9h/gzld9qugrwi4yp08">第9章 EM算法及其推广</a></p><h2 id="UVy30">四、模型的推断</h2><h3 id="Z0QHd">1.推断</h3><h4 id="cvFJg">（1）概念</h4>观测到部分变量时，计算其他变量的某个子集的条件概率<p>=&gt;关键在：求任意一个变量子集的边际分布</p><h4 id="d4pVF">（2）分类</h4>精确推断、近似推断<h3 id="VWDDy">2.精确推断</h3><h4 id="uXRIe">（1）变量消除法</h4>`p(x<sub>1</sub>|x<sub>4</sub>)=p(x<sub>1</sub> , x<sub>4</sub>) / p(x<sub>4</sub>)`<p>其中：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734680575646-037268e4-d3bf-4733-bf75-f4ec9b5c7116.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734681007597-d391be22-debf-4405-8120-95b44abd8803.png"></p><p>这个过程中消除了变量，减少计算边际分布的计算复杂度</p><h4 id="ZFoqV">（2）信念传播算法=BP算法=和积算法=消息传递算法</h4>思想：将变量消除法的和积操作看作消息并保存<p>消息传递过程：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734681770197-a0f0547a-f35f-45c4-b225-24ceb13df0a1.png"></p><h5 id="ZEQly">树结构上的信念传播算法</h5>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734682085914-cd956ed9-69be-4b24-a7b2-b3736e6f51a0.png)<h3 id="E6KUZ">3.近似推断</h3>if图模型结构复杂=&gt;精确推断开销大<p>if图模型变量连续+积分函数没有闭式解=&gt;无法使用精确推断</p><h4 id="u4KD4">（1）环路信念传播</h4>在具有环路的图上用信念传播算法<h4 id="VN20P">（2）变分推断</h4>引入简单分布（称为变分分布）近似条件概率，迭代计算：<p>更新变分分布参数，最小化变分分布和真实分布的差异=&gt;根据变分分布来推断</p><h4 id="kM5du">（3）采样法</h4>用模拟方式采集符合某个分布的样本，用样本估计和分布有关的运算<h2 id="h9kWI">五、变分推断</h2>泛函：函数的函数，输入是函数，输出是实数=&gt; f(x)的泛函：F(f(x))<p>变分法：寻找使F(f(x))取得极大/极小值的f(x)</p><p>变分推断：推断问题转换为泛函优化问题——<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734685101039-de38636a-ae90-4b6a-97bd-3f70ef45bdbc.png">最小化变分分布和真实分布差异</p><p>这个问题的解法：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734686049345-b34320f9-b5a1-4e84-a7ed-9d1a03a11cee.png"></p><h2 id="FvcQ5">六、基于采样法的近似推断</h2>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734790562062-5efb041b-1a24-47f0-a957-2a454d9d2963.png)其中要推断的概率分布为p(x)，采样法近似计算这个期望<h3 id="cCl42">1.采样法=蒙特卡罗方法=统计模拟方法</h3>通过随机采样（给定概率密度函数中抽取符合其概率分布的样本）近似估计计算问题数值解<p>过程：p(x)中独立抽取N个样本 =&gt; N个样本的均值近似为f(x)的期望 =&gt; N无穷大时收敛于期望值</p><p>难点：如何让计算机生成满足p(x)的样本</p><p>解决方案：用p(x)的累积分布函数cdf(x)的逆函数来生成服从p(x)的样本</p><p>难点：累积分布函数cdf(x)的逆函数在p(x)复杂时难以计算</p><p>解决方案：见下</p><h3 id="MrdyV">2.拒绝采样=接受-拒绝采样</h3>p(x)难以采样 =&gt; 引入容易的采样的分布q(x) 称为提议分布 =&gt; 以某**<font style="color:#DF2A3F;">标准</font>**拒绝一部分样本 =&gt; 最终采集的样本浮层p(x) 【kq(x)覆盖未归一化的分布p(x)——kq(x)≥p(x)】<p>**<font style="color:#DF2A3F;">标准</font>**：每次抽取样本的接受概率</p><p>   <img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734791678715-f8c8ae40-382b-4433-bb27-77d5161e98c2.png"></p><p>判断拒绝采样的好坏：拒绝率太高，采样效率会不理想</p><h3 id="yoQOG">3.重要性采样</h3>思想：我只是想算那个期望（𝔼𝑝[𝑓(𝑥)]），抽取的样本其实不用严格服从p(x)，所以用提议分布q(x)直接采样并估计期望<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734792317276-822ffe69-1c8f-40b2-98da-686e4e54ff43.png"></p><p>w(x)是重要性权重</p><h3 id="oGTmP">4.马尔可夫链蒙特卡罗方法 MCMC</h3>思想：将采样过程看成马尔可夫链——第t+1次采样依赖于第t次抽取的样本和状态转移分布（即提议分布）<p>关键：构造出平稳分布为p(x)的马尔可夫链，且状态转移分布容易采样</p><p>预烧期：马尔可夫链需要一段时间的随机游走才能达到平稳状态，这个时期内的采样点要丢掉！</p><h4 id="OIFcY">（1）Metropolis-Hastings算法=MH算法</h4>动机：状态转移分布（提议分布）的平稳分布往往不是p(x)<p>思想：引入拒绝采样来修正提议分布，使最终采样的分布为p(x)</p><p>与拒绝采样的区别：第t+1次采样样本的接受概率和第t次所采样的样本有关系！</p><h4 id="s9j2G">（2）Metropolis算法</h4>在MH算法基础上，加限定条件：提议分布是对称的<p>这样使得接受率公式简化了！</p><h4 id="FydVD">（3）吉布斯采样</h4>可看作MH算法的特例<p>思想：使用全条件概率作为提议分布，对每个维度采样，设置接受率A=1</p><p>全条件概率：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734793771706-409738d2-dadf-4114-a237-052294c00b99.png"></p><p>每单步采样构成马尔可夫链。</p><h3 id="nAKdB">5.几种方法的对比</h3>拒绝采样、重要性采样——效率随空间维数的增加而指数降低<p>马尔可夫链蒙特卡罗方法——容易对高维变量进行采样</p><h1 id="O8b7I">第12章 深度信念网络</h1><h2 id="KScF4">一、玻尔兹曼机</h2><h3 id="NLw3k">1.形式</h3>看图理解<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734796524691-e180d359-03a2-4bfc-a923-5b04a03d0766.png"></p><h3 id="n03kA">2.玻尔兹曼分布</h3>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734796646984-6711063e-c282-4808-b498-e0be102a6b2a.png)<p>𝐸<sub>𝛼</sub> 为状态 𝛼 的能量，𝑘 为玻尔兹曼常量，𝑇 为系统温度,  exp( −𝐸<sub>𝛼</sub> /𝑘𝑇 ) 称 为玻尔兹曼因子</p><h3 id="MlLI2">3.玻尔兹曼机</h3><h4 id="hVSyU">（1）概念</h4>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734797899548-e18f5c9f-e28f-4b39-af6c-9a589f7f8f8c.png)<p>x<sub>i</sub> 取值1表示模型接受x<sub>i</sub>代表的假设，取值0代表模型拒绝x<sub>i</sub>代表的假设</p><p>w<sub>ij</sub>表示两个假设间的弱约束关系，为正说明相互支持，可能被同时接受，为负反之</p><h4 id="ubRPJ">（2）应用</h4><h5 id="wwcAY">①解决搜索问题</h5><h5 id="smofE">②解决学习问题</h5><h3 id="j9a6M">4.生成模型——以基于吉布斯采样生成样本为例</h3>过程：<h5 id="rQTlI">①随机选择变量X<sub>i</sub></h5><h5 id="gvgH3">②根据全条件概率设置状态为1或0</h5>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734799154446-6072a38d-1108-4b19-a2dc-9a5cb1731641.png)<h5 id="C7uzM">③固定温度T下运行足够时间，达到热平衡</h5>T → ∞ ： 可以很快达到热平衡<p>T → 0 ： 变成确定性方法，退化成Hopfield网络</p><h5 id="qR6BQ">④此时任何全局状态概率服从玻尔兹曼分布p(x)，只与系统能量有关，与初始状态无关</h5><h3 id="MZjhz">5.能量最小化与模拟退化</h3><h4 id="GtL6G">（1）能量最小化</h4>简单、确定性方法如Hopfield网络，会收敛到局部最优解而不是全局最优<h4 id="N3dX1">（2）模拟退火</h4>目的：作为寻找全局最优的近似方法<p>过程：刚开始在高温运行达到热平衡，然后逐渐降低，直到低温也达到热平衡</p><h3 id="a2lo5">6.参数学习</h3>学习的参数是：W和b<p>定义对数似然函数后求偏导</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734807044635-9de356f5-3af0-4fec-b59e-d49ddcb13f31.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734808682577-bc3b2a42-1820-421a-ae19-93a334c27a2a.png"></p><p>涉及计算配分函数和期望，难精确计算，所以用MCMC方法来近似求解：</p><p>固定住可观测变量 𝒗，只对 𝒉 进行吉布斯采样</p><p>=&gt; 达到热平衡，采样x<sub>i</sub> x<sub>j</sub>的值</p><p>=&gt; 近似期望</p><h2 id="AQ5OT">二、受限玻尔兹曼机</h2>玻尔兹曼机每更新一次权重就要重新热平衡，低效<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734809842162-64f42c0f-ccf5-4c69-8066-bcfdfa3e5a17.png"></p><p>规定能量函数和联合概率分布：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734852124541-96fdb738-0882-4501-a5b9-398283731918.png"></p><h3 id="iEkwR">1.生成模型</h3>给定联合分布概率：<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734853364005-2febe201-d902-4fe3-aaf9-233d7275c700.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734853904348-77c5b7ec-32d4-493b-b1af-31d94b58a9b7.png"></p><p>吉布斯采样：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734855168838-f32d84b2-4fd9-48cf-a21c-f74e2e666832.png"></p><h3 id="q6TSW">2.参数学习</h3>要学习的参数：W a b<p>方法：最大化对数似然函数</p><p>   <img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734855677926-171af57b-16dd-46fd-a364-419911fdffb6.png"></p><p>   求偏导</p><p>   <img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734855713346-93110036-b3a6-4eee-a7b9-d93b1d070cd4.png"></p><p>   要算配分函数和俩期望，难算，用MCMC方法近似：</p><pre><code> 固定v并设为训练样本中的值，根据条件概率对h采样， 再不固定v，通过**吉布斯采样**轮流更新v和h，达到热平衡采集v和h的值</code></pre><p>  <img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734855819640-768a7acf-0968-4fe2-a676-faf5cf39fe6e.png"></p><h4 id="gXYha">对比散度学习算法（对受限玻尔兹曼机来说，比吉布斯采样更有效）</h4>【CD-k算法】<p>用一个训练样本作v的初始值 =&gt; 交替对v和h进行吉布斯采样 =&gt;不需要等到收敛，k步足够</p><h3 id="ZgWPx">3.受限玻尔兹曼机的类型</h3><h4 id="Fipyq">（1）伯努利-伯努利 受限玻尔兹曼机</h4><h4 id="HXlQJ">（2）高斯-伯努利 受限玻尔兹曼机</h4><h4 id="AA43k">（3）伯努利-高斯 受限玻尔兹曼机</h4><h2 id="Ui3lE">三、深度信念网络 DBN</h2>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734856597048-732159c8-0c9f-4db3-8cf0-f78330bf0f5c.png)<p>有：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734856848614-401440eb-a9ae-4aa0-84ea-2c0a2f866f3e.png">且<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734856893382-4db6b3ea-5aac-42a6-aa01-cd723b50db0b.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734856877023-7337507f-9ea6-440c-be02-d85a4a1d7cba.png"></p><h3 id="JzuFr">1.生成模型</h3>生成样本过程：<p>运行顶层受限玻尔兹曼机，进行足够多次吉布斯采样</p><p>=&gt;达到热平衡，生成样本h<sup>(L-1)</sup></p><p>=&gt;计算下一层变量条件分布+采样</p><p>=&gt;continue</p><h3 id="uB3X3">2.参数学习</h3>过程：<p>每层Sigmoid信念网络转化成受限玻尔兹曼机【隐变量后验概率相互独立】</p><p>=&gt;逐层训练【自底向上，每次训练一层，训练包括俩阶段：逐层预训练、精调】</p><h4 id="Co8yZ">（1）逐层预训练</h4><h4 id="RVMND">![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734857888794-e31c4cbc-c4b3-4c9d-b9d0-217ec34bf59f.png)</h4><h4 id="rStTu">（2）精调</h4><h5 id="FcBw4">①作为生成模型的精调</h5>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734858258324-4703410a-0bd8-419e-bd3f-16006ab8aa60.png)<p>生成权重：向下的 | 定义原始生成模型</p><p>认知权重：向上的 | 反向计算上行的条件概率</p><h6 id="n4hG5">Wake-Sleep算法</h6>![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734870461235-e5203462-6c66-4b02-bc57-a87799f05541.png)<p>交替两个阶段直到收敛</p><h5 id="BpbKs">②作为判别模型的精调</h5>在深度信念网络的最顶层再增加一层输出层，然后使用 反向传播算法 对这些权重进行调优<h1 id="SOC8P">第13章 深度生成模型</h1>概率生成模型=生成模型：<p>根据可观测样本，学习参数化模型，<strong>近似未知分布</strong>，<strong>生成与真实样本相近的样本</strong></p><pre><code>     &lt;font style="color:#DF2A3F;"&gt;概率密度估计    &lt;/font&gt;            &lt;font style="color:#DF2A3F;"&gt;生成样本（采样）&lt;/font&gt;</code></pre><p>深度生成模型：</p><p>利用深度神经网络建模复杂分布/生成符合分布的样本</p><h2 id="Uk3UT">一、概率生成模型</h2><h3 id="Mo5jo">1.密度估计</h3>概念：根据数据集估计它的概率密度函数pde<p>难点：不存在复杂依赖关系，难用图模型</p><p>解决：引入隐变量，用EM算法</p><p>问题：EM算法需要估计的条件分布比较复杂的时候咋整？</p><p>解决：变分自编码器——用神经网络建模</p><h3 id="C4Vct">2.生成样本=采样</h3>概念：给定pde，生成相应样本<p>过程：在EM算法中，隐变量先验分布采样+条件分布采样</p><p>生成对抗网络的思想：从简单分布中采集出的样本，送到神经网络里，使得输出服从我们的分布，避免了密度估计</p><h3 id="ELtoe">3.应用于监督学习</h3>典型：朴素贝叶斯、隐马尔可夫<p>on opposite：判别模型 eg.Logistic回归、SVM、神经网络</p><p>关系：生成模型可得到判别模型，反之不成立</p><h2 id="ho4Xg">二、变分自编码器</h2>为了得到，拆解为：![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872132020-29cfc142-d992-4720-8a53-6564c6d4d86b.png)<p>假设拆解后的这两个分布都服从某种参数化分布族，则用最大似然来估计</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872212071-28d2e2b9-7b07-4cf0-8378-a64ef61d194f.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872221422-4a026eed-9c6c-412e-8793-07354e29e21b.png"></p><p>其中<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872245297-dff73eee-ee45-4229-bd70-b090bf0554bf.png">是额外引入的变分密度函数</p><p>最大似然过程用EM：</p><p>E：寻<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872327662-eaa2c392-5837-4277-837a-d1a9a831512d.png">等于/接近<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872347092-b0ea8dc8-cdeb-46e0-ace0-ac7fffeeada0.png"></p><p>M：固定<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872327662-eaa2c392-5837-4277-837a-d1a9a831512d.png">，找θ，最大化ELBO</p><p>理论最优<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872327662-eaa2c392-5837-4277-837a-d1a9a831512d.png">=<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872347092-b0ea8dc8-cdeb-46e0-ace0-ac7fffeeada0.png">：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872406231-9a674c89-3979-47ec-9912-78154f69f72a.png">，但这个<strong>不好计算</strong></p><p>解决方案：变分推断，近似估计，用简单的<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872327662-eaa2c392-5837-4277-837a-d1a9a831512d.png">来近似推断<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872347092-b0ea8dc8-cdeb-46e0-ace0-ac7fffeeada0.png"></p><p>问题：<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872347092-b0ea8dc8-cdeb-46e0-ace0-ac7fffeeada0.png">一般复杂，近似效果不好，也难用已知分布族函数建模</p><p>解决方案：变分自编码器</p><p>解决具体方式：</p><p>用神经网络估计<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872327662-eaa2c392-5837-4277-837a-d1a9a831512d.png">（近似<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872347092-b0ea8dc8-cdeb-46e0-ace0-ac7fffeeada0.png">）——这个神经网络称为推断网络——输入x，输出<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734874168597-1067d6f0-e503-4a90-869a-8483f7d66f38.png"></p><p>【推断网络的目标：<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734874168597-1067d6f0-e503-4a90-869a-8483f7d66f38.png">尽可能接近真实后验<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872347092-b0ea8dc8-cdeb-46e0-ace0-ac7fffeeada0.png"> =&gt; 最小化KL =&gt; 找到网络参数**<font style="color:#DF2A3F;">𝜙</font><strong><sup></sup></strong><font style="color:#DF2A3F;">∗</font>**使得ELBO最大】</p><pre><code>   用神经网络估计![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872812773-687a53bd-48f6-4afe-a15c-49425ffef82a.png)——这个神经网络称为生成网络——输入z，输出![](https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872799769-2ccebd70-c4ed-43da-9454-6839272596b3.png)</code></pre><p>（<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734874588271-a79e2d0d-8c05-4153-854f-e73106b4d042.png">可分为 隐变量 𝒛 的先验分布<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734874549927-c94f5f9c-81b7-44ad-86a6-99d7e06cb7f7.png">和条件概率分布<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734874562219-714d1fc3-ade9-4f79-9efb-e3d57bd9fc3e.png">）</p><p>【生成网络的目标：找到网络参数**<font style="color:#DF2A3F;">θ</font><strong><sup></sup></strong><font style="color:#DF2A3F;">∗</font>**使得ELBO最大】</p><p>  【注意<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872347092-b0ea8dc8-cdeb-46e0-ace0-ac7fffeeada0.png">和<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734872812773-687a53bd-48f6-4afe-a15c-49425ffef82a.png"> 和<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734874168597-1067d6f0-e503-4a90-869a-8483f7d66f38.png">not the same】</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734873905175-904363a2-402f-441c-810b-ef9494379b1b.png"></p><p>汇合推断网络和生成网络的目标（都是使证据下界ELBO最大）：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734875204678-2b90be01-0b9c-43a0-b6f7-f6509ccb8bb5.png"><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734875222457-4ad1c8b5-e26a-4b1c-a7ee-e9f4985240d6.png"></p><p>再参数化：𝑓(𝜃) 的参数 𝜃=𝑔(𝜗)，则 𝑓(𝜗)= 𝑓(𝑔(𝜗))</p><p>引入分布为𝑝(𝜖) 的随机变量 𝜖，把目标的第一项期望写成<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734875854657-2c217ee0-93ea-450a-ac65-9af9ab09de19.png"></p><p>假设第二项的<img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734875907074-c4bc69bb-d11b-4c4d-964a-462e99e4d6a3.png">有：</p><p><img src="https://cdn.nlark.com/yuque/0/2024/png/40781129/1734875982235-d75a48db-a21d-41c0-9887-95c5c9dfab6a.png"></p><p>通过再参数化，可用梯度下降法来学习参数</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> 蒲公英书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VideoCaptioner字幕生成与翻译相关配置与cookie问题解决</title>
      <link href="/2025/03/20/post1/"/>
      <url>/2025/03/20/post1/</url>
      
        <content type="html"><![CDATA[<h1 id="VideoCaptioner"><a href="#VideoCaptioner" class="headerlink" title="VideoCaptioner"></a>VideoCaptioner</h1><p>用处就是给无字幕、无翻译的视频生成带翻译的字幕。但是！！！<br>和b站、youtube上的字幕生成翻译不同，这个可以<font color="pink"><strong>调用大模型进行字幕翻译优化</strong></font><br>项目地址：<a href="https://github.com/WEIFENG2333/VideoCaptioner">https://github.com/WEIFENG2333/VideoCaptioner</a></p><h2 id="关于LLM-api的配置"><a href="#关于LLM-api的配置" class="headerlink" title="关于LLM api的配置"></a>关于LLM api的配置</h2><p>在设置里面可以找到LLM配置，有条件的家人可以选择优质一点的大模型，但我是穷鬼，直接选择免费的GLM-4-Flash，智谱的这个模型是<strong>免费且token无限制</strong>的！！<br><img src="/../images/1.png" alt="LLM配置" title="LLM配置"><br>智谱api申请地址：<a href="https://www.bigmodel.cn/console/overview%E3%80%81">https://www.bigmodel.cn/console/overview、</a><br><img src="/../images/2.png" alt="智谱api概览首页" title="智谱api概览首页"><br><img src="/../images/3.png" alt="智谱api创建入口" title="智谱api创建入口"></p><h2 id="任务创建"><a href="#任务创建" class="headerlink" title="任务创建"></a>任务创建</h2><p>我尝试了俩视频，分别在B站上和油管上的，B站的直接把url复制到框内就能下载，但youtube需要记录cookie（有人机验证），可以在配置文件设置一下就也可以绕过了<br><img src="/../images/5.png" alt="创建任务" title="创建任务"><br>后面就是正常按照流程去生成字幕、翻译了。看一下效果：<br><img src="/../images/6.png" alt="B站上的视频" title="B站上的视频"><br><img src="/../images/7.png" alt="油管上的视频" title="油管上的视频"><br>感觉还阔以</p><h2 id="youtube链接的cookie问题"><a href="#youtube链接的cookie问题" class="headerlink" title="youtube链接的cookie问题"></a>youtube链接的cookie问题</h2><p>首先需要在edge的扩展里整一个插件：Export Cookies File<br><img src="/../images/8.png" alt="插件" title="Export Cookies File"><br>然后回到咱们的视频，运行扩展，导出cookie文件<br><img src="/../images/9.png" alt="运行扩展" title="导出cookie文件"><br>把文件重命名为cookies.txt并放到项目路径中的AppData目录下<br><img src="/../images/10.png" alt="移动到项目路径" title="放到该放的位置捏"><br>然后重启软件，提交url，就能download啦！！完美绕过youtube的付费download！<br>我打算以后下载YouTube的视频也这样搞了，还能顺便生成字幕，美哉美哉~~</p>]]></content>
      
      
      <categories>
          
          <category> 工具设置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
